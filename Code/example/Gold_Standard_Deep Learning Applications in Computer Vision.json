{"corpusId": 3557281, "sections": [{"index": 1, "title": "Introduction", "paragraphs": [{"text": "Deep learning allows computational models of multiple processing layers to learn and represent data with multiple levels of abstraction mimicking how the brain perceives and understands multimodal information, thus implicitly capturing intricate structures of large-scale data. Deep learning is a rich family of methods, encompassing neural networks, hierarchical probabilistic models, and a variety of unsupervised and supervised feature learning algorithms. The recent surge of interest in deep learning methods is due to the fact that they have been shown to outperform previous state-ofthe-art techniques in several tasks, as well as the abundance of complex data from different sources (e.g., visual, audio, medical, social, and sensor).", "citations": []}, {"text": "The ambition to create a system that simulates the human brain fueled the initial development of neural networks. In 1943, McCulloch and Pitts [1] tried to understand how the brain could produce highly complex patterns by using interconnected basic cells, called neurons. The McCulloch and Pitts model of a neuron, called a MCP model, has made an important contribution to the development of artificial neural networks. A series of major contributions in the field is presented in Table 1, including LeNet [2] and Long Short-Term Memory [3], leading up to today's \"era of deep learning.\" One of the most substantial breakthroughs in deep learning came in 2006, when Hinton et al. [4] introduced the Deep Belief Network, with multiple layers of Restricted Boltzmann Machines, greedily training one layer at a time in an unsupervised way. Guiding the training of intermediate levels of representation using unsupervised learning, performed locally at each level, was the main principle behind a series of developments that brought about the last decade's surge in deep architectures and deep learning algorithms.", "citations": [{"ref_id": "b0", "matched_paper_id": 15619658, "title": "A logical calculus of the ideas immanent in nervous activity"}, {"ref_id": "b1", "matched_paper_id": 2542741, "title": "Handwritten digit recognition with a back-propagation network"}, {"ref_id": "b2", "matched_paper_id": 1915014, "title": "Long short-term memory"}, {"ref_id": "b3", "matched_paper_id": 2309950, "title": "A fast learning algorithm for deep belief nets"}]}, {"text": "Among the most prominent factors that contributed to the huge boost of deep learning are the appearance of large, high-quality, publicly available labelled datasets, along with the empowerment of parallel GPU computing, which enabled the transition from CPU-based to GPU-based training thus allowing for significant acceleration in deep models' training. Additional factors may have played a lesser role as well, such as the alleviation of the vanishing gradient problem owing to the disengagement from saturating activation functions (such as hyperbolic tangent and the logistic function), the proposal of new regularization techniques (e.g., dropout, batch normalization, and data augmentation), and the appearance of powerful frameworks like TensorFlow [5], theano [6], and mxnet [7], which allow for faster prototyping.", "citations": [{"ref_id": "b4", "matched_paper_id": null, "title": ""}, {"ref_id": "b5", "matched_paper_id": 8180128, "title": "Theano: new features and speed improvements"}, {"ref_id": "b6", "matched_paper_id": null, "title": ""}]}, {"text": "Deep learning has fueled great strides in a variety of computer vision problems, such as object detection (e.g., [8,9]), motion tracking (e.g., [10,11]), action recognition (e.g., [12,13]), human pose estimation (e.g., [14,15]), and semantic segmentation (e.g., [16,17]). In this overview, we will concisely review the main developments in deep learning architectures and algorithms for computer vision applications. In this context, we will focus on three of the most important types of deep learning models with respect to their applicability in visual understanding, that is, Convolutional Neural Networks (CNNs), the \"Boltzmann family\" including Deep Belief Networks (DBNs) and Deep Boltzmann Machines (DBMs) and Stacked (Denoising) Autoencoders. Needless to say, the current coverage is by no means exhaustive; for example, Long Short-Term Memory (LSTM), in the category of Recurrent Neural Networks, although of great significance as a deep learning scheme, is not presented in this review, since it is predominantly applied in problems such as language modeling, text classification, handwriting recognition, machine translation, speech/music recognition, and less so in computer vision problems. The overview is intended to be useful to computer vision and multimedia analysis researchers, as well as to general machine learning researchers, who are interested in the state of the art in deep learning for computer vision tasks, such as object detection and recognition, face recognition, action/activity recognition, and human pose estimation.", "citations": [{"ref_id": "b7", "matched_paper_id": 11014549, "title": "DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks"}, {"ref_id": "b8", "matched_paper_id": 12221270, "title": "Weakly Supervised Cascaded Convolutional Networks"}, {"ref_id": "b9", "matched_paper_id": 28081849, "title": "FAST-MDL: Fast Adaptive Supervised Training of multi-layered deep learning models for consistent object tracking and classification"}, {"ref_id": "b10", "matched_paper_id": 5046657, "title": "Adaptable deep learning structures for object labeling/tracking under dynamic visual environments"}, {"ref_id": "b11", "matched_paper_id": 15158546, "title": "A deep structured model with radius-margin bound for 3D human activity recognition"}, {"ref_id": "b12", "matched_paper_id": 32942438, "title": "Exploring deep learning based solutions in fine grained activity recognition in the wild"}, {"ref_id": "b13", "matched_paper_id": 206592152, "title": "DeepPose: Human pose estimation via deep neural networks"}, {"ref_id": "b14", "matched_paper_id": 6619926, "title": "Articulated pose estimation by a graphical model with image dependent pairwise relations"}, {"ref_id": "b15", "matched_paper_id": 623137, "title": "Learning deconvolution network for semantic segmentation"}, {"ref_id": "b16", "matched_paper_id": 1629541, "title": "Fully convolutional networks for semantic segmentation"}]}, {"text": "The remainder of this paper is organized as follows. In Section 2, the three aforementioned groups of deep learning model are reviewed: Convolutional Neural Networks, Deep Belief Networks and Deep Boltzmann Machines, and Stacked Autoencoders. The basic architectures, training processes, recent developments, advantages, and limitations of each group are presented. In Section 3, we describe the contribution of deep learning algorithms to key computer vision tasks, such as object detection and recognition, face recognition, action/activity recognition, and human pose estimation; we also provide a list of important datasets and resources for benchmarking and validation of deep learning algorithms. Finally, Section 4 concludes the paper with a summary of findings.", "citations": []}], "citations_in_section": ["b0", "b1", "b10", "b11", "b12", "b13", "b14", "b15", "b16", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9"]}, {"index": 2, "title": "Deep Learning Methods and Developments", "paragraphs": [], "citations_in_section": []}, {"index": 3, "title": "Convolutional Neural Networks. Convolutional Neural", "paragraphs": [{"text": "Networks (CNNs) were inspired by the visual system's structure, and in particular by the models of it proposed in [18]. The first computational models based on these local connectivities between neurons and on hierarchically organized transformations of the image are found in Neocognitron [19], which describes that when neurons with the same parameters are applied on patches of the previous layer at different locations, a form of translational invariance is acquired. Yann LeCun and his collaborators later designed Convolutional Neural Networks employing the error gradient and attaining very good results in a variety of pattern recognition tasks [20][21][22].", "citations": [{"ref_id": "b17", "matched_paper_id": 17055992, "title": "Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex"}, {"ref_id": "b18", "matched_paper_id": 206775608, "title": "Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"}, {"ref_id": "b19", "matched_paper_id": 14542261, "title": "Gradient-based learning applied to document recognition"}, {"ref_id": "b20", "matched_paper_id": 41312633, "title": "Backpropagation applied to handwritten zip code recognition"}, {"ref_id": "b21", "matched_paper_id": 542039, "title": "A mathematical motivation for complex-valued convolutional networks"}]}, {"text": "A CNN comprises three main types of neural layers, namely, (i) convolutional layers, (ii) pooling layers, and (iii) fully connected layers. Each type of layer plays a different role. Figure 1 shows a CNN architecture for an object detection in image task. Every layer of a CNN transforms the input volume to an output volume of neuron activation, eventually leading to the final fully connected layers, resulting in a mapping of the input data to a 1D feature vector. CNNs have been extremely successful in computer vision applications, such as face recognition, object detection, powering vision in robotics, and self-driving cars.", "citations": []}, {"text": "(i) Convolutional Layers. In the convolutional layers, a CNN utilizes various kernels to convolve the whole image as at (x j , y j )", "citations": []}, {"text": "at (x k , y k ) Figure 1: Example architecture of a CNN for a computer vision task (object detection).", "citations": []}, {"text": "well as the intermediate feature maps, generating various feature maps. Because of the advantages of the convolution operation, several works (e.g., [23,24]) have proposed it as a substitute for fully connected layers with a view to attaining faster learning times.", "citations": [{"ref_id": "b22", "matched_paper_id": 206592664, "title": "Is object localization for free? -Weakly-supervised learning with convolutional neural networks"}, {"ref_id": "b23", "matched_paper_id": 206592484, "title": "Going deeper with convolutions"}]}, {"text": "(ii) Pooling Layers. Pooling layers are in charge of reducing the spatial dimensions (width × height) of the input volume for the next convolutional layer. The pooling layer does not affect the depth dimension of the volume. The operation performed by this layer is also called subsampling or downsampling, as the reduction of size leads to a simultaneous loss of information. However, such a loss is beneficial for the network because the decrease in size leads to less computational overhead for the upcoming layers of the network, and also it works against overfitting. Average pooling and max pooling are the most commonly used strategies. In [25] a detailed theoretical analysis of max pooling and average pooling performances is given, whereas in [26] it was shown that max pooling can lead to faster convergence, select superior invariant features, and improve generalization. Also there are a number of other variations of the pooling layer in the literature, each inspired by different motivations and serving distinct needs, for example, stochastic pooling [27], spatial pyramid pooling [28,29], and def-pooling [30].", "citations": [{"ref_id": "b24", "matched_paper_id": 2167514, "title": "A theoretical analysis of feature pooling in visual recognition"}, {"ref_id": "b25", "matched_paper_id": 18388506, "title": "Evaluation of pooling operations in convolutional architectures for object recognition"}, {"ref_id": "b26", "matched_paper_id": 17981839, "title": "Max-Pooling Dropout for Regularization of Convolutional Neural Networks"}, {"ref_id": "b27", "matched_paper_id": 436933, "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"}, {"ref_id": "b28", "matched_paper_id": 436933, "title": "Spatial pyramid pooling in convolutional networks for visual recognition"}, {"ref_id": "b29", "matched_paper_id": 11102127, "title": "DeepID-Net: Deformable deep convolutional neural networks for object detection"}]}, {"text": "(iii) Fully Connected Layers. Following several convolutional and pooling layers, the high-level reasoning in the neural network is performed via fully connected layers. Neurons in a fully connected layer have full connections to all activation in the previous layer, as their name implies. Their activation can hence be computed with a matrix multiplication followed by a bias offset. Fully connected layers eventually convert the 2D feature maps into a 1D feature vector. The derived vector either could be fed forward into a certain number of categories for classification [31] or could be considered as a feature vector for further processing [32]. The architecture of CNNs employs three concrete ideas: (a) local receptive fields, (b) tied weights, and (c) spatial subsampling. Based on local receptive field, each unit in a convolutional layer receives inputs from a set of neighboring units belonging to the previous layer. This way neurons are capable of extracting elementary visual features such as edges or corners. These features are then combined by the subsequent convolutional layers in order to detect higher order features. Furthermore, the idea that elementary feature detectors, which are useful on a part of an image, are likely to be useful across the entire image is implemented by the concept of tied weights. The concept of tied weights constraints a set of units to have identical weights. Concretely, the units of a convolutional layer are organized in planes. All units of a plane share the same set of weights. Thus, each plane is responsible for constructing a specific feature. The outputs of planes are called feature maps. Each convolutional layer consists of several planes, so that multiple feature maps can be constructed at each location.", "citations": [{"ref_id": "b30", "matched_paper_id": 195908774, "title": "Imagenet classification with deep convolutional neural networks"}, {"ref_id": "b31", "matched_paper_id": 215827080, "title": "Rich feature hierarchies for accurate object detection and semantic segmentation"}]}, {"text": "During the construction of a feature map, the entire image is scanned by a unit whose states are stored at corresponding locations in the feature map. This construction is equivalent to a convolution operation, followed by an additive bias term and sigmoid function:", "citations": []}, {"text": "where stands for the depth of the convolutional layer, W is the weight matrix, and b is the bias term. For fully connected neural networks, the weight matrix is full, that is, connects every input to every unit with different weights. For CNNs, the weight matrix W is very sparse due to the concept of tied weights. Thus, W has the form of", "citations": []}, {"text": "where w are matrices having the same dimensions with the units' receptive fields. Employing a sparse weight matrix reduces the number of network's tunable parameters and thus increases its generalization ability. Multiplying W with layer inputs is like convolving the input with w, which can be seen as a trainable filter. If the input to −1 convolutional layer is of 4 Computational Intelligence and Neuroscience dimension × and the receptive field of units at a specific plane of convolutional layer is of dimension × , then the constructed feature map will be a matrix of dimensions ( − + 1) × ( − + 1). Specifically, the element of feature map at ( , ) location will be", "citations": []}, {"text": "where the bias term is scalar. Using (4) and (3) sequentially for all ( , ) positions of input, the feature map for the corresponding plane is constructed.", "citations": []}, {"text": "One of the difficulties that may arise with training of CNNs has to do with the large number of parameters that have to be learned, which may lead to the problem of overfitting. To this end, techniques such as stochastic pooling, dropout, and data augmentation have been proposed. Furthermore, CNNs are often subjected to pretraining, that is, to a process that initializes the network with pretrained parameters instead of randomly set ones. Pretraining can accelerate the learning process and also enhance the generalization capability of the network.", "citations": []}, {"text": "Overall, CNNs were shown to significantly outperform traditional machine learning approaches in a wide range of computer vision and pattern recognition tasks [33], examples of which will be presented in Section 3. Their exceptional performance combined with the relative easiness in training are the main reasons that explain the great surge in their popularity over the last few years.", "citations": [{"ref_id": "b32", "matched_paper_id": 207178999, "title": "Learning deep architectures for AI"}]}], "citations_in_section": ["b17", "b18", "b19", "b20", "b21", "b22", "b23", "b24", "b25", "b26", "b27", "b28", "b29", "b30", "b31", "b32"]}, {"index": 4, "title": "Deep Belief Networks and Deep Boltzmann Machines.", "paragraphs": [{"text": "Deep Belief Networks and Deep Boltzmann Machines are deep learning models that belong in the \"Boltzmann family,\" in the sense that they utilize the Restricted Boltzmann Machine (RBM) as learning module. The Restricted Boltzmann Machine (RBM) is a generative stochastic neural network. DBNs have undirected connections at the top two layers which form an RBM and directed connections to the lower layers. DBMs have undirected connections between all layers of the network. A graphic depiction of DBNs and DBMs can be found in Figure 2. In the following subsections, we will describe the basic characteristics of DBNs and DBMs, after presenting their basic building block, the RBM.", "citations": []}], "citations_in_section": []}, {"index": 5, "title": "Restricted Boltzmann Machines.", "paragraphs": [{"text": "A Restricted Boltzmann Machine ( [34,35]) is an undirected graphical model with stochastic visible variables k ∈ {0, 1} and stochastic hidden variables h ∈ {0, 1} , where each visible variable is connected to each hidden variable. An RBM is a variant of the Boltzmann Machine, with the restriction that the visible units and hidden units must form a bipartite graph. This restriction allows for more efficient training algorithms, in particular the gradient-based contrastive divergence algorithm [36].", "citations": [{"ref_id": "b33", "matched_paper_id": 533055, "title": "Information processing in dynamical systems: Foundations of harmony theory"}, {"ref_id": "b34", "matched_paper_id": null, "title": ""}, {"ref_id": "b35", "matched_paper_id": 17861266, "title": "On contrastive divergence learning"}]}, {"text": "The model defines the energy function : {0, 1} × {0, 1} → R:", "citations": []}, {"text": "where = {a, b, W} are the model parameters; that is, represents the symmetric interaction term between visible unit and hidden unit , and , are bias terms. The joint distribution over the visible and hidden units is given by", "citations": []}, {"text": "where Z( ) is the normalizing constant. The conditional distributions over hidden h and visible v vectors can be derived by (5) and (6) as", "citations": []}, {"text": "Given a set of observations {k } =1 the derivative of the loglikelihood with respect to the model parameters can be derived by (6) as", "citations": []}, {"text": "where E data denotes an expectation with respect to the data distribution data (h, k; ) = (h | k; ) data (k), with data (k) = (1/ ) ∑ (k − k n ) representing the empirical distribution and E model is an expectation with respect to the distribution defined by the model, as in (6).", "citations": []}, {"text": "A detailed explanation along with the description of a practical way to train RBMs was given in [37], whereas [38] discusses the main difficulties of training RBMs and their underlying reasons and proposes a new algorithm with an adaptive learning rate and an enhanced gradient, so as to address the aforementioned difficulties.", "citations": [{"ref_id": "b36", "matched_paper_id": 21145246, "title": "A practical guide to training restricted Boltzmann machines"}, {"ref_id": "b37", "matched_paper_id": 11878505, "title": "Enhanced gradient for training restricted Boltzmann machines"}]}], "citations_in_section": ["b33", "b34", "b35", "b36", "b37"]}, {"index": 6, "title": "Deep Belief Networks.", "paragraphs": [{"text": "Deep Belief Networks (DBNs) are probabilistic generative models which provide a joint probability distribution over observable data and labels. They are formed by stacking RBMs and training them in a greedy manner, as was proposed in [39]. A DBN initially employs an efficient layer-by-layer greedy learning strategy to initialize the deep network, and, in the sequel, fine-tunes all weights jointly with the desired outputs. DBNs are graphical models which learn to extract a deep hierarchical representation of the training data. They model the joint distribution between observed vector x and the hidden layers h as follows: The principle of greedy layer-wise unsupervised training can be applied to DBNs with RBMs as the building blocks for each layer [33,39]. A brief description of the process follows:", "citations": [{"ref_id": "b38", "matched_paper_id": 1658773, "title": "Reducing the dimensionality of data with neural networks"}, {"ref_id": "b32", "matched_paper_id": 207178999, "title": "Learning deep architectures for AI"}, {"ref_id": "b38", "matched_paper_id": 1658773, "title": "Reducing the dimensionality of data with neural networks"}]}, {"text": "(1) Train the first layer as an RBM that models the raw input x = h 0 as its visible layer. (2) Use that first layer to obtain a representation of the input that will be used as data for the second layer. Two common solutions exist. This representation can be chosen as being the mean activation  (2) and (3)) for the desired number of layers, each time propagating upward either samples or mean values. (5) Fine-tune all the parameters of this deep architecture with respect to a proxy for the DBN log-likelihood, or with respect to a supervised training criterion (after adding extra learning machinery to convert the learned representation into supervised predictions, e.g., a linear classifier).", "citations": []}, {"text": "There are two main advantages in the above-described greedy learning process of the DBNs [40]. First, it tackles the challenge of appropriate selection of parameters, which in some cases can lead to poor local optima, thereby ensuring that the network is appropriately initialized. Second, there is no requirement for labelled data since the process is unsupervised. Nevertheless, DBNs are also plagued by a number of shortcomings, such as the computational cost associated with training a DBN and the fact that the steps towards further optimization of the network based on maximum likelihood training approximation are unclear [41]. Furthermore, a significant disadvantage of DBNs is that they do not account for the two-dimensional structure of an input image, which may significantly affect their performance and applicability in computer vision and multimedia analysis problems. However, a later variation of the DBN, the Convolutional Deep Belief Network (CDBN) ( [42,43]), uses the spatial information of neighboring pixels by introducing convolutional RBMs, thus producing a translation invariant generative model that successfully scales when it comes to high dimensional images, as is evidenced in [44].  [46] based algorithm to maximize the lower bound on the likelihood. Such a process would seem vulnerable to falling in poor local minima [45], leaving several units effectively dead. Instead, a greedy layer-wise training strategy was proposed [47], which essentially consists in pretraining the layers of the DBM, similarly to DBN, namely, by stacking RBMs and training each layer to independently model the output of the previous layer, followed by a final joint finetuning.", "citations": [{"ref_id": "b39", "matched_paper_id": 10663248, "title": "Deep machine learning-a new frontier in artificial intelligence research"}, {"ref_id": "b40", "matched_paper_id": 393948, "title": "Representation learning: a review and new perspectives"}, {"ref_id": "b41", "matched_paper_id": 12008458, "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations"}, {"ref_id": "b42", "matched_paper_id": 9511725, "title": "Unsupervised learning of hierarchical representations with convolutional deep belief networks"}, {"ref_id": "b43", "matched_paper_id": 206591781, "title": "Learning hierarchical representations for face verification with convolutional deep belief networks"}, {"ref_id": "b45", "matched_paper_id": 15419929, "title": "On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates"}, {"ref_id": "b44", "matched_paper_id": 877639, "title": "Deep boltzmann machines"}, {"ref_id": "b46", "matched_paper_id": 9383489, "title": "Efficient learning of deep Boltzmann machines"}]}], "citations_in_section": ["b32", "b38", "b39", "b40", "b41", "b42", "b43", "b44", "b45", "b46"]}, {"index": 7, "title": "Deep Boltzmann", "paragraphs": [{"text": "Regarding the advantages of DBMs, they can capture many layers of complex representations of input data and they are appropriate for unsupervised learning since they can be trained on unlabeled data, but they can also be finetuned for a particular task in a supervised fashion. One of the attributes that sets DBMs apart from other deep models is that the approximate inference process of DBMs includes, apart from the usual bottom-up process, a top-down feedback, thus incorporating uncertainty about inputs in a more effective manner. Furthermore, in DBMs, by following the approximate gradient of a variational lower bound on the likelihood objective, one can jointly optimize the parameters of all layers, which is very beneficial especially in cases of learning models from heterogeneous data originating from different modalities [48].", "citations": [{"ref_id": "b47", "matched_paper_id": 710430, "title": "Multimodal learning with deep Boltzmann machines"}]}, {"text": "As far as the drawbacks of DBMs are concerned, one of the most important ones is, as mentioned above, the high computational cost of inference, which is almost prohibitive when it comes to joint optimization in sizeable datasets. Several methods have been proposed to improve the effectiveness of DBMs. These include accelerating inference by using separate models to initialize the values of the hidden units in all layers [47,49], or other improvements at the pretraining stage [50,51] or at the training stage [52,53].", "citations": [{"ref_id": "b46", "matched_paper_id": 9383489, "title": "Efficient learning of deep Boltzmann machines"}, {"ref_id": "b48", "matched_paper_id": 12487239, "title": "An efficient learning procedure for deep Boltzmann machines"}, {"ref_id": "b49", "matched_paper_id": 8717922, "title": "A better way to pretrain Deep Boltzmann Machines"}, {"ref_id": "b50", "matched_paper_id": 7178848, "title": "A two-stage pretraining algorithm for deep boltzmann machines"}, {"ref_id": "b51", "matched_paper_id": 6087730, "title": "Deep Boltzmann Machines and the Centering Trick"}, {"ref_id": "b52", "matched_paper_id": 6442575, "title": "Multi-prediction deep Boltzmann machines"}]}], "citations_in_section": ["b46", "b47", "b48", "b49", "b50", "b51", "b52"]}, {"index": 8, "title": "Stacked (Denoising) Autoencoders.", "paragraphs": [{"text": "Stacked Autoencoders use the autoencoder as their main building block, similarly to the way that Deep Belief Networks use Restricted Boltzmann Machines as component. It is therefore important to briefly present the basics of the autoencoder and its denoising version, before describing the deep learning architecture of Stacked (Denoising) Autoencoders.", "citations": []}], "citations_in_section": []}, {"index": 9, "title": "2.3.1.", "paragraphs": [{"text": "Autoencoders. An autoencoder is trained to encode the input x into a representation r(x) in a way that input can be reconstructed from r(x) [33]. The target output of the autoencoder is thus the autoencoder input itself. Hence, the output vectors have the same dimensionality as the input vector. In the course of this process, the reconstruction error is being minimized, and the corresponding code is the learned feature. If there is one linear hidden layer and the mean squared error criterion is used to train the network, then the hidden units learn to project the input in the span of the first principal components of the data [54]. If the hidden layer is nonlinear, the autoencoder behaves differently from PCA, with the ability to capture multimodal aspects of the input distribution [55]. The parameters of the model are optimized so that the average reconstruction error is minimized. There are many alternatives to measure the reconstruction error, including the traditional squared error:", "citations": [{"ref_id": "b32", "matched_paper_id": 207178999, "title": "Learning deep architectures for AI"}, {"ref_id": "b53", "matched_paper_id": 206775335, "title": "Auto-association by multilayer perceptrons and singular value decomposition"}, {"ref_id": "b54", "matched_paper_id": 18490972, "title": "Nonlinear autoassociation is not equivalent to PCA"}]}], "citations_in_section": ["b32", "b53", "b54"]}, {"index": 10, "title": "Hidden node", "paragraphs": [{"text": "Reconstruct error Reconstruction Input Corrupted input = ‖x − f (r (x))‖ 2 ,", "citations": []}, {"text": "where function f is the decoder and f(r(x)) is the reconstruction produced by the model. If the input is interpreted as bit vectors or vectors of bit probabilities, then the loss function of the reconstruction could be represented by cross-entropy; that is,", "citations": []}, {"text": "The goal is for the representation (or code) r(x) to be a distributed representation that manages to capture the coordinates along the main variations of the data, similarly to the principle of Principal Components Analysis (PCA). Given that r(x) is not lossless, it is impossible for it to constitute a successful compression for all input x. The aforementioned optimization process results in low reconstruction error on test examples from the same distribution as the training examples but generally high reconstruction error on samples arbitrarily chosen from the input space. [56] is a stochastic version of the autoencoder where the input is stochastically corrupted, but the uncorrupted input is still used as target for the reconstruction. In simple terms, there are two main aspects in the function of a denoising autoencoder: first it tries to encode the input (namely, preserve the information about the input), and second it tries to undo the effect of a corruption process stochastically applied to the input of the autoencoder (see Figure 3). The latter can only be done by capturing the statistical dependencies between the inputs. It can be shown that the denoising autoencoder maximizes a lower bound on the log-likelihood of a generative model.", "citations": [{"ref_id": "b55", "matched_paper_id": 207168299, "title": "Extracting and composing robust features with denoising autoencoders"}]}], "citations_in_section": ["b55"]}, {"index": 11, "title": "Denoising Autoencoders. The denoising autoencoder", "paragraphs": [{"text": "In [56], the stochastic corruption process arbitrarily sets a number of inputs to zero. Then the denoising autoencoder is trying to predict the corrupted values from the uncorrupted ones, for randomly selected subsets of missing patterns. In essence, the ability to predict any subset of variables from the remaining ones is a sufficient condition for completely capturing the joint distribution between a set of variables. It should be mentioned that using autoencoders for denoising was introduced in earlier works (e.g., [57]), but the substantial contribution of [56] lies in the demonstration of the successful use of the method for unsupervised pretraining of a deep architecture and in linking the denoising autoencoder to a generative model.", "citations": [{"ref_id": "b55", "matched_paper_id": 207168299, "title": "Extracting and composing robust features with denoising autoencoders"}, {"ref_id": "b56", "matched_paper_id": null, "title": "Memoires associatives distribuees"}, {"ref_id": "b55", "matched_paper_id": 207168299, "title": "Extracting and composing robust features with denoising autoencoders"}]}], "citations_in_section": ["b55", "b56"]}, {"index": 12, "title": "Stacked (Denoising) Autoencoders.", "paragraphs": [{"text": "It is possible to stack denoising autoencoders in order to form a deep network by feeding the latent representation (output code) of the denoising autoencoder of the layer below as input to the current layer. The unsupervised pretraining of such an architecture is done one layer at a time. Each layer is trained as a denoising autoencoder by minimizing the error in reconstructing its input (which is the output code of the previous layer). When the first layers are trained, we can train the ( + 1)th layer since it will then be possible compute the latent representation from the layer underneath.", "citations": []}, {"text": "When pretraining of all layers is completed, the network goes through a second stage of training called fine-tuning. Here supervised fine-tuning is considered when the goal is to optimize prediction error on a supervised task. To this end, a logistic regression layer is added on the output code of the output layer of the network. The derived network is then trained like a multilayer perceptron, considering only the encoding parts of each autoencoder at this point. This stage is supervised, since the target class is taken into account during training.", "citations": []}, {"text": "As is easily seen, the principle for training stacked autoencoders is the same as the one previously described for Deep Belief Networks, but using autoencoders instead of Restricted Boltzmann Machines. A number of comparative experimental studies show that Deep Belief Networks tend to outperform stacked autoencoders ( [58,59]), but this is not always the case, especially when DBNs are compared to Stacked Denoising Autoencoders [56].", "citations": [{"ref_id": "b57", "matched_paper_id": 14805281, "title": "An empirical evaluation of deep architectures on problems with many factors of variation"}, {"ref_id": "b58", "matched_paper_id": 14201947, "title": "Greedy layer-wise training of deep networks"}, {"ref_id": "b55", "matched_paper_id": 207168299, "title": "Extracting and composing robust features with denoising autoencoders"}]}, {"text": "One strength of autoencoders as the basic unsupervised component of a deep architecture is that, unlike with RBMs, they allow almost any parametrization of the layers, on condition that the training criterion is continuous in the parameters. In contrast, one of the shortcomings of SAs is that they do not correspond to a generative model, when with generative models like RBMs and DBNs, samples can be drawn to check the outputs of the learning process.", "citations": []}], "citations_in_section": ["b55", "b57", "b58"]}, {"index": 13, "title": "Discussion.", "paragraphs": [{"text": "Some of the strengths and limitations of the presented deep learning models were already discussed in the respective subsections. In an attempt to compare these models (for a summary see Table 2), we can say that CNNs have generally performed better than DBNs in current literature on benchmark computer vision datasets such as MNIST. In cases where the input is nonvisual, DBNs often outperform other models, but the difficulty in accurately estimating joint probabilities as well as the computational cost in creating a DBN constitutes drawbacks. A major positive aspect of CNNs is \"feature learning,\" that is, the bypassing of handcrafted features, which are necessary for other types of networks; however, in CNNs features are automatically learned. On the other hand, CNNs rely on the availability of ground truth, that is, labelled training data, whereas DBNs/DBMs and SAs do not have this limitation and can work in an unsupervised manner. On a different note, one of the disadvantages of autoencoders lies in the fact that they could become ineffective if errors are present in the first layers. Such errors may cause the network to learn to reconstruct the average of the training data. Denoising autoencoders [56], however, can retrieve the correct input from a corrupted version, thus leading the network to grasp the structure of the input distribution. In terms of the efficiency of the training process, only in the case of SAs is real-time training possible, whereas CNNs and DBNs/DBMs training processes are time-consuming. Finally, one of the strengths of CNNs is the fact that they can be invariant to transformations such as translation, scale, and rotation. Invariance to translation, rotation, and scale is one of the most important assets of CNNs, especially in computer vision problems, such as object detection, because it allows abstracting an object's identity or category from the specifics of the visual input (e.g., relative positions/orientation of the camera and the object), thus enabling the network to effectively recognize a given object in cases where the actual pixel values on the image can significantly differ.", "citations": [{"ref_id": "b55", "matched_paper_id": 207168299, "title": "Extracting and composing robust features with denoising autoencoders"}]}], "citations_in_section": ["b55"]}, {"index": 14, "title": "Applications in Computer Vision", "paragraphs": [{"text": "In this section, we survey works that have leveraged deep learning methods to address key tasks in computer vision, such as object detection, face recognition, action and activity recognition, and human pose estimation.", "citations": []}], "citations_in_section": []}, {"index": 15, "title": "Object Detection.", "paragraphs": [{"text": "Object detection is the process of detecting instances of semantic objects of a certain class (such as humans, airplanes, or birds) in digital images and video ( Figure 4). A common approach for object detection frameworks includes the creation of a large set of candidate windows that are in the sequel classified using CNN features. For example, the method described in [32] employs selective search [60] to derive object proposals, extracts CNN features for each proposal, and then feeds the features to an SVM classifier to decide whether the windows include the object or not. A large number of works is based on the concept of Regions with CNN features proposed in [32]. Approaches following the Regions with CNN paradigm usually have good detection accuracies (e.g., [61,62]); however, there is a significant number of methods trying to further improve the performance of Regions with CNN approaches, some of which succeed in finding approximate object positions but often cannot precisely determine the exact position of the object [63]. To this end, such methods often follow a joint object detection-semantic segmentation approach [64][65][66], usually attaining good results. A vast majority of works on object detection using deep learning apply a variation of CNNs, for example, [  (in which a new def-pooling layer and new learning strategy are proposed), [9] (weakly supervised cascaded CNNs), and [69] (subcategory-aware CNNs). However, there does exist a relatively small number of object detection attempts using other deep models. For example, [70] proposes a coarse object locating method based on a saliency mechanism in conjunction with a DBN for object detection in remote sensing images; [71] presents a new DBN for 3D object recognition, in which the top-level model is a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients; [72] employs a fused deep learning approach, while [73] explores the representation capabilities of a deep model in a semisupervised paradigm. Finally, [74] leverages stacked autoencoders for multiple organ detection in medical images, while [75] exploits saliency-guided stacked autoencoders for videobased salient object detection.", "citations": [{"ref_id": "b31", "matched_paper_id": 215827080, "title": "Rich feature hierarchies for accurate object detection and semantic segmentation"}, {"ref_id": "b59", "matched_paper_id": 216077384, "title": "Selective search for object recognition"}, {"ref_id": "b31", "matched_paper_id": 215827080, "title": "Rich feature hierarchies for accurate object detection and semantic segmentation"}, {"ref_id": "b60", "matched_paper_id": 206770307, "title": "Fast R-CNN"}, {"ref_id": "b61", "matched_paper_id": 10328909, "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"ref_id": "b62", "matched_paper_id": 5819909, "title": "How good are detection proposals, really"}, {"ref_id": "b63", "matched_paper_id": 9272368, "title": "Simultaneous detection and segmentation"}, {"ref_id": "b64", "matched_paper_id": 3792560, "title": "Towards unified object detection and semantic segmentation"}, {"ref_id": "b65", "matched_paper_id": 542190, "title": "SegDeepM: Exploiting segmentation and context in deep neural networks for object detection"}, {"ref_id": "b8", "matched_paper_id": 12221270, "title": "Weakly Supervised Cascaded Convolutional Networks"}, {"ref_id": "b68", "matched_paper_id": 26108190, "title": "S-CNN: Subcategory-aware convolutional networks for object detection"}, {"ref_id": "b69", "matched_paper_id": 32085416, "title": "Efficient Saliency-Based Object Detection in Remote Sensing Images Using Deep Belief Networks"}, {"ref_id": "b70", "matched_paper_id": 2416787, "title": "3D object recognition with deep belief nets"}, {"ref_id": "b71", "matched_paper_id": 21070027, "title": "Fast and adaptive deep fusion learning for detecting visual objects"}, {"ref_id": "b72", "matched_paper_id": null, "title": ""}, {"ref_id": "b73", "matched_paper_id": 8772285, "title": "Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data"}, {"ref_id": "b74", "matched_paper_id": 6988818, "title": "A benchmark dataset and saliencyguided stacked autoencoders for video-based salient object detection"}]}], "citations_in_section": ["b31", "b59", "b60", "b61", "b62", "b63", "b64", "b65", "b68", "b69", "b70", "b71", "b72", "b73", "b74", "b8"]}, {"index": 16, "title": "Face Recognition.", "paragraphs": [{"text": "Face recognition is one of the hottest computer vision applications with great commercial interest as well. A variety of face recognition systems based on the extraction of handcrafted features have been proposed [76][77][78][79]; in such cases, a feature extractor extracts features from an aligned face to obtain a low-dimensional representation, based on which a classifier makes predictions. CNNs brought about a change in the face recognition field, thanks to their feature learning and transformation invariance properties. The first work employing CNNs for face recognition was [80]; today light CNNs [81] and VGG Face Descriptor [82] are among the state of the art. In [44] a Convolutional DBN achieved a great performance in face verification. Moreover, Google's FaceNet [83] and Facebook's Deep-Face [84] are both based on CNNs. DeepFace [84] models a face in 3D and aligns it to appear as a frontal face. Then, the normalized input is fed to a single convolution-poolingconvolution filter, followed by three locally connected layers and two fully connected layers used to make final predictions. Although DeepFace attains great performance rates, its representation is not easy to interpret because the faces of the same person are not necessarily clustered during the training process. On the other hand, FaceNet defines a triplet loss function on the representation, which makes the training process learn to cluster the face representation of the same person. Furthermore, CNNs constitute the core of OpenFace [85], an open-source face recognition tool, which is of comparable (albeit a little lower) accuracy, is open-source, and is suitable for mobile computing, because of its smaller size and fast execution time.", "citations": [{"ref_id": "b75", "matched_paper_id": 5785086, "title": "Blessing of dimensionality: high-dimensional feature and its efficient compression for face verification"}, {"ref_id": "b76", "matched_paper_id": 5726206, "title": "A practical transfer learning algorithm for face verification"}, {"ref_id": "b77", "matched_paper_id": 11757052, "title": "Tom-vs-Pete classifiers and identity-preserving alignment for face verification"}, {"ref_id": "b78", "matched_paper_id": 1345207, "title": "Bayesian face revisited: a joint formulation"}, {"ref_id": "b79", "matched_paper_id": 2883848, "title": "Face recognition: a convolutional neural-network approach"}, {"ref_id": "b80", "matched_paper_id": null, "title": ""}, {"ref_id": "b81", "matched_paper_id": 4637184, "title": "Deep Face Recognition"}, {"ref_id": "b43", "matched_paper_id": 206591781, "title": "Learning hierarchical representations for face verification with convolutional deep belief networks"}, {"ref_id": "b82", "matched_paper_id": 206592766, "title": "FaceNet: a unified embedding for face recognition and clustering"}, {"ref_id": "b83", "matched_paper_id": 2814088, "title": "DeepFace: closing the gap to human-level performance in face verification"}, {"ref_id": "b83", "matched_paper_id": 2814088, "title": "DeepFace: closing the gap to human-level performance in face verification"}, {"ref_id": "b84", "matched_paper_id": null, "title": ""}]}], "citations_in_section": ["b43", "b75", "b76", "b77", "b78", "b79", "b80", "b81", "b82", "b83", "b84"]}, {"index": 17, "title": "Action and Activity Recognition.", "paragraphs": [{"text": "Human action and activity recognition is a research issue that has received a lot of attention from researchers [86,87]. Many works on human activity recognition based on deep learning techniques have been proposed in the literature in the last few years [88]. In [89] deep learning was used for complex event detection and recognition in video sequences: first, saliency maps were used for detecting and localizing events, and then deep learning was applied to the pretrained features for identifying the most important frames that correspond to the underlying event. In [90] the authors successfully employ a CNN-based approach for activity recognition in beach volleyball, similarly to the approach of [91] for event classification from large-scale video datasets; in [92], a CNN model is used for activity recognition based on smartphone sensor data. The authors of [12] incorporate a radius-margin bound as a regularization term into the deep CNN model, which effectively improves the generalization performance of the CNN for activity classification. In [13], the authors scrutinize the applicability of CNN as joint feature extraction and classification model for fine-grained activities; they find that due to the challenges of large intraclass variances, small interclass variances, and limited training samples per activity, an approach that directly uses deep features learned from ImageNet in an SVM classifier is preferable.", "citations": [{"ref_id": "b85", "matched_paper_id": 11489291, "title": "A top-down event-driven approach for concurrent activity recognition"}, {"ref_id": "b86", "matched_paper_id": 888778, "title": "Improving multi-camera activity recognition by employing neural network based readjustment"}, {"ref_id": "b87", "matched_paper_id": 16983288, "title": "Deep learning based human behavior recognition in industrial workflows"}, {"ref_id": "b88", "matched_paper_id": 7508190, "title": "DevNet: A Deep Event Network for multimedia event detection and evidence recounting"}, {"ref_id": "b89", "matched_paper_id": 16170944, "title": "Activity recognition in beach volleyball using a DEEp Convolutional Neural NETwork: leveraging the potential of DEEp Learning in sports"}, {"ref_id": "b90", "matched_paper_id": 206592218, "title": "Large-scale video classification with convolutional neural networks"}, {"ref_id": "b91", "matched_paper_id": 7870225, "title": "Human activity recognition with smartphone sensors using deep learning neural networks"}, {"ref_id": "b11", "matched_paper_id": 15158546, "title": "A deep structured model with radius-margin bound for 3D human activity recognition"}, {"ref_id": "b12", "matched_paper_id": 32942438, "title": "Exploring deep learning based solutions in fine grained activity recognition in the wild"}]}, {"text": "Driven by the adaptability of the models and by the availability of a variety of different sensors, an increasingly popular strategy for human activity recognition consists in fusing multimodal features and/or data. In [93], the authors mixed appearance and motion features for recognizing group activities in crowded scenes collected from the web. For the combination of the different modalities, the authors applied multitask deep learning. The work of [94] explores combination of heterogeneous features for complex event recognition. The problem is viewed as two different tasks: first, the most informative features for recognizing events are estimated, and then the different features are combined using an AND/OR graph structure. There is also a number of works combining more than one type of model, apart from several data modalities. In [95], the authors propose a multimodal multistream deep learning framework to tackle the egocentric activity recognition problem, using both the video and sensor data and employing a dual CNNs and Long Short-Term Memory architecture. Multimodal fusion with a combined CNN and LSTM architecture is also proposed in [96]. Finally, [97] uses DBNs for activity recognition using input video sequences that also include depth information.", "citations": [{"ref_id": "b92", "matched_paper_id": 27680895, "title": "Crowded Scene Understanding by Deeply Learned Volumetric Slices"}, {"ref_id": "b93", "matched_paper_id": 851173, "title": "Combining the right features for complex event recognition"}, {"ref_id": "b94", "matched_paper_id": 9094338, "title": "Multimodal Multi-Stream Deep Learning for Egocentric Activity Recognition"}, {"ref_id": "b95", "matched_paper_id": 63833913, "title": "Multiview fusion for activity recognition using deep neural networks"}, {"ref_id": "b96", "matched_paper_id": 15685913, "title": "Human activity recognition using deep belief networks"}]}], "citations_in_section": ["b11", "b12", "b85", "b86", "b87", "b88", "b89", "b90", "b91", "b92", "b93", "b94", "b95", "b96"]}, {"index": 18, "title": "Human Pose Estimation.", "paragraphs": [{"text": "The goal of human pose estimation is to determine the position of human joints from images, image sequences, depth images, or skeleton data as provided by motion capturing hardware [98]. Human pose estimation is a very challenging task owing to the vast range of human silhouettes and appearances, difficult illumination, and cluttered background. Before the era of deep learning, pose estimation was based on detection of body parts, for example, through pictorial structures [99].", "citations": [{"ref_id": "b97", "matched_paper_id": 8810735, "title": "Dance analysis using multiple kinect sensors"}, {"ref_id": "b98", "matched_paper_id": 2277383, "title": "Pictorial structures for object recognition"}]}, {"text": "Moving on to deep learning methods in human pose estimation, we can group them into holistic and part-based methods, depending on the way the input images are processed. The holistic processing methods tend to accomplish their task in a global fashion and do not explicitly define a model for each individual part and their spatial relationships. DeepPose [14] is a holistic model that formulates the human pose estimation method as a joint regression problem and does not explicitly define the graphical model or part detectors for the human pose estimation. Nevertheless, holisticbased methods tend to be plagued by inaccuracy in the high-precision region due to the difficulty in learning direct regression of complex pose vectors from images.", "citations": [{"ref_id": "b13", "matched_paper_id": 206592152, "title": "DeepPose: Human pose estimation via deep neural networks"}]}, {"text": "On the other hand, the part-based processing methods focus on detecting the human body parts individually, followed by a graphic model to incorporate the spatial information. In [15], the authors, instead of training the network using the whole image, use the local part patches and background patches to train a CNN, in order to learn conditional probabilities of the part presence and spatial relationships. In [100] the approach trains multiple smaller CNNs to perform independent binary body-part classification, followed with a higher-level weak spatial model to remove strong outliers and to enforce global pose consistency. Finally, in [101], a multiresolution CNN is designed to perform heat-map likelihood regression for each body part, followed with an implicit graphic model to further promote joint consistency.", "citations": [{"ref_id": "b14", "matched_paper_id": 6619926, "title": "Articulated pose estimation by a graphical model with image dependent pairwise relations"}, {"ref_id": "b99", "matched_paper_id": 7777777, "title": "Learning human pose estimation features with convolutional networks"}, {"ref_id": "b100", "matched_paper_id": 392527, "title": "Joint training of a convolutional network and a graphical model for human pose estimation"}]}], "citations_in_section": ["b100", "b13", "b14", "b97", "b98", "b99"]}, {"index": 19, "title": "3.5.", "paragraphs": [{"text": "Datasets. The applicability of deep learning approaches has been evaluated on numerous datasets, whose content varied greatly, according the application scenario. Regardless of the investigated case, the main application domain is (natural) images. A brief description of utilized datasets (traditional and new ones) for benchmarking purposes is provided below.", "citations": []}, {"text": "(1) Grayscale Images. The most used grayscale images dataset is MNIST [20] and its variations, that is, NIST and perturbed NIST. The application scenario is the recognition of handwritten digits.", "citations": [{"ref_id": "b19", "matched_paper_id": 14542261, "title": "Gradient-based learning applied to document recognition"}]}, {"text": "(2) RGB Natural Images. Caltech RGB image datasets [102], for example, Caltech 101/Caltech 256 and the Caltech Silhouettes, contain pictures of objects belonging to 101/256 categories. CIFAR datasets [103] consist of thousands of 32 × 32 color images in various classes. COIL datasets [104] consist of different objects imaged at every angle in a 360 rotation.", "citations": [{"ref_id": "b101", "matched_paper_id": 6953475, "title": "One-shot learning of object categories"}, {"ref_id": "b102", "matched_paper_id": null, "title": ""}, {"ref_id": "b103", "matched_paper_id": null, "title": ""}]}, {"text": "(3) Hyperspectral Images. SCIEN hyperspectral image data [105] and AVIRIS sensor based datasets [106], for example, contain hyperspectral images.", "citations": [{"ref_id": "b104", "matched_paper_id": 15718221, "title": "A collection of hyperspectral images for imaging systems research"}, {"ref_id": "b105", "matched_paper_id": null, "title": ""}]}, {"text": "(4) Facial Characteristics Images. Adience benchmark dataset [107] can be used for facial attributes identification, that is, age and gender, from images of faces. Face recognition in unconstrained environments [108] is another commonly used dataset.", "citations": [{"ref_id": "b106", "matched_paper_id": 9442999, "title": "Age and gender estimation of unfiltered faces"}, {"ref_id": "b107", "matched_paper_id": null, "title": ""}]}, {"text": "(5) Medical Images. Chest X-ray dataset [109] comprises 112120 frontal-view X-ray images of 30805 unique patients with the text-mined fourteen disease image labels (where each image can have multilabels). Lymph Node Detection and Segmentation datasets [110] consist of Computed Tomography images of the mediastinum and abdomen.", "citations": [{"ref_id": "b108", "matched_paper_id": 8945673, "title": "ChestX-Ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases"}, {"ref_id": "b109", "matched_paper_id": 9938334, "title": "Leveraging mid-level semantic boundary cues for automated lymph node detection"}]}, {"text": "(6) Video Streams. The WR datasets [111,112] can be used for video-based activity recognition in assembly lines [113], containing sequences of 7 categories of industrial tasks. YouTube-8M [114] is a dataset of 8 million YouTube video URLs, along with video-level labels from a diverse set of 4800 Knowledge Graph entities.", "citations": [{"ref_id": "b110", "matched_paper_id": 7170984, "title": "A dataset for workflow recognition in industrial scenes"}, {"ref_id": "b111", "matched_paper_id": 14805968, "title": "A threefold dataset for activity and workflow recognition in complex industrial environments"}, {"ref_id": "b112", "matched_paper_id": 6309858, "title": "A system for multicamera task recognition and summarization for structured environments"}, {"ref_id": "b113", "matched_paper_id": null, "title": ""}]}], "citations_in_section": ["b101", "b102", "b103", "b104", "b105", "b106", "b107", "b108", "b109", "b110", "b111", "b112", "b113", "b19"]}, {"index": 20, "title": "Conclusions", "paragraphs": [{"text": "The surge of deep learning over the last years is to a great extent due to the strides it has enabled in the field of computer vision. The three key categories of deep learning for computer vision that have been reviewed in this paper, namely, CNNs, the \"Boltzmann family\" including DBNs and DBMs, and SdAs, have been employed to achieve significant performance rates in a variety of visual understanding tasks, such as object detection, face recognition, action and activity recognition, human pose estimation, image retrieval, and semantic segmentation. However, each category has distinct advantages and disadvantages. CNNs have the unique capability of feature learning, that is, of automatically learning features based on the given dataset. CNNs are also invariant to transformations, which is a great asset for certain computer vision applications. On the other hand, they heavily rely on the existence of labelled data, in contrast to DBNs/DBMs and SdAs, which can work in an unsupervised fashion. Of the models investigated, both CNNs and DBNs/DBMs are computationally demanding when it comes to training, whereas SdAs can be trained in real time under certain circumstances.", "citations": []}, {"text": "As a closing note, in spite of the promising-in some cases impressive-results that have been documented in the literature, significant challenges do remain, especially as far as the theoretical groundwork that would clearly explain the ways to define the optimal selection of model type and structure for a given task or to profoundly comprehend the reasons for which a specific architecture or algorithm is effective in a given task or not. These are among the most important issues that will continue to attract the interest of the machine learning research community in the years to come.", "citations": []}], "citations_in_section": []}, {"index": 21, "title": "Conflicts of Interest", "paragraphs": [{"text": "The authors declare that there are no conflicts of interest regarding the publication of this paper.", "citations": []}], "citations_in_section": []}, {"index": 22, "title": "Figure 2 :", "paragraphs": [], "citations_in_section": []}, {"index": 23, "title": "Figure 3 :", "paragraphs": [], "citations_in_section": []}, {"index": 24, "title": "Figure 4 :", "paragraphs": [], "citations_in_section": []}, {"index": 25, "title": "Table 2 :", "paragraphs": [], "citations_in_section": []}], "references": [{"ref_id": "b0", "matched_paper_id": 15619658, "title": "A logical calculus of the ideas immanent in nervous activity", "metadata": {"corpusId": "15619658", "paperId": "090c5a5df345ab60c41d6de02b3e366e1a27cf43", "doi": "10.1007/BF02459570", "url": "https://www.semanticscholar.org/paper/090c5a5df345ab60c41d6de02b3e366e1a27cf43", "abstract": null, "year": 1990, "referenceCount": 17, "citationCount": 15390, "influentialCitationCount": 545, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Philosophy", "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": null, "journal": {"name": "Bulletin of Mathematical Biology", "volume": "52", "issue": "", "pages": "99-115", "id": "https://openalex.org/S118940690", "h_index": 153, "i10_index": 2611, "2yr_mean_citedness": 2.4202334630350193, "is_core": true, "type": "journal"}, "authors": [{"authorId": "4605464", "name": "W. McCulloch", "hIndex": 31, "citationCount": 19197, "paperCount": 118}, {"authorId": "50314979", "name": "W. Pitts", "hIndex": 16, "citationCount": 19986, "paperCount": 27}], "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time."}, "topics": ["Advanced Algebra and Logic"], "keywords": ["Net (polyhedron)", "Logical conjunction", "Neurophysiology"], "mesh": [], "referenced_works_count": 1}, "referenced_works": ["https://openalex.org/W4298166646"]}, {"ref_id": "b1", "matched_paper_id": 2542741, "title": "Handwritten digit recognition with a back-propagation network", "metadata": {"corpusId": "2542741", "paperId": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6", "doi": "", "url": "https://www.semanticscholar.org/paper/86ab4cae682fbd49c5a5bedb630e5a40fa7529f6", "abstract": null, "year": 1989, "referenceCount": 11, "citationCount": 4007, "influentialCitationCount": 244, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "396-404", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1688882", "name": "Yann LeCun", "hIndex": 132, "citationCount": 244817, "paperCount": 405}, {"authorId": "2219581", "name": "B. Boser", "hIndex": 50, "citationCount": 37101, "paperCount": 212}, {"authorId": "1747317", "name": "J. Denker", "hIndex": 37, "citationCount": 27722, "paperCount": 95}, {"authorId": "37274089", "name": "D. Henderson", "hIndex": 17, "citationCount": 16594, "paperCount": 28}, {"authorId": "2799635", "name": "R. Howard", "hIndex": 37, "citationCount": 20561, "paperCount": 154}, {"authorId": "34859193", "name": "W. Hubbard", "hIndex": 16, "citationCount": 16829, "paperCount": 29}, {"authorId": "2041866", "name": "L. Jackel", "hIndex": 39, "citationCount": 22280, "paperCount": 130}], "tldr": {"model": "tldr@v2.0.0", "text": "Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task, and has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b2", "matched_paper_id": 1915014, "title": "Long short-term memory", "metadata": {"corpusId": "1915014", "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "doi": "10.1162/neco.1997.9.8.1735", "url": "https://www.semanticscholar.org/paper/2e9d221c206e9503ceb452302d68d10e293f2a10", "abstract": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.", "year": 1997, "referenceCount": 48, "citationCount": 87472, "influentialCitationCount": 9371, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "1997-11-01", "publicationTypes": ["JournalArticle", "Review"], "journal": {"name": "Neural Computation", "volume": "9", "issue": "", "pages": "1735-1780", "id": "https://openalex.org/S207023548", "h_index": 248, "i10_index": 2520, "2yr_mean_citedness": 2.7464788732394365, "is_core": true, "type": "journal"}, "authors": [{"authorId": "3308557", "name": "Sepp Hochreiter", "hIndex": 55, "citationCount": 125991, "paperCount": 274}, {"authorId": "145341374", "name": "J. Schmidhuber", "hIndex": 98, "citationCount": 170585, "paperCount": 466}], "tldr": {"model": "tldr@v2.0.0", "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."}, "topics": ["Neural Networks and Applications", "Domain Adaptation and Few-Shot Learning"], "keywords": [], "mesh": ["Algorithms/None", "Memory/None", "Memory, Short-Term/None", "Models, Neurological/None", "Neural Networks, Computer/None", "Learning/None", "Models, Psychological/None", "Nerve Net/physiology", "Nerve Net/None", "Time Factors/None"], "referenced_works_count": 34}, "referenced_works": ["https://openalex.org/W1674799117", "https://openalex.org/W1881179843", "https://openalex.org/W1963605035", "https://openalex.org/W1971129545", "https://openalex.org/W1971209221", "https://openalex.org/W1982291194", "https://openalex.org/W1984375561", "https://openalex.org/W2007431958", "https://openalex.org/W202296964", "https://openalex.org/W2036317923", "https://openalex.org/W2048060899", "https://openalex.org/W2057653135", "https://openalex.org/W2086756055", "https://openalex.org/W2103452139", "https://openalex.org/W2107878631", "https://openalex.org/W2111871983", "https://openalex.org/W2114471683", "https://openalex.org/W2118127772", "https://openalex.org/W2119216348", "https://openalex.org/W2121553911", "https://openalex.org/W2123716044", "https://openalex.org/W2128499899", "https://openalex.org/W2129831132", "https://openalex.org/W2131387845", "https://openalex.org/W2136939460", "https://openalex.org/W2143503258", "https://openalex.org/W2144001972", "https://openalex.org/W2146367896", "https://openalex.org/W2154890045", "https://openalex.org/W2156960699", "https://openalex.org/W2162704388", "https://openalex.org/W2165432985", "https://openalex.org/W2168934702", "https://openalex.org/W4285719527"]}, {"ref_id": "b3", "matched_paper_id": 2309950, "title": "A fast learning algorithm for deep belief nets", "metadata": {"corpusId": "2309950", "paperId": "8978cf7574ceb35f4c3096be768c7547b28a35d0", "doi": "10.1162/neco.2006.18.7.1527", "url": "https://www.semanticscholar.org/paper/8978cf7574ceb35f4c3096be768c7547b28a35d0", "abstract": "We show how to use “complementary priors” to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.", "year": 2006, "referenceCount": 39, "citationCount": 15983, "influentialCitationCount": 1198, "fieldsOfStudy": ["Computer Science", "Mathematics", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2006-07-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Neural Computation", "volume": "18", "issue": "", "pages": "1527-1554", "id": "https://openalex.org/S207023548", "h_index": 248, "i10_index": 2520, "2yr_mean_citedness": 2.7464788732394365, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}, {"authorId": "2217144", "name": "Simon Osindero", "hIndex": 34, "citationCount": 37127, "paperCount": 67}, {"authorId": "1725303", "name": "Y. Teh", "hIndex": 76, "citationCount": 46819, "paperCount": 297}], "tldr": {"model": "tldr@v2.0.0", "text": "A fast, greedy algorithm is derived that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory."}, "topics": ["Domain Adaptation and Few-Shot Learning", "Generative Adversarial Networks and Image Synthesis", "Neural Networks and Applications"], "keywords": ["Associative property", "Discriminative model", "Generative model", "Deep belief network"], "mesh": ["Algorithms/None", "Learning/physiology", "Neural Networks, Computer/None", "Neurons/physiology", "Animals/None", "Humans/None", "Learning/None", "Neurons/None"], "referenced_works_count": 31}, "referenced_works": ["https://openalex.org/W145818128", "https://openalex.org/W1802356529", "https://openalex.org/W1973419624", "https://openalex.org/W1983423683", "https://openalex.org/W1993845689", "https://openalex.org/W2004940028", "https://openalex.org/W2033272835", "https://openalex.org/W2057175746", "https://openalex.org/W2070534370", "https://openalex.org/W2077947937", "https://openalex.org/W2083380015", "https://openalex.org/W2091886411", "https://openalex.org/W2095038093", "https://openalex.org/W2101706260", "https://openalex.org/W2112796928", "https://openalex.org/W2114153178", "https://openalex.org/W2116064496", "https://openalex.org/W2124537004", "https://openalex.org/W2124914669", "https://openalex.org/W2125663122", "https://openalex.org/W2131329059", "https://openalex.org/W2131686571", "https://openalex.org/W2138448681", "https://openalex.org/W2156163116", "https://openalex.org/W2156740722", "https://openalex.org/W2158778629", "https://openalex.org/W2159080219", "https://openalex.org/W2159737176", "https://openalex.org/W2567948266", "https://openalex.org/W4240861491", "https://openalex.org/W66838807"]}, {"ref_id": "b4", "matched_paper_id": null, "title": ""}, {"ref_id": "b5", "matched_paper_id": 8180128, "title": "Theano: new features and speed improvements", "metadata": {"corpusId": "8180128", "paperId": "855d0f722d75cc56a66a00ede18ace96bafee6bd", "doi": "", "url": "https://www.semanticscholar.org/paper/855d0f722d75cc56a66a00ede18ace96bafee6bd", "abstract": "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.", "year": 2012, "referenceCount": 15, "citationCount": 1417, "influentialCitationCount": 76, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2012-11-23", "publicationTypes": ["JournalArticle"], "journal": {"name": "ArXiv", "volume": "abs/1211.5590", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3227028", "name": "Frédéric Bastien", "hIndex": 7, "citationCount": 5352, "paperCount": 10}, {"authorId": "3087941", "name": "Pascal Lamblin", "hIndex": 13, "citationCount": 13134, "paperCount": 18}, {"authorId": "1996134", "name": "Razvan Pascanu", "hIndex": 71, "citationCount": 47351, "paperCount": 178}, {"authorId": "32837403", "name": "J. Bergstra", "hIndex": 26, "citationCount": 27083, "paperCount": 43}, {"authorId": "153440022", "name": "I. Goodfellow", "hIndex": 64, "citationCount": 142902, "paperCount": 103}, {"authorId": "47944877", "name": "Arnaud Bergeron", "hIndex": 6, "citationCount": 4274, "paperCount": 8}, {"authorId": "2065828537", "name": "Nicolas Bouchard", "hIndex": 2, "citationCount": 3742, "paperCount": 2}, {"authorId": "1393680089", "name": "David Warde-Farley", "hIndex": 27, "citationCount": 50501, "paperCount": 37}, {"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}], "tldr": {"model": "tldr@v2.0.0", "text": "New features and efficiency improvements to Theano are presented, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b6", "matched_paper_id": null, "title": ""}, {"ref_id": "b7", "matched_paper_id": 11014549, "title": "DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks", "metadata": {"corpusId": "11014549", "paperId": "1a6d748365dbf3b17f2db371a30469478ee7b142", "doi": "10.1109/TPAMI.2016.2587642", "url": "https://www.semanticscholar.org/paper/1a6d748365dbf3b17f2db371a30469478ee7b142", "abstract": "In this paper, we propose deformable deep convolutional neural networks for generic object detection. This new deep learning object detection framework has innovations in multiple aspects. In the proposed new deep architecture, a new deformation constrained pooling (def-pooling) layer models the deformation of object parts with geometric constraint and penalty. A new pre-training strategy is proposed to learn feature representations more suitable for the object detection task and with good generalization capability. By changing the net structures, training strategies, adding and removing some key components in the detection pipeline, a set of models with large diversity are obtained, which significantly improves the effectiveness of model averaging. The proposed approach improves the mean averaged precision obtained by RCNN [16], which was the state-of-the-art, from 31% to 50.3% on the ILSVRC2014 detection test set. It also outperforms the winner of ILSVRC2014, GoogLeNet, by 6.1%. Detailed component-wise analysis is also provided through extensive experimental evaluation, which provides a global view for people to understand the deep learning object detection pipeline.", "year": 2017, "referenceCount": 84, "citationCount": 118, "influentialCitationCount": 2, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2017-07-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "39", "issue": "", "pages": "1320-1334", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "3001348", "name": "Wanli Ouyang", "hIndex": 91, "citationCount": 38577, "paperCount": 311}, {"authorId": "2550719", "name": "Xingyu Zeng", "hIndex": 21, "citationCount": 2864, "paperCount": 32}, {"authorId": "31843833", "name": "Xiaogang Wang", "hIndex": 127, "citationCount": 92937, "paperCount": 641}, {"authorId": "2146345714", "name": "Shi Qiu", "hIndex": 8, "citationCount": 2554, "paperCount": 13}, {"authorId": "47571885", "name": "Ping Luo", "hIndex": 64, "citationCount": 36482, "paperCount": 201}, {"authorId": "2476765", "name": "Yonglong Tian", "hIndex": 26, "citationCount": 15337, "paperCount": 43}, {"authorId": "49404547", "name": "Hongsheng Li", "hIndex": 60, "citationCount": 15268, "paperCount": 187}, {"authorId": "123363188", "name": "Shuo Yang", "hIndex": 13, "citationCount": 842, "paperCount": 48}, {"authorId": "40072288", "name": "Zhe Wang", "hIndex": 26, "citationCount": 5678, "paperCount": 41}, {"authorId": "46382329", "name": "Hongyang Li", "hIndex": 23, "citationCount": 3686, "paperCount": 31}, {"authorId": "2119043802", "name": "Kun Wang", "hIndex": 10, "citationCount": 1036, "paperCount": 16}, {"authorId": "1721677", "name": "Junjie Yan", "hIndex": 73, "citationCount": 22685, "paperCount": 150}, {"authorId": "1717179", "name": "Chen Change Loy", "hIndex": 113, "citationCount": 70830, "paperCount": 341}, {"authorId": "50295995", "name": "Xiaoou Tang", "hIndex": 132, "citationCount": 108044, "paperCount": 429}], "tldr": {"model": "tldr@v2.0.0", "text": "By changing the net structures, training strategies, adding and removing some key components in the detection pipeline, a set of models with large diversity are obtained, which significantly improves the effectiveness of model averaging."}, "topics": ["Advanced Neural Network Applications", "Human Pose and Action Recognition", "Advanced Image and Video Retrieval Techniques"], "keywords": ["Pooling", "Feature (linguistics)"], "mesh": [], "referenced_works_count": 84}, "referenced_works": ["https://openalex.org/W1516887802", "https://openalex.org/W1517303303", "https://openalex.org/W1524680991", "https://openalex.org/W1536680647", "https://openalex.org/W1560380655", "https://openalex.org/W1686810756", "https://openalex.org/W1799366690", "https://openalex.org/W1832500336", "https://openalex.org/W1861492603", "https://openalex.org/W1896395893", "https://openalex.org/W1899185266", "https://openalex.org/W1942214758", "https://openalex.org/W1960182310", "https://openalex.org/W1960289438", "https://openalex.org/W1970183457", "https://openalex.org/W1976948919", "https://openalex.org/W1977470347", "https://openalex.org/W1980163762", "https://openalex.org/W1986460963", "https://openalex.org/W1986905809", "https://openalex.org/W1987118352", "https://openalex.org/W1994529670", "https://openalex.org/W1996478295", "https://openalex.org/W1998808035", "https://openalex.org/W2010340098", "https://openalex.org/W2013640163", "https://openalex.org/W2024665880", "https://openalex.org/W2028742349", "https://openalex.org/W2030536784", "https://openalex.org/W2031489346", "https://openalex.org/W2037511607", "https://openalex.org/W2046589395", "https://openalex.org/W2049705550", "https://openalex.org/W2052355211", "https://openalex.org/W2056025798", "https://openalex.org/W2062118960", "https://openalex.org/W2077493928", "https://openalex.org/W2083896825", "https://openalex.org/W2084997728", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2110226160", "https://openalex.org/W2117539524", "https://openalex.org/W2123099218", "https://openalex.org/W2129305389", "https://openalex.org/W2133444763", "https://openalex.org/W2134670479", "https://openalex.org/W2136579260", "https://openalex.org/W2141357020", "https://openalex.org/W2141364309", "https://openalex.org/W2142037471", "https://openalex.org/W2143352446", "https://openalex.org/W2150385913", "https://openalex.org/W2151454023", "https://openalex.org/W2152945944", "https://openalex.org/W2155541015", "https://openalex.org/W2155893237", "https://openalex.org/W2156547346", "https://openalex.org/W2161106546", "https://openalex.org/W2161969291", "https://openalex.org/W2163605009", "https://openalex.org/W2166127773", "https://openalex.org/W2168356304", "https://openalex.org/W2179352600", "https://openalex.org/W2201245532", "https://openalex.org/W2206858481", "https://openalex.org/W2295594159", "https://openalex.org/W2464305746", "https://openalex.org/W2469885745", "https://openalex.org/W2535410496", "https://openalex.org/W2555176855", "https://openalex.org/W2613718673", "https://openalex.org/W2962851944", "https://openalex.org/W2963037989", "https://openalex.org/W2963173190", "https://openalex.org/W2963542991", "https://openalex.org/W2963690996", "https://openalex.org/W2963996492", "https://openalex.org/W345900524", "https://openalex.org/W4294375521", "https://openalex.org/W56385144", "https://openalex.org/W639708223", "https://openalex.org/W7746136", "https://openalex.org/W94414152"]}, {"ref_id": "b8", "matched_paper_id": 12221270, "title": "Weakly Supervised Cascaded Convolutional Networks", "metadata": {"corpusId": "12221270", "paperId": "804eecda772857604566935070b6d3d8644b628e", "doi": "10.1109/CVPR.2017.545", "url": "https://www.semanticscholar.org/paper/804eecda772857604566935070b6d3d8644b628e", "abstract": "Object detection is a challenging task in visual understanding domain, and even more so if the supervision is to be weak. Recently, few efforts to handle the task without expensive human annotations is established by promising deep neural network. A new architecture of cascaded networks is proposed to learn a convolutional neural network (CNN) under such conditions. We introduce two such architectures, with either two cascade stages or three which are trained in an end-to-end pipeline. The first stage of both architectures extracts best candidate of class specific region proposals by training a fully convolutional network. In the case of the three stage architecture, the middle stage provides object segmentation, using the output of the activation maps of first stage. The final stage of both architectures is a part of a convolutional neural network that performs multiple instance learning on proposals extracted in the previous stage(s). Our experiments on the PASCAL VOC 2007, 2010, 2012 and large scale object datasets, ILSVRC 2013, 2014 datasets show improvements in the areas of weakly-supervised object detection, classification and localization.", "year": 2016, "referenceCount": 40, "citationCount": 296, "influentialCitationCount": 38, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2016-11-24", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "5131-5139", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3310120", "name": "Ali Diba", "hIndex": 19, "citationCount": 2406, "paperCount": 50}, {"authorId": "50633800", "name": "Vivek Sharma", "hIndex": 21, "citationCount": 2074, "paperCount": 53}, {"authorId": "3451338", "name": "A. Pazandeh", "hIndex": 4, "citationCount": 424, "paperCount": 4}, {"authorId": "2367683", "name": "H. Pirsiavash", "hIndex": 37, "citationCount": 9544, "paperCount": 91}, {"authorId": "1681236", "name": "L. Gool", "hIndex": 179, "citationCount": 170276, "paperCount": 1531}], "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces two new architecture of cascaded networks, with either two cascade stages or three which are trained in an end-to-end pipeline to learn a convolutional neural network (CNN) under such conditions."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Pascal (unit)"], "mesh": [], "referenced_works_count": 41}, "referenced_works": ["https://openalex.org/W1536680647", "https://openalex.org/W1575299770", "https://openalex.org/W1586079445", "https://openalex.org/W1686810756", "https://openalex.org/W1783315696", "https://openalex.org/W1866072925", "https://openalex.org/W1934621328", "https://openalex.org/W1952794764", "https://openalex.org/W1963882359", "https://openalex.org/W1994488211", "https://openalex.org/W2020477327", "https://openalex.org/W2088049833", "https://openalex.org/W2099528205", "https://openalex.org/W2106841609", "https://openalex.org/W2108598243", "https://openalex.org/W2112343299", "https://openalex.org/W2121056381", "https://openalex.org/W2128715914", "https://openalex.org/W2132984949", "https://openalex.org/W2133324800", "https://openalex.org/W2147347568", "https://openalex.org/W2155893237", "https://openalex.org/W2161381512", "https://openalex.org/W2163605009", "https://openalex.org/W2168356304", "https://openalex.org/W2168912077", "https://openalex.org/W2179352600", "https://openalex.org/W2186827065", "https://openalex.org/W2295107390", "https://openalex.org/W2441255125", "https://openalex.org/W2613718673", "https://openalex.org/W2952072685", "https://openalex.org/W2962762541", "https://openalex.org/W2962835968", "https://openalex.org/W2963603913", "https://openalex.org/W3106250896", "https://openalex.org/W318792885", "https://openalex.org/W4252558448", "https://openalex.org/W611457968", "https://openalex.org/W639708223", "https://openalex.org/W7746136"]}, {"ref_id": "b9", "matched_paper_id": 28081849, "title": "FAST-MDL: Fast Adaptive Supervised Training of multi-layered deep learning models for consistent object tracking and classification", "metadata": {"corpusId": "28081849", "paperId": "fbcca6c416bce787a605ec0169d4196a0f5e93ec", "doi": "10.1109/IST.2016.7738244", "url": "https://www.semanticscholar.org/paper/fbcca6c416bce787a605ec0169d4196a0f5e93ec", "abstract": "In this paper, we propose a Fast Adaptive Supervised Training Algorithm, called FAST-MDL, for dynamically updating the parameters of a multi-layered deep learning structure in order to fit the current environmental conditions. The method provides promising results in consistent long term object labeling and detection under abruptly changing visual conditions, severe illumination changes and occlusions (either full or partial). The retraining algorithm trusts as much as possible the current conditions (discriminative constraints), while simultaneously providing a minimal modification of the already obtained knowledge of the network (generative constraints). Experimental results in real-life video sequences demonstrate the efficiency of the proposed method compared to existing techniques.", "year": 2016, "referenceCount": 28, "citationCount": 32, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2016-10-01", "publicationTypes": ["Conference"], "journal": {"name": "2016 IEEE International Conference on Imaging Systems and Techniques (IST)", "volume": "", "issue": "", "pages": "318-323", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "120205775", "name": "N. Doulamis", "hIndex": 45, "citationCount": 10014, "paperCount": 454}, {"authorId": "2594647", "name": "A. Voulodimos", "hIndex": 30, "citationCount": 5323, "paperCount": 160}], "tldr": {"model": "tldr@v2.0.0", "text": "The proposed Fast Adaptive Supervised Training Algorithm, called FAST-MDL, provides promising results in consistent long term object labeling and detection under abruptly changing visual conditions, severe illumination changes and occlusions."}, "topics": ["Video Surveillance and Tracking Methods", "Human Pose and Action Recognition", "Image Enhancement Techniques"], "keywords": ["Discriminative model", "Retraining", "Minimum description length"], "mesh": [], "referenced_works_count": 19}, "referenced_works": ["https://openalex.org/W1412306085", "https://openalex.org/W1964395255", "https://openalex.org/W1980163762", "https://openalex.org/W1983364832", "https://openalex.org/W1988115241", "https://openalex.org/W2034276366", "https://openalex.org/W2036021121", "https://openalex.org/W2099866409", "https://openalex.org/W2100495367", "https://openalex.org/W2110226160", "https://openalex.org/W2139427956", "https://openalex.org/W2152396391", "https://openalex.org/W2153410696", "https://openalex.org/W2162741153", "https://openalex.org/W2163922914", "https://openalex.org/W2168117308", "https://openalex.org/W2169066052", "https://openalex.org/W2182924040", "https://openalex.org/W2295320150"]}, {"ref_id": "b10", "matched_paper_id": 5046657, "title": "Adaptable deep learning structures for object labeling/tracking under dynamic visual environments", "metadata": {"corpusId": "5046657", "paperId": "3bbc2928f7f6a0005a10d49ff4f4ec271fbaa2aa", "doi": "10.1007/s11042-017-5349-7", "url": "https://www.semanticscholar.org/paper/3bbc2928f7f6a0005a10d49ff4f4ec271fbaa2aa", "abstract": null, "year": 2018, "referenceCount": 55, "citationCount": 15, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2018-04-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Multimedia Tools and Applications", "volume": "77", "issue": "", "pages": "9651-9689", "id": "https://openalex.org/S110206669", "h_index": 134, "i10_index": 7247, "2yr_mean_citedness": 3.9574852265265923, "is_core": true, "type": "journal"}, "authors": [{"authorId": "120205775", "name": "N. Doulamis", "hIndex": 45, "citationCount": 10014, "paperCount": 454}], "tldr": {"model": "tldr@v2.0.0", "text": "The results indicates that the self-adaptive deep neural network architecture is able to correctly label and separate foreground objects from background even under severe visual changes, such as occlusion, illumination variations and change of camera views, and within real time computational constraints."}, "topics": ["Video Surveillance and Tracking Methods", "3D Surveying and Cultural Heritage", "Visual Attention and Saliency Detection"], "keywords": ["Discriminative model", "Generative model"], "mesh": [], "referenced_works_count": 53}, "referenced_works": ["https://openalex.org/W1586730761", "https://openalex.org/W1925745898", "https://openalex.org/W1964395255", "https://openalex.org/W1966580635", "https://openalex.org/W1980163762", "https://openalex.org/W1983364832", "https://openalex.org/W2021344326", "https://openalex.org/W2025768430", "https://openalex.org/W2034085526", "https://openalex.org/W2035424729", "https://openalex.org/W2048997502", "https://openalex.org/W2056828588", "https://openalex.org/W2056877710", "https://openalex.org/W2066377255", "https://openalex.org/W2072072671", "https://openalex.org/W2098638146", "https://openalex.org/W2099866409", "https://openalex.org/W2100495367", "https://openalex.org/W2100770139", "https://openalex.org/W2102625004", "https://openalex.org/W2102765684", "https://openalex.org/W2112538708", "https://openalex.org/W2112796928", "https://openalex.org/W2121281594", "https://openalex.org/W2125515328", "https://openalex.org/W2130103520", "https://openalex.org/W2130325614", "https://openalex.org/W2134905716", "https://openalex.org/W2139427956", "https://openalex.org/W2140833774", "https://openalex.org/W2147768505", "https://openalex.org/W2153715347", "https://openalex.org/W2158816371", "https://openalex.org/W2158899491", "https://openalex.org/W2161591461", "https://openalex.org/W2162741153", "https://openalex.org/W2163922914", "https://openalex.org/W2165720259", "https://openalex.org/W2167089254", "https://openalex.org/W2167608136", "https://openalex.org/W2168117308", "https://openalex.org/W2170865122", "https://openalex.org/W2293078015", "https://openalex.org/W2295320150", "https://openalex.org/W2401070136", "https://openalex.org/W2401619634", "https://openalex.org/W2546302380", "https://openalex.org/W2550564506", "https://openalex.org/W2765158272", "https://openalex.org/W2971913558", "https://openalex.org/W3215393340", "https://openalex.org/W4285719527", "https://openalex.org/W73684747"]}, {"ref_id": "b11", "matched_paper_id": 15158546, "title": "A deep structured model with radius-margin bound for 3D human activity recognition", "metadata": {"corpusId": "15158546", "paperId": "e64bfcc3c8c384dee854a1c73a4a2e66f8cd00d7", "doi": "10.1007/s11263-015-0876-z", "url": "https://www.semanticscholar.org/paper/e64bfcc3c8c384dee854a1c73a4a2e66f8cd00d7", "abstract": "Understanding human activity is very challenging even with the recently developed 3D/depth sensors. To solve this problem, this work investigates a novel deep structured model, which adaptively decomposes an activity instance into temporal parts using the convolutional neural networks. Our model advances the traditional deep learning approaches in two aspects. First, we incorporate latent temporal structure into the deep model, accounting for large temporal variations of diverse human activities. In particular, we utilize the latent variables to decompose the input activity into a number of temporally segmented sub-activities, and accordingly feed them into the parts (i.e. sub-networks) of the deep architecture. Second, we incorporate a radius–margin bound as a regularization term into our deep model, which effectively improves the generalization performance for classification. For model training, we propose a principled learning algorithm that iteratively (i) discovers the optimal latent variables (i.e. the ways of activity decomposition) for all training instances, (ii) updates the classifiers based on the generated features, and (iii) updates the parameters of multi-layer neural networks. In the experiments, our approach is validated on several complex scenarios for human activity recognition and demonstrates superior performances over other state-of-the-art approaches.", "year": 2015, "referenceCount": 58, "citationCount": 102, "influentialCitationCount": 7, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-12-05", "publicationTypes": ["JournalArticle"], "journal": {"name": "International Journal of Computer Vision", "volume": "118", "issue": "", "pages": "256 - 273", "id": "https://openalex.org/S25538012", "h_index": 283, "i10_index": 2338, "2yr_mean_citedness": 10.77304964539007, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2110901865", "name": "Liang Lin", "hIndex": 16, "citationCount": 2118, "paperCount": 35}, {"authorId": "3170394", "name": "Keze Wang", "hIndex": 19, "citationCount": 2166, "paperCount": 45}, {"authorId": "1724520", "name": "W. Zuo", "hIndex": 97, "citationCount": 52316, "paperCount": 571}, {"authorId": "39872583", "name": "M. Wang", "hIndex": 93, "citationCount": 42091, "paperCount": 1815}, {"authorId": "33642939", "name": "Jiebo Luo", "hIndex": 97, "citationCount": 40384, "paperCount": 706}, {"authorId": "36685537", "name": "Lei Zhang", "hIndex": 108, "citationCount": 54595, "paperCount": 369}], "tldr": {"model": "tldr@v2.0.0", "text": "A novel deep structured model, which adaptively decomposes an activity instance into temporal parts using the convolutional neural networks, and incorporates latent temporal structure into the deep model, accounting for large temporal variations of diverse human activities."}, "topics": ["Human Pose and Action Recognition", "Context-Aware Activity Recognition Systems", "Anomaly Detection Techniques and Applications"], "keywords": ["Margin (machine learning)", "Regularization", "Activity Recognition"], "mesh": [], "referenced_works_count": 64}, "referenced_works": ["https://openalex.org/W1752482607", "https://openalex.org/W1895641373", "https://openalex.org/W1947481528", "https://openalex.org/W1975325338", "https://openalex.org/W1983364832", "https://openalex.org/W1985912834", "https://openalex.org/W1992681465", "https://openalex.org/W1993164181", "https://openalex.org/W1994205671", "https://openalex.org/W2002585172", "https://openalex.org/W2008824967", "https://openalex.org/W2009038235", "https://openalex.org/W2012451022", "https://openalex.org/W2016053056", "https://openalex.org/W2017695267", "https://openalex.org/W2020719522", "https://openalex.org/W2045792079", "https://openalex.org/W2052916967", "https://openalex.org/W2053742104", "https://openalex.org/W2058256495", "https://openalex.org/W2063153269", "https://openalex.org/W2064052975", "https://openalex.org/W2071730211", "https://openalex.org/W2084997728", "https://openalex.org/W2085735683", "https://openalex.org/W2095569536", "https://openalex.org/W2095705004", "https://openalex.org/W2099680562", "https://openalex.org/W2099972257", "https://openalex.org/W2100495367", "https://openalex.org/W2102605133", "https://openalex.org/W2103959632", "https://openalex.org/W2108333036", "https://openalex.org/W2112504244", "https://openalex.org/W2114216982", "https://openalex.org/W2115701093", "https://openalex.org/W2132734311", "https://openalex.org/W2136036867", "https://openalex.org/W2137275576", "https://openalex.org/W2139857301", "https://openalex.org/W2142258645", "https://openalex.org/W2143267104", "https://openalex.org/W2143352446", "https://openalex.org/W2145546283", "https://openalex.org/W2146055337", "https://openalex.org/W2148603752", "https://openalex.org/W2153410696", "https://openalex.org/W2154579312", "https://openalex.org/W2158001550", "https://openalex.org/W2160144863", "https://openalex.org/W2162415752", "https://openalex.org/W2162670331", "https://openalex.org/W2162741153", "https://openalex.org/W2163395651", "https://openalex.org/W2163605009", "https://openalex.org/W2168356304", "https://openalex.org/W2308045930", "https://openalex.org/W2404218691", "https://openalex.org/W2949966521", "https://openalex.org/W2963602979", "https://openalex.org/W2964241990", "https://openalex.org/W3099037876", "https://openalex.org/W3102322242", "https://openalex.org/W4205969993"]}, {"ref_id": "b12", "matched_paper_id": 32942438, "title": "Exploring deep learning based solutions in fine grained activity recognition in the wild", "metadata": {"corpusId": "32942438", "paperId": "1dabb080e3e968633f4b3774f19192f8378f5b67", "doi": "10.1109/ICPR.2016.7899664", "url": "https://www.semanticscholar.org/paper/1dabb080e3e968633f4b3774f19192f8378f5b67", "abstract": "In this paper, we explore the usage of deep learning based solutions in fine grained activity recognition in the wild. As a powerful tool, deep learning has been widely used in image classification, object detection and activity recognition. We focus on implementing deep learning methods into the more complicated fine grained activity recognition problems. We test our solutions on MPII activity dataset with 410 activities. We find that due to the challenges of large intra class variances, small inter class variances, and limited training samples per activity, the classical two stream deep ConvNets method does not perform that well for fine grained activity recognition. Observing these issues, we propose a solution to directly use deep features learned from ImageNet in an SVM. In experiments, we achieve a 20 percent improvement compared to the classical two stream deep ConvNets solutions, on MPII fine grained activity challenge videos.", "year": 2016, "referenceCount": 30, "citationCount": 23, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2016-12-01", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2016 23rd International Conference on Pattern Recognition (ICPR)", "volume": "", "issue": "", "pages": "384-389", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "49409536", "name": "Song Cao", "hIndex": 7, "citationCount": 324, "paperCount": 13}, {"authorId": "144862593", "name": "R. Nevatia", "hIndex": 84, "citationCount": 26490, "paperCount": 341}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a solution to directly use deep features learned from ImageNet in an SVM, which achieves a 20 percent improvement compared to the classical two stream deep ConvNets solutions, on MPII fine grained activity challenge videos."}, "topics": ["Human Pose and Action Recognition", "Anomaly Detection Techniques and Applications", "Context-Aware Activity Recognition Systems"], "keywords": ["Activity Recognition"], "mesh": [], "referenced_works_count": 31}, "referenced_works": ["https://openalex.org/W1511568086", "https://openalex.org/W1864464506", "https://openalex.org/W1998605630", "https://openalex.org/W2019660985", "https://openalex.org/W2020163092", "https://openalex.org/W2036502167", "https://openalex.org/W2046589395", "https://openalex.org/W2064851185", "https://openalex.org/W2080873731", "https://openalex.org/W2110765924", "https://openalex.org/W2112053844", "https://openalex.org/W2122686738", "https://openalex.org/W2126574503", "https://openalex.org/W2126579184", "https://openalex.org/W2130843763", "https://openalex.org/W2133728753", "https://openalex.org/W2139117248", "https://openalex.org/W2142194269", "https://openalex.org/W2142900973", "https://openalex.org/W2151214862", "https://openalex.org/W2156303437", "https://openalex.org/W2158076255", "https://openalex.org/W2163273012", "https://openalex.org/W2163292664", "https://openalex.org/W2213241010", "https://openalex.org/W24089286", "https://openalex.org/W2535410496", "https://openalex.org/W2963173190", "https://openalex.org/W410625161", "https://openalex.org/W64813323", "https://openalex.org/W787785461"]}, {"ref_id": "b13", "matched_paper_id": 206592152, "title": "DeepPose: Human pose estimation via deep neural networks", "metadata": {"corpusId": "206592152", "paperId": "2a002ce457f7ab3088fbd2691734f1ce79f750c4", "doi": "10.1109/CVPR.2014.214", "url": "https://www.semanticscholar.org/paper/2a002ce457f7ab3088fbd2691734f1ce79f750c4", "abstract": "We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regres- sors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formula- tion which capitalizes on recent advances in Deep Learn- ing. We present a detailed empirical analysis with state-of- art or better performance on four academic benchmarks of diverse real-world images.", "year": 2013, "referenceCount": 28, "citationCount": 2714, "influentialCitationCount": 157, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-12-16", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2014 IEEE Conference on Computer Vision and Pattern Recognition", "volume": "", "issue": "", "pages": "1653-1660", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1726415", "name": "Alexander Toshev", "hIndex": 33, "citationCount": 19828, "paperCount": 53}, {"authorId": "2574060", "name": "Christian Szegedy", "hIndex": 28, "citationCount": 194285, "paperCount": 50}], "tldr": {"model": "tldr@v2.0.0", "text": "The pose estimation is formulated as a DNN-based regression problem towards body joints and a cascade of such DNN regres- sors which results in high precision pose estimates."}, "topics": ["Human Pose and Action Recognition", "Gait Recognition and Analysis", "Hand Gesture Recognition Systems"], "keywords": ["Deep Neural Networks"], "mesh": [], "referenced_works_count": 25}, "referenced_works": ["https://openalex.org/W1551519658", "https://openalex.org/W171061157", "https://openalex.org/W1975961009", "https://openalex.org/W1976948919", "https://openalex.org/W1994529670", "https://openalex.org/W2009647132", "https://openalex.org/W2022699039", "https://openalex.org/W2030536784", "https://openalex.org/W2045798786", "https://openalex.org/W2057204268", "https://openalex.org/W2095989672", "https://openalex.org/W2097151019", "https://openalex.org/W2102605133", "https://openalex.org/W2103015390", "https://openalex.org/W2105990640", "https://openalex.org/W2118931255", "https://openalex.org/W2128271252", "https://openalex.org/W2131263044", "https://openalex.org/W2135533529", "https://openalex.org/W2143478373", "https://openalex.org/W2146502635", "https://openalex.org/W2152926413", "https://openalex.org/W2163605009", "https://openalex.org/W2166440240", "https://openalex.org/W2405601855"]}, {"ref_id": "b14", "matched_paper_id": 6619926, "title": "Articulated pose estimation by a graphical model with image dependent pairwise relations", "metadata": {"corpusId": "6619926", "paperId": "ed9a133865295aee70c62f8764a904be0498350e", "doi": "", "url": "https://www.semanticscholar.org/paper/ed9a133865295aee70c62f8764a904be0498350e", "abstract": "We present a method for estimating articulated human pose from a single static image based on a graphical model with novel pairwise relations that make adaptive use of local image measurements. More precisely, we specify a graphical model for human pose which exploits the fact the local image measurements can be used both to detect parts (or joints) and also to predict the spatial relationships between them (Image Dependent Pairwise Relations). These spatial relationships are represented by a mixture model. We use Deep Convolutional Neural Networks (DCNNs) to learn conditional probabilities for the presence of parts and their spatial relationships within image patches. Hence our model combines the representational flexibility of graphical models with the efficiency and statistical power of DCNNs. Our method significantly outperforms the state of the art methods on the LSP and FLIC datasets and also performs very well on the Buffy dataset without any training.", "year": 2014, "referenceCount": 28, "citationCount": 507, "influentialCitationCount": 67, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-07-12", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "1736-1744", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "48283662", "name": "Xianjie Chen", "hIndex": 8, "citationCount": 3511, "paperCount": 13}, {"authorId": "145081362", "name": "A. Yuille", "hIndex": 125, "citationCount": 94360, "paperCount": 758}], "tldr": {"model": "tldr@v2.0.0", "text": "This work specifies a graphical model for human pose which exploits the fact the local image measurements can be used both to detect parts (or joints) and also to predict the spatial relationships between them (Image Dependent Pairwise Relations)."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b15", "matched_paper_id": 623137, "title": "Learning deconvolution network for semantic segmentation", "metadata": {"corpusId": "623137", "paperId": "cf986bfe13a24d4739f95df3a856a3c6e4ed4c1c", "doi": "10.1109/ICCV.2015.178", "url": "https://www.semanticscholar.org/paper/cf986bfe13a24d4739f95df3a856a3c6e4ed4c1c", "abstract": "We propose a novel semantic segmentation algorithm by learning a deep deconvolution network. We learn the network on top of the convolutional layers adopted from VGG 16-layer net. The deconvolution network is composed of deconvolution and unpooling layers, which identify pixelwise class labels and predict segmentation masks. We apply the trained network to each proposal in an input image, and construct the final semantic segmentation map by combining the results from all proposals in a simple manner. The proposed algorithm mitigates the limitations of the existing methods based on fully convolutional networks by integrating deep deconvolution network and proposal-wise prediction, our segmentation method typically identifies detailed structures and handles objects in multiple scales naturally. Our network demonstrates outstanding performance in PASCAL VOC 2012 dataset, and we achieve the best accuracy (72.5%) among the methods trained without using Microsoft COCO dataset through ensemble with the fully convolutional network.", "year": 2015, "referenceCount": 31, "citationCount": 4131, "influentialCitationCount": 259, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-05-17", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE International Conference on Computer Vision (ICCV)", "volume": "", "issue": "", "pages": "1520-1528", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2018393", "name": "Hyeonwoo Noh", "hIndex": 13, "citationCount": 6111, "paperCount": 15}, {"authorId": "2241528", "name": "Seunghoon Hong", "hIndex": 25, "citationCount": 8580, "paperCount": 46}, {"authorId": "40030651", "name": "Bohyung Han", "hIndex": 54, "citationCount": 18354, "paperCount": 155}], "tldr": {"model": "tldr@v2.0.0", "text": "A novel semantic segmentation algorithm by learning a deep deconvolution network on top of the convolutional layers adopted from VGG 16-layer net, which demonstrates outstanding performance in PASCAL VOC 2012 dataset."}, "topics": ["Advanced Neural Network Applications", "Multimodal Machine Learning Applications", "Advanced Image and Video Retrieval Techniques"], "keywords": ["Pascal (unit)", "Convolution (computer science)"], "mesh": [], "referenced_works_count": 33}, "referenced_works": ["https://openalex.org/W1495267108", "https://openalex.org/W1507506748", "https://openalex.org/W1529410181", "https://openalex.org/W1686810756", "https://openalex.org/W1836465849", "https://openalex.org/W1849277567", "https://openalex.org/W1854404533", "https://openalex.org/W1893585201", "https://openalex.org/W1903029394", "https://openalex.org/W1923115158", "https://openalex.org/W1923697677", "https://openalex.org/W1938976761", "https://openalex.org/W1948751323", "https://openalex.org/W1961881037", "https://openalex.org/W1983364832", "https://openalex.org/W2022508996", "https://openalex.org/W2031489346", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2108598243", "https://openalex.org/W2141200610", "https://openalex.org/W2144794286", "https://openalex.org/W2155893237", "https://openalex.org/W2156303437", "https://openalex.org/W2161236525", "https://openalex.org/W2163605009", "https://openalex.org/W2293220651", "https://openalex.org/W2952793010", "https://openalex.org/W2962835968", "https://openalex.org/W360623563", "https://openalex.org/W4239072543", "https://openalex.org/W586034241", "https://openalex.org/W7746136"]}, {"ref_id": "b16", "matched_paper_id": 1629541, "title": "Fully convolutional networks for semantic segmentation", "metadata": {"corpusId": "1629541", "paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "doi": "10.1109/CVPR.2015.7298965", "url": "https://www.semanticscholar.org/paper/6fc6803df5f9ae505cae5b2f178ade4062c768d0", "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build \"fully convolutional\" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.", "year": 2014, "referenceCount": 69, "citationCount": 36819, "influentialCitationCount": 4282, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-11-14", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "3431-3440", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1782282", "name": "Evan Shelhamer", "hIndex": 22, "citationCount": 58140, "paperCount": 45}, {"authorId": "2117314646", "name": "Jonathan Long", "hIndex": 7, "citationCount": 53408, "paperCount": 10}, {"authorId": "1753210", "name": "Trevor Darrell", "hIndex": 149, "citationCount": 201432, "paperCount": 630}], "tldr": {"model": "tldr@v2.0.0", "text": "The key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning."}, "topics": ["Advanced Neural Network Applications", "Domain Adaptation and Few-Shot Learning", "Multimodal Machine Learning Applications"], "keywords": ["Pascal (unit)"], "mesh": [], "referenced_works_count": 50}, "referenced_works": ["https://openalex.org/W125693051", "https://openalex.org/W1507506748", "https://openalex.org/W1542723449", "https://openalex.org/W1546771929", "https://openalex.org/W1565402342", "https://openalex.org/W1663973292", "https://openalex.org/W1686810756", "https://openalex.org/W1842610785", "https://openalex.org/W1849277567", "https://openalex.org/W1923115158", "https://openalex.org/W1948751323", "https://openalex.org/W1984757472", "https://openalex.org/W2022508996", "https://openalex.org/W2037227137", "https://openalex.org/W2067912884", "https://openalex.org/W2090518410", "https://openalex.org/W2092985495", "https://openalex.org/W2097117768", "https://openalex.org/W2100921332", "https://openalex.org/W2102605133", "https://openalex.org/W2115755118", "https://openalex.org/W2125215748", "https://openalex.org/W2128237624", "https://openalex.org/W2136391815", "https://openalex.org/W2137278143", "https://openalex.org/W2144794286", "https://openalex.org/W2147800946", "https://openalex.org/W2154644822", "https://openalex.org/W2154815154", "https://openalex.org/W2155541015", "https://openalex.org/W2155893237", "https://openalex.org/W2158778629", "https://openalex.org/W2163605009", "https://openalex.org/W2166559794", "https://openalex.org/W2167510172", "https://openalex.org/W2171740948", "https://openalex.org/W2179352600", "https://openalex.org/W2186094539", "https://openalex.org/W2594639291", "https://openalex.org/W2914484425", "https://openalex.org/W2950179405", "https://openalex.org/W2951234442", "https://openalex.org/W2952422028", "https://openalex.org/W2962835968", "https://openalex.org/W2963542991", "https://openalex.org/W4238404964", "https://openalex.org/W4294375521", "https://openalex.org/W4919037", "https://openalex.org/W56385144", "https://openalex.org/W78159342"]}, {"ref_id": "b17", "matched_paper_id": 17055992, "title": "Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex", "metadata": {"corpusId": "17055992", "paperId": "6b4fe4aa4d66fecc7b2869569002714d91d0b3f7", "doi": "10.1113/jphysiol.1962.sp006837", "url": "https://www.semanticscholar.org/paper/6b4fe4aa4d66fecc7b2869569002714d91d0b3f7", "abstract": "What chiefly distinguishes cerebral cortex from other parts of the central nervous system is the great diversity of its cell types and interconnexions. It would be astonishing if such a structure did not profoundly modify the response patterns of fibres coming into it. In the cat's visual cortex, the receptive field arrangements of single cells suggest that there is indeed a degree of complexity far exceeding anything yet seen at lower levels in the visual system. In a previous paper we described receptive fields of single cortical cells, observing responses to spots of light shone on one or both retinas (Hubel & Wiesel, 1959). In the present work this method is used to examine receptive fields of a more complex type (Part I) and to make additional observations on binocular interaction (Part II). This approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours. In the past, the technique of recording evoked slow waves has been used with great success in studies of functional anatomy. It was employed by Talbot & Marshall (1941) and by Thompson, Woolsey & Talbot (1950) for mapping out the visual cortex in the rabbit, cat, and monkey. Daniel & Whitteiidge (1959) have recently extended this work in the primate. Most of our present knowledge of retinotopic projections, binocular overlap, and the second visual area is based on these investigations. Yet the method of evoked potentials is valuable mainly for detecting behaviour common to large populations of neighbouring cells; it cannot differentiate functionally between areas of cortex smaller than about 1 mm2. To overcome this difficulty a method has in recent years been developed for studying cells separately or in small groups during long micro-electrode penetrations through nervous tissue. Responses are correlated with cell location by reconstructing the electrode tracks from histological material. These techniques have been applied to", "year": 1962, "referenceCount": 33, "citationCount": 13441, "influentialCitationCount": 525, "fieldsOfStudy": ["Medicine", "Psychology"], "s2FieldsOfStudy": [{"category": "Medicine", "source": "external"}, {"category": "Psychology", "source": "external"}, {"category": "Biology", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle"], "journal": {"name": "The Journal of Physiology", "volume": "160", "issue": "", "pages": "", "id": "https://openalex.org/S2090548", "h_index": 478, "i10_index": 30410, "2yr_mean_citedness": 3.0454086781029264, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2334226", "name": "D. Hubel", "hIndex": 64, "citationCount": 68740, "paperCount": 146}, {"authorId": "2629471", "name": "T. Wiesel", "hIndex": 62, "citationCount": 67773, "paperCount": 116}], "tldr": {"model": "tldr@v2.0.0", "text": "This method is used to examine receptive fields of a more complex type and to make additional observations on binocular interaction and this approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours."}, "topics": ["Visual perception and processing mechanisms", "Neurobiology and Insect Physiology Research", "Neural dynamics and brain function"], "keywords": [], "mesh": ["Cerebral Cortex/physiology", "Visual Cortex/None", "Animals/None", "Cats/None", "Cerebral Cortex/None"], "referenced_works_count": 19}, "referenced_works": ["https://openalex.org/W1973430742", "https://openalex.org/W2010554296", "https://openalex.org/W2030753578", "https://openalex.org/W2037316494", "https://openalex.org/W2059829044", "https://openalex.org/W2085219660", "https://openalex.org/W2091522422", "https://openalex.org/W2103212315", "https://openalex.org/W2110121211", "https://openalex.org/W2111624873", "https://openalex.org/W2126750729", "https://openalex.org/W2136325353", "https://openalex.org/W2166025442", "https://openalex.org/W2167424526", "https://openalex.org/W2212384750", "https://openalex.org/W2253776861", "https://openalex.org/W2418648566", "https://openalex.org/W2418763445", "https://openalex.org/W2469564089"]}, {"ref_id": "b18", "matched_paper_id": 206775608, "title": "Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "metadata": {"corpusId": "206775608", "paperId": "69e68bfaadf2dccff800158749f5a50fe82d173b", "doi": "10.1007/BF00344251", "url": "https://www.semanticscholar.org/paper/69e68bfaadf2dccff800158749f5a50fe82d173b", "abstract": null, "year": 1980, "referenceCount": 17, "citationCount": 4664, "influentialCitationCount": 228, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "1980-04-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Biological Cybernetics", "volume": "36", "issue": "", "pages": "193-202", "id": "https://openalex.org/S87357125", "h_index": 204, "i10_index": 2899, "2yr_mean_citedness": 1.7692307692307692, "is_core": true, "type": "journal"}, "authors": [{"authorId": "3160228", "name": "K. Fukushima", "hIndex": 24, "citationCount": 11342, "paperCount": 143}], "tldr": {"model": "tldr@v2.0.0", "text": "A neural network model for a mechanism of visual pattern recognition that is self-organized by “learning without a teacher”, and acquires an ability to recognize stimulus patterns based on the geometrical similarity of their shapes without affected by their positions."}, "topics": ["Neural dynamics and brain function", "Visual perception and processing mechanisms", "Neural Networks and Applications"], "keywords": ["Neocognitron", "Stimulus (psychology)", "Hypercomplex number", "Lateral inhibition"], "mesh": ["Form Perception/None", "Learning/physiology", "Models, Neurological/None", "Nerve Net/physiology", "Nervous System Physiological Phenomena/None", "Pattern Recognition, Visual/None", "Cognition/physiology", "Cognition/None", "Computers/None", "Learning/None", "Nerve Net/None"], "referenced_works_count": 13}, "referenced_works": ["https://openalex.org/W1483166444", "https://openalex.org/W1594551768", "https://openalex.org/W2010315761", "https://openalex.org/W201165979", "https://openalex.org/W2053120614", "https://openalex.org/W2091546412", "https://openalex.org/W2116360511", "https://openalex.org/W2272360941", "https://openalex.org/W22889343", "https://openalex.org/W2313924934", "https://openalex.org/W2322002063", "https://openalex.org/W2324189819", "https://openalex.org/W4285719527"]}, {"ref_id": "b19", "matched_paper_id": 14542261, "title": "Gradient-based learning applied to document recognition", "metadata": {"corpusId": "14542261", "paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "doi": "10.1109/5.726791", "url": "https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4", "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.", "year": 1998, "referenceCount": 149, "citationCount": 52674, "influentialCitationCount": 5988, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle", "Review"], "journal": {"name": "Proc. IEEE", "volume": "86", "issue": "", "pages": "2278-2324", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1688882", "name": "Yann LeCun", "hIndex": 132, "citationCount": 244817, "paperCount": 405}, {"authorId": "52184096", "name": "L. Bottou", "hIndex": 74, "citationCount": 116503, "paperCount": 198}, {"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}, {"authorId": "1721248", "name": "P. Haffner", "hIndex": 28, "citationCount": 58071, "paperCount": 75}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."}, "topics": ["Handwritten Text Recognition Techniques", "Image Processing and 3D Reconstruction", "Neural Networks and Applications"], "keywords": ["Handwriting Recognition", "Handwriting"], "mesh": [], "referenced_works_count": 126}, "referenced_works": ["https://openalex.org/W103129759", "https://openalex.org/W146900863", "https://openalex.org/W1530666108", "https://openalex.org/W1544211475", "https://openalex.org/W1547224907", "https://openalex.org/W1553004968", "https://openalex.org/W1575881144", "https://openalex.org/W1597009674", "https://openalex.org/W1625762979", "https://openalex.org/W1654022110", "https://openalex.org/W1667072054", "https://openalex.org/W1676820704", "https://openalex.org/W169539560", "https://openalex.org/W1761621746", "https://openalex.org/W183625566", "https://openalex.org/W1836880760", "https://openalex.org/W1877570817", "https://openalex.org/W1919233617", "https://openalex.org/W19621276", "https://openalex.org/W1975113431", "https://openalex.org/W1991133427", "https://openalex.org/W1992774725", "https://openalex.org/W1994065256", "https://openalex.org/W1994530392", "https://openalex.org/W1998255116", "https://openalex.org/W1999497791", "https://openalex.org/W2006544565", "https://openalex.org/W2007857129", "https://openalex.org/W2010315761", "https://openalex.org/W2010581677", "https://openalex.org/W2030781528", "https://openalex.org/W2035526030", "https://openalex.org/W2041460909", "https://openalex.org/W2042492924", "https://openalex.org/W2046485094", "https://openalex.org/W2047121664", "https://openalex.org/W2053176763", "https://openalex.org/W2055075080", "https://openalex.org/W2056695679", "https://openalex.org/W2056763477", "https://openalex.org/W2057200159", "https://openalex.org/W2057619148", "https://openalex.org/W2060604179", "https://openalex.org/W2063541597", "https://openalex.org/W2087347434", "https://openalex.org/W2090614046", "https://openalex.org/W2091987367", "https://openalex.org/W2093717447", "https://openalex.org/W2095757522", "https://openalex.org/W2095891604", "https://openalex.org/W2097316030", "https://openalex.org/W2099070536", "https://openalex.org/W2100921332", "https://openalex.org/W2103496339", "https://openalex.org/W2104867159", "https://openalex.org/W2107878631", "https://openalex.org/W2112957975", "https://openalex.org/W2113292028", "https://openalex.org/W2115240329", "https://openalex.org/W2116360511", "https://openalex.org/W2117671523", "https://openalex.org/W2119113516", "https://openalex.org/W2124351082", "https://openalex.org/W2125529971", "https://openalex.org/W2125838338", "https://openalex.org/W2126514931", "https://openalex.org/W2128652941", "https://openalex.org/W2131877510", "https://openalex.org/W2132131403", "https://openalex.org/W2132793646", "https://openalex.org/W2132904398", "https://openalex.org/W2134267682", "https://openalex.org/W2134429390", "https://openalex.org/W2135936685", "https://openalex.org/W2137291015", "https://openalex.org/W2137440383", "https://openalex.org/W2140005396", "https://openalex.org/W2140539590", "https://openalex.org/W2141207507", "https://openalex.org/W2144354855", "https://openalex.org/W2144405074", "https://openalex.org/W2147800946", "https://openalex.org/W2148099973", "https://openalex.org/W2148295954", "https://openalex.org/W2148603752", "https://openalex.org/W2149814369", "https://openalex.org/W2151871503", "https://openalex.org/W2154579312", "https://openalex.org/W2156909104", "https://openalex.org/W2158670134", "https://openalex.org/W2161523118", "https://openalex.org/W2162794177", "https://openalex.org/W2165668746", "https://openalex.org/W2165959773", "https://openalex.org/W2166559794", "https://openalex.org/W2168263526", "https://openalex.org/W2170599822", "https://openalex.org/W2170837066", "https://openalex.org/W2171590421", "https://openalex.org/W2346626577", "https://openalex.org/W2432517183", "https://openalex.org/W2565808444", "https://openalex.org/W2566703758", "https://openalex.org/W2598912124", "https://openalex.org/W2606748186", "https://openalex.org/W2609716011", "https://openalex.org/W2728988083", "https://openalex.org/W2766736793", "https://openalex.org/W2798500587", "https://openalex.org/W28586472", "https://openalex.org/W3004732066", "https://openalex.org/W3016210511", "https://openalex.org/W3017143921", "https://openalex.org/W3022861191", "https://openalex.org/W3101571078", "https://openalex.org/W3139633029", "https://openalex.org/W3207021134", "https://openalex.org/W324611197", "https://openalex.org/W413857758", "https://openalex.org/W4206670532", "https://openalex.org/W4212774754", "https://openalex.org/W4301028212", "https://openalex.org/W66978610", "https://openalex.org/W811578723", "https://openalex.org/W85412639", "https://openalex.org/W98859974"]}, {"ref_id": "b20", "matched_paper_id": 41312633, "title": "Backpropagation applied to handwritten zip code recognition", "metadata": {"corpusId": "41312633", "paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27", "doi": "10.1162/neco.1989.1.4.541", "url": "https://www.semanticscholar.org/paper/a8e8f3c8d4418c8d62e306538c9c1292635e9d27", "abstract": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.", "year": 1989, "referenceCount": 13, "citationCount": 10997, "influentialCitationCount": 695, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "1989-12-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Neural Computation", "volume": "1", "issue": "", "pages": "541-551", "id": "https://openalex.org/S207023548", "h_index": 248, "i10_index": 2520, "2yr_mean_citedness": 2.7464788732394365, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1688882", "name": "Yann LeCun", "hIndex": 132, "citationCount": 244817, "paperCount": 405}, {"authorId": "2219581", "name": "B. Boser", "hIndex": 50, "citationCount": 37101, "paperCount": 212}, {"authorId": "1747317", "name": "J. Denker", "hIndex": 37, "citationCount": 27722, "paperCount": 95}, {"authorId": "37274089", "name": "D. Henderson", "hIndex": 17, "citationCount": 16594, "paperCount": 28}, {"authorId": "2799635", "name": "R. Howard", "hIndex": 37, "citationCount": 20561, "paperCount": 154}, {"authorId": "34859193", "name": "W. Hubbard", "hIndex": 16, "citationCount": 16829, "paperCount": 29}, {"authorId": "2041866", "name": "L. Jackel", "hIndex": 39, "citationCount": 22280, "paperCount": 130}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."}, "topics": ["Handwritten Text Recognition Techniques", "Neural Networks and Applications", "Geophysical Methods and Applications"], "keywords": ["Backpropagation", "Code (set theory)", "Zip code"], "mesh": [], "referenced_works_count": 14}, "referenced_works": ["https://openalex.org/W169539560", "https://openalex.org/W19621276", "https://openalex.org/W1965770722", "https://openalex.org/W2058841211", "https://openalex.org/W2101926813", "https://openalex.org/W2116360511", "https://openalex.org/W2153988646", "https://openalex.org/W2157475639", "https://openalex.org/W2165758113", "https://openalex.org/W2167277568", "https://openalex.org/W2169163929", "https://openalex.org/W2606594511", "https://openalex.org/W2766736793", "https://openalex.org/W56903235"]}, {"ref_id": "b21", "matched_paper_id": 542039, "title": "A mathematical motivation for complex-valued convolutional networks", "metadata": {"corpusId": "542039", "paperId": "f55fe2b4344f015927a834d8ad6f52a35c3a8c8e", "doi": "10.1162/NECO_a_00824", "url": "https://www.semanticscholar.org/paper/f55fe2b4344f015927a834d8ad6f52a35c3a8c8e", "abstract": "A complex-valued convolutional network (convnet) implements the repeated application of the following composition of three operations, recursively applying the composition to an input vector of nonnegative real numbers: (1) convolution with complex-valued vectors, followed by (2) taking the absolute value of every entry of the resulting vectors, followed by (3) local averaging. For processing real-valued random vectors, complex-valued convnets can be viewed as data-driven multiscale windowed power spectra, data-driven multiscale windowed absolute spectra, data-driven multiwavelet absolute values, or (in their most general configuration) data-driven nonlinear multiwavelet packets. Indeed, complex-valued convnets can calculate multiscale windowed spectra when the convnet filters are windowed complex-valued exponentials. Standard real-valued convnets, using rectified linear units (ReLUs), sigmoidal (e.g., logistic or tanh) nonlinearities, or max pooling, for example, do not obviously exhibit the same exact correspondence with data-driven wavelets (whereas for complex-valued convnets, the correspondence is much more than just a vague analogy). Courtesy of the exact correspondence, the remarkably rich and rigorous body of mathematical analysis for wavelets applies directly to (complex-valued) convnets.", "year": 2015, "referenceCount": 36, "citationCount": 101, "influentialCitationCount": 3, "fieldsOfStudy": ["Mathematics", "Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2015-03-11", "publicationTypes": ["JournalArticle"], "journal": {"name": "Neural Computation", "volume": "28", "issue": "", "pages": "815-825", "id": "https://openalex.org/S207023548", "h_index": 248, "i10_index": 2520, "2yr_mean_citedness": 2.7464788732394365, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2973721", "name": "M. Tygert", "hIndex": 20, "citationCount": 3483, "paperCount": 70}, {"authorId": "143627859", "name": "Joan Bruna", "hIndex": 45, "citationCount": 35697, "paperCount": 119}, {"authorId": "2127604", "name": "Soumith Chintala", "hIndex": 28, "citationCount": 86444, "paperCount": 43}, {"authorId": "1688882", "name": "Yann LeCun", "hIndex": 132, "citationCount": 244817, "paperCount": 405}, {"authorId": "3058304", "name": "Serkan Piantino", "hIndex": 3, "citationCount": 447, "paperCount": 4}, {"authorId": "3149531", "name": "Arthur Szlam", "hIndex": 48, "citationCount": 23748, "paperCount": 136}], "tldr": {"model": "tldr@v2.0.0", "text": "Complex-valued convnets can calculate multiscale windowed spectra when the convnet filters are windowed complex-valued exponentials, and the remarkably rich and rigorous body of mathematical analysis for wavelets applies directly to (complex-valued) convnets."}, "topics": ["Image and Signal Denoising Methods", "Advanced Image Fusion Techniques", "Neural Networks and Applications"], "keywords": ["Pooling", "Convolution (computer science)"], "mesh": [], "referenced_works_count": 35}, "referenced_works": ["https://openalex.org/W1510019349", "https://openalex.org/W1510825849", "https://openalex.org/W1586192175", "https://openalex.org/W179797469", "https://openalex.org/W18046889", "https://openalex.org/W1890000358", "https://openalex.org/W1932922755", "https://openalex.org/W2035071469", "https://openalex.org/W2048673468", "https://openalex.org/W2062024414", "https://openalex.org/W2072072671", "https://openalex.org/W2109812093", "https://openalex.org/W2112796928", "https://openalex.org/W2119605622", "https://openalex.org/W2124386111", "https://openalex.org/W2128424195", "https://openalex.org/W2142933548", "https://openalex.org/W2151103935", "https://openalex.org/W2158162781", "https://openalex.org/W2161969291", "https://openalex.org/W2211840438", "https://openalex.org/W228380312", "https://openalex.org/W2604272474", "https://openalex.org/W2618530766", "https://openalex.org/W2919115771", "https://openalex.org/W2949708616", "https://openalex.org/W3100766587", "https://openalex.org/W3118608800", "https://openalex.org/W4242546747", "https://openalex.org/W4255272544", "https://openalex.org/W4300428639", "https://openalex.org/W563777065", "https://openalex.org/W574370508", "https://openalex.org/W59771946", "https://openalex.org/W786888796"]}, {"ref_id": "b22", "matched_paper_id": 206592664, "title": "Is object localization for free? -Weakly-supervised learning with convolutional neural networks", "metadata": {"corpusId": "206592664", "paperId": "ec679c45e88fa25fec32c30bc7c1b7d7fd0facec", "doi": "10.1109/CVPR.2015.7298668", "url": "https://www.semanticscholar.org/paper/ec679c45e88fa25fec32c30bc7c1b7d7fd0facec", "abstract": "Successful methods for visual object recognition typically rely on training datasets containing lots of richly annotated images. Detailed image annotation, e.g. by object bounding boxes, however, is both expensive and often subjective. We describe a weakly supervised convolutional neural network (CNN) for object classification that relies only on image-level labels, yet can learn from cluttered scenes containing multiple objects. We quantify its object classification and object location prediction performance on the Pascal VOC 2012 (20 object classes) and the much larger Microsoft COCO (80 object classes) datasets. We find that the network (i) outputs accurate image-level labels, (ii) predicts approximate locations (but not extents) of objects, and (iii) performs comparably to its fully-supervised counterparts using object bounding box annotation for training.", "year": 2015, "referenceCount": 63, "citationCount": 895, "influentialCitationCount": 104, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-06-07", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "685-694", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2093491", "name": "M. Oquab", "hIndex": 12, "citationCount": 7462, "paperCount": 27}, {"authorId": "52184096", "name": "L. Bottou", "hIndex": 74, "citationCount": 116503, "paperCount": 198}, {"authorId": "143991676", "name": "I. Laptev", "hIndex": 71, "citationCount": 36107, "paperCount": 192}, {"authorId": "1782755", "name": "Josef Sivic", "hIndex": 76, "citationCount": 43684, "paperCount": 190}], "tldr": {"model": "tldr@v2.0.0", "text": "A weakly supervised convolutional neural network is described for object classification that relies only on image-level labels, yet can learn from cluttered scenes containing multiple objects."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Pascal (unit)", "Bounding overwatch", "Minimum bounding box", "Supervised Learning", "Contextual image classification"], "mesh": [], "referenced_works_count": 65}, "referenced_works": ["https://openalex.org/W1487583988", "https://openalex.org/W1507506748", "https://openalex.org/W1530666108", "https://openalex.org/W1552060966", "https://openalex.org/W1567302070", "https://openalex.org/W1577863149", "https://openalex.org/W1590510366", "https://openalex.org/W1606858007", "https://openalex.org/W1625255723", "https://openalex.org/W1764806478", "https://openalex.org/W1799366690", "https://openalex.org/W1849277567", "https://openalex.org/W1861492603", "https://openalex.org/W1899185266", "https://openalex.org/W1952794764", "https://openalex.org/W1964763677", "https://openalex.org/W1973054923", "https://openalex.org/W1994529670", "https://openalex.org/W2031489346", "https://openalex.org/W2033832873", "https://openalex.org/W2037511607", "https://openalex.org/W2048060899", "https://openalex.org/W2055132753", "https://openalex.org/W2055349880", "https://openalex.org/W2062118960", "https://openalex.org/W2073983104", "https://openalex.org/W2081613070", "https://openalex.org/W2088711760", "https://openalex.org/W2098245519", "https://openalex.org/W2099528205", "https://openalex.org/W2102605133", "https://openalex.org/W2106317217", "https://openalex.org/W2109586012", "https://openalex.org/W2112020727", "https://openalex.org/W2113325037", "https://openalex.org/W2115240329", "https://openalex.org/W2120369594", "https://openalex.org/W2120419212", "https://openalex.org/W2125479168", "https://openalex.org/W2129305389", "https://openalex.org/W2131846894", "https://openalex.org/W2133324800", "https://openalex.org/W2134529554", "https://openalex.org/W2137023887", "https://openalex.org/W2147800946", "https://openalex.org/W2154422044", "https://openalex.org/W2155541015", "https://openalex.org/W2156689847", "https://openalex.org/W2161381512", "https://openalex.org/W2163605009", "https://openalex.org/W2166010828", "https://openalex.org/W2168356304", "https://openalex.org/W2171706135", "https://openalex.org/W2534457893", "https://openalex.org/W2536305071", "https://openalex.org/W2951505120", "https://openalex.org/W2952072685", "https://openalex.org/W2962851944", "https://openalex.org/W2963173190", "https://openalex.org/W2963542991", "https://openalex.org/W2963996492", "https://openalex.org/W318792885", "https://openalex.org/W4294375521", "https://openalex.org/W4302086866", "https://openalex.org/W753012316"]}, {"ref_id": "b23", "matched_paper_id": 206592484, "title": "Going deeper with convolutions", "metadata": {"corpusId": "206592484", "paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "doi": "10.1109/CVPR.2015.7298594", "url": "https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327", "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.", "year": 2014, "referenceCount": 265, "citationCount": 42681, "influentialCitationCount": 4200, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-09-16", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "1-9", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2574060", "name": "Christian Szegedy", "hIndex": 28, "citationCount": 194285, "paperCount": 50}, {"authorId": "2157222093", "name": "Wei Liu", "hIndex": 9, "citationCount": 44054, "paperCount": 11}, {"authorId": "39978391", "name": "Yangqing Jia", "hIndex": 34, "citationCount": 84237, "paperCount": 60}, {"authorId": "3142556", "name": "P. Sermanet", "hIndex": 35, "citationCount": 59673, "paperCount": 70}, {"authorId": "144828948", "name": "Scott E. Reed", "hIndex": 27, "citationCount": 81046, "paperCount": 33}, {"authorId": "1838674", "name": "Dragomir Anguelov", "hIndex": 34, "citationCount": 85380, "paperCount": 49}, {"authorId": "1761978", "name": "D. Erhan", "hIndex": 37, "citationCount": 113969, "paperCount": 60}, {"authorId": "2657155", "name": "Vincent Vanhoucke", "hIndex": 31, "citationCount": 113055, "paperCount": 59}, {"authorId": "39863668", "name": "Andrew Rabinovich", "hIndex": 21, "citationCount": 52984, "paperCount": 39}], "tldr": {"model": "tldr@v2.0.0", "text": "A deep convolutional neural network architecture codenamed Inception is proposed that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14)."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Intuition"], "mesh": [], "referenced_works_count": 21}, "referenced_works": ["https://openalex.org/W104184427", "https://openalex.org/W1709548961", "https://openalex.org/W1849277567", "https://openalex.org/W1904365287", "https://openalex.org/W2068730032", "https://openalex.org/W2069277577", "https://openalex.org/W2086161653", "https://openalex.org/W2102605133", "https://openalex.org/W2112796928", "https://openalex.org/W2113325037", "https://openalex.org/W2122283107", "https://openalex.org/W2129305389", "https://openalex.org/W2130306094", "https://openalex.org/W2143915663", "https://openalex.org/W2144982973", "https://openalex.org/W2147800946", "https://openalex.org/W2163605009", "https://openalex.org/W2168231600", "https://openalex.org/W2963542991", "https://openalex.org/W2963911037", "https://openalex.org/W388277973"]}, {"ref_id": "b24", "matched_paper_id": 2167514, "title": "A theoretical analysis of feature pooling in visual recognition", "metadata": {"corpusId": "2167514", "paperId": "405aed4b8ecdd869b2e83095dde51c396334115f", "doi": "", "url": "https://www.semanticscholar.org/paper/405aed4b8ecdd869b2e83095dde51c396334115f", "abstract": null, "year": 2010, "referenceCount": 20, "citationCount": 1307, "influentialCitationCount": 54, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2010-06-21", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "111-118", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "90841478", "name": "Y-Lan Boureau", "hIndex": 29, "citationCount": 9276, "paperCount": 48}, {"authorId": "144189388", "name": "J. Ponce", "hIndex": 78, "citationCount": 47337, "paperCount": 279}, {"authorId": "1688882", "name": "Yann LeCun", "hIndex": 132, "citationCount": 244817, "paperCount": 405}], "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that the reasons underlying the performance of various pooling methods are obscured by several confounding factors, such as the link between the sample cardinality in a spatial pool and the resolution at which low-level features have been extracted."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b25", "matched_paper_id": 18388506, "title": "Evaluation of pooling operations in convolutional architectures for object recognition", "metadata": {"corpusId": "18388506", "paperId": "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33", "doi": "10.1007/978-3-642-15825-4_10", "url": "https://www.semanticscholar.org/paper/5d21006fa32ff69f6b0a646f26ce0db84f2f4d33", "abstract": null, "year": 2010, "referenceCount": 27, "citationCount": 1545, "influentialCitationCount": 43, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2010-09-15", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "92-101", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2070963479", "name": "Dominik Scherer", "hIndex": 2, "citationCount": 1596, "paperCount": 2}, {"authorId": "2113785713", "name": "Andreas C. Müller", "hIndex": 8, "citationCount": 1867, "paperCount": 13}, {"authorId": "1699019", "name": "Sven Behnke", "hIndex": 55, "citationCount": 15497, "paperCount": 527}], "tldr": {"model": "tldr@v2.0.0", "text": "The aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks, and empirical results show that a maximum pooling operation significantly outperforms subsampling operations."}, "topics": ["Advanced Image and Video Retrieval Techniques", "Advanced Neural Network Applications", "Image Retrieval and Classification Techniques"], "keywords": ["Pooling"], "mesh": [], "referenced_works_count": 24}, "referenced_works": ["https://openalex.org/W1502609557", "https://openalex.org/W1576278180", "https://openalex.org/W1601963269", "https://openalex.org/W1624854622", "https://openalex.org/W2042028172", "https://openalex.org/W2103212315", "https://openalex.org/W2105464770", "https://openalex.org/W2112504244", "https://openalex.org/W2127232721", "https://openalex.org/W2127807804", "https://openalex.org/W2128354257", "https://openalex.org/W2134557905", "https://openalex.org/W2139427956", "https://openalex.org/W2149194912", "https://openalex.org/W2151103935", "https://openalex.org/W2156163116", "https://openalex.org/W2161893161", "https://openalex.org/W2161969291", "https://openalex.org/W2162915993", "https://openalex.org/W2166049352", "https://openalex.org/W2616465717", "https://openalex.org/W2914484425", "https://openalex.org/W4238404964", "https://openalex.org/W73247952"]}, {"ref_id": "b26", "matched_paper_id": 17981839, "title": "Max-Pooling Dropout for Regularization of Convolutional Neural Networks", "metadata": {"corpusId": "17981839", "paperId": "4287d9f41e3cd5c48a6ccdf1500e60d5a6f31bde", "doi": "10.1007/978-3-319-26532-2_6", "url": "https://www.semanticscholar.org/paper/4287d9f41e3cd5c48a6ccdf1500e60d5a6f31bde", "abstract": "Recently, dropout has seen increasing use in deep learning. For deep convolutional neural networks, dropout is known to work well in fully-connected layers. However, its effect in pooling layers is still not clear. This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time. In light of this insight, we advocate employing our proposed probabilistic weighted pooling, instead of commonly used max-pooling, to act as model averaging at test time. Empirical evidence validates the superiority of probabilistic weighted pooling. We also compare max-pooling dropout and stochastic pooling, both of which introduce stochasticity based on multinomial distributions at pooling stage.", "year": 2015, "referenceCount": 8, "citationCount": 141, "influentialCitationCount": 11, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2015-11-09", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "46-54", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3016112", "name": "Haibing Wu", "hIndex": 8, "citationCount": 653, "paperCount": 9}, {"authorId": "1649999106", "name": "Xiaodong Gu", "hIndex": 25, "citationCount": 2803, "paperCount": 130}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time, and advocates employing the proposed probabilistic weighted pooling, instead of commonly used max- Pooling, to act as model averaging at test time."}, "topics": ["Adversarial Robustness in Machine Learning", "Advanced Neural Network Applications", "Stochastic Gradient Optimization Techniques"], "keywords": ["Dropout (neural networks)", "Pooling", "Multinomial distribution", "Regularization"], "mesh": [], "referenced_works_count": 8}, "referenced_works": ["https://openalex.org/W1665214252", "https://openalex.org/W1904365287", "https://openalex.org/W1907282891", "https://openalex.org/W2136836265", "https://openalex.org/W2163605009", "https://openalex.org/W2294059674", "https://openalex.org/W3118608800", "https://openalex.org/W4919037"]}, {"ref_id": "b27", "matched_paper_id": 436933, "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition", "metadata": {"corpusId": "436933", "paperId": "cbb19236820a96038d000dc629225d36e0b6294a", "doi": "10.1007/978-3-319-10578-9_23", "url": "https://www.semanticscholar.org/paper/cbb19236820a96038d000dc629225d36e0b6294a", "abstract": "Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224<inline-formula><tex-math>$\\times$ </tex-math><alternatives><inline-graphic xlink:type=\"simple\" xlink:href=\"he-ieq1-2389824.gif\"/></alternatives></inline-formula>224) input image. This requirement is “artificial” and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 <inline-formula><tex-math>$\\times$</tex-math><alternatives><inline-graphic xlink:type=\"simple\" xlink:href=\"he-ieq2-2389824.gif\"/> </alternatives></inline-formula> faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.", "year": 2014, "referenceCount": 46, "citationCount": 10846, "influentialCitationCount": 688, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-06-18", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "37", "issue": "", "pages": "1904-1916", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "39353098", "name": "Kaiming He", "hIndex": 67, "citationCount": 454471, "paperCount": 84}, {"authorId": "1771551", "name": "X. Zhang", "hIndex": 79, "citationCount": 252055, "paperCount": 833}, {"authorId": "3080683", "name": "Shaoqing Ren", "hIndex": 13, "citationCount": 285050, "paperCount": 18}, {"authorId": null, "name": "Jian Sun"}], "tldr": {"model": "tldr@v2.0.0", "text": "This work equips the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement, and develops a new network structure, called SPP-net, which can generate a fixed-length representation regardless of image size/scale."}, "topics": ["Advanced Image and Video Retrieval Techniques", "Advanced Neural Network Applications", "Video Surveillance and Tracking Methods"], "keywords": ["Pooling", "Pyramid (geometry)"], "mesh": [], "referenced_works_count": 54}, "referenced_works": ["https://openalex.org/W1487583988", "https://openalex.org/W1524680991", "https://openalex.org/W1606858007", "https://openalex.org/W1686810756", "https://openalex.org/W1709548961", "https://openalex.org/W1799366690", "https://openalex.org/W1922123711", "https://openalex.org/W1976921161", "https://openalex.org/W1984309565", "https://openalex.org/W1994002998", "https://openalex.org/W2010181071", "https://openalex.org/W2027922120", "https://openalex.org/W2031489346", "https://openalex.org/W2062118960", "https://openalex.org/W2097018403", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2104978738", "https://openalex.org/W2108598243", "https://openalex.org/W2110226160", "https://openalex.org/W2117539524", "https://openalex.org/W2129305389", "https://openalex.org/W2130306094", "https://openalex.org/W2131846894", "https://openalex.org/W2145287260", "https://openalex.org/W2145406111", "https://openalex.org/W2147414309", "https://openalex.org/W2147800946", "https://openalex.org/W2151103935", "https://openalex.org/W2153635508", "https://openalex.org/W2155541015", "https://openalex.org/W2161381512", "https://openalex.org/W2161969291", "https://openalex.org/W2162915993", "https://openalex.org/W2163605009", "https://openalex.org/W2166049352", "https://openalex.org/W2166127773", "https://openalex.org/W2167090521", "https://openalex.org/W2167215970", "https://openalex.org/W2168356304", "https://openalex.org/W2179352600", "https://openalex.org/W2184852195", "https://openalex.org/W2206858481", "https://openalex.org/W2949194345", "https://openalex.org/W2952186574", "https://openalex.org/W2953360861", "https://openalex.org/W2963173190", "https://openalex.org/W2963542991", "https://openalex.org/W3120421331", "https://openalex.org/W4232730838", "https://openalex.org/W4239072543", "https://openalex.org/W4294375521", "https://openalex.org/W4388829817", "https://openalex.org/W7746136"]}, {"ref_id": "b28", "matched_paper_id": 436933, "title": "Spatial pyramid pooling in convolutional networks for visual recognition", "metadata": {"corpusId": "436933", "paperId": "cbb19236820a96038d000dc629225d36e0b6294a", "doi": "10.1007/978-3-319-10578-9_23", "url": "https://www.semanticscholar.org/paper/cbb19236820a96038d000dc629225d36e0b6294a", "abstract": "Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224<inline-formula><tex-math>$\\times$ </tex-math><alternatives><inline-graphic xlink:type=\"simple\" xlink:href=\"he-ieq1-2389824.gif\"/></alternatives></inline-formula>224) input image. This requirement is “artificial” and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 <inline-formula><tex-math>$\\times$</tex-math><alternatives><inline-graphic xlink:type=\"simple\" xlink:href=\"he-ieq2-2389824.gif\"/> </alternatives></inline-formula> faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.", "year": 2014, "referenceCount": 46, "citationCount": 10846, "influentialCitationCount": 688, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-06-18", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "37", "issue": "", "pages": "1904-1916", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "39353098", "name": "Kaiming He", "hIndex": 67, "citationCount": 454471, "paperCount": 84}, {"authorId": "1771551", "name": "X. Zhang", "hIndex": 79, "citationCount": 252055, "paperCount": 833}, {"authorId": "3080683", "name": "Shaoqing Ren", "hIndex": 13, "citationCount": 285050, "paperCount": 18}, {"authorId": null, "name": "Jian Sun"}], "tldr": {"model": "tldr@v2.0.0", "text": "This work equips the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement, and develops a new network structure, called SPP-net, which can generate a fixed-length representation regardless of image size/scale."}, "topics": ["Advanced Image and Video Retrieval Techniques", "Advanced Neural Network Applications", "Video Surveillance and Tracking Methods"], "keywords": ["Pooling", "Pyramid (geometry)"], "mesh": [], "referenced_works_count": 54}, "referenced_works": ["https://openalex.org/W1487583988", "https://openalex.org/W1524680991", "https://openalex.org/W1606858007", "https://openalex.org/W1686810756", "https://openalex.org/W1709548961", "https://openalex.org/W1799366690", "https://openalex.org/W1922123711", "https://openalex.org/W1976921161", "https://openalex.org/W1984309565", "https://openalex.org/W1994002998", "https://openalex.org/W2010181071", "https://openalex.org/W2027922120", "https://openalex.org/W2031489346", "https://openalex.org/W2062118960", "https://openalex.org/W2097018403", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2104978738", "https://openalex.org/W2108598243", "https://openalex.org/W2110226160", "https://openalex.org/W2117539524", "https://openalex.org/W2129305389", "https://openalex.org/W2130306094", "https://openalex.org/W2131846894", "https://openalex.org/W2145287260", "https://openalex.org/W2145406111", "https://openalex.org/W2147414309", "https://openalex.org/W2147800946", "https://openalex.org/W2151103935", "https://openalex.org/W2153635508", "https://openalex.org/W2155541015", "https://openalex.org/W2161381512", "https://openalex.org/W2161969291", "https://openalex.org/W2162915993", "https://openalex.org/W2163605009", "https://openalex.org/W2166049352", "https://openalex.org/W2166127773", "https://openalex.org/W2167090521", "https://openalex.org/W2167215970", "https://openalex.org/W2168356304", "https://openalex.org/W2179352600", "https://openalex.org/W2184852195", "https://openalex.org/W2206858481", "https://openalex.org/W2949194345", "https://openalex.org/W2952186574", "https://openalex.org/W2953360861", "https://openalex.org/W2963173190", "https://openalex.org/W2963542991", "https://openalex.org/W3120421331", "https://openalex.org/W4232730838", "https://openalex.org/W4239072543", "https://openalex.org/W4294375521", "https://openalex.org/W4388829817", "https://openalex.org/W7746136"]}, {"ref_id": "b29", "matched_paper_id": 11102127, "title": "DeepID-Net: Deformable deep convolutional neural networks for object detection", "metadata": {"corpusId": "11102127", "paperId": "5b249cf39370503f22fc7d4b257d735555d647ce", "doi": "10.1109/CVPR.2015.7298854", "url": "https://www.semanticscholar.org/paper/5b249cf39370503f22fc7d4b257d735555d647ce", "abstract": "In this paper, we propose deformable deep convolutional neural networks for generic object detection.This new deep learning object detection framework has innovations in multiple aspects.In the proposed new deep architecture, a new deformation constrained pooling (def-pooling) layer models the deformation of object parts with geometric constraint and penalty.A new pre-training strategy is proposed to learn feature representations more suitable for the object detection task and with good generalization capability.By changing the net structures, training strategies, adding and removing some key components in the detection pipeline, a set of models with large diversity are obtained, which significantly improves the effectiveness of model averaging.The proposed approach improves the mean averaged precision obtained by RCNN [14], which was the state-ofthe-art, from 31% to 50.3% on the ILSVRC2014 detection test set.It also outperforms the winner of ILSVRC2014, GoogLeNet, by 6.1%.Detailed component-wise analysis is also provided through extensive experimental evaluation, which provide a global view for people to understand the deep learning object detection pipeline.", "year": 2014, "referenceCount": 66, "citationCount": 431, "influentialCitationCount": 9, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-12-17", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "2403-2412", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3001348", "name": "Wanli Ouyang", "hIndex": 91, "citationCount": 38577, "paperCount": 311}, {"authorId": "31843833", "name": "Xiaogang Wang", "hIndex": 127, "citationCount": 92937, "paperCount": 641}, {"authorId": "2550719", "name": "Xingyu Zeng", "hIndex": 21, "citationCount": 2864, "paperCount": 32}, {"authorId": "2146345714", "name": "Shi Qiu", "hIndex": 8, "citationCount": 2554, "paperCount": 13}, {"authorId": "47571885", "name": "Ping Luo", "hIndex": 64, "citationCount": 36482, "paperCount": 201}, {"authorId": "2476765", "name": "Yonglong Tian", "hIndex": 26, "citationCount": 15337, "paperCount": 43}, {"authorId": "49404547", "name": "Hongsheng Li", "hIndex": 60, "citationCount": 15268, "paperCount": 187}, {"authorId": "92887925", "name": "Shuo Yang", "hIndex": 15, "citationCount": 7554, "paperCount": 17}, {"authorId": "40072288", "name": "Zhe Wang", "hIndex": 26, "citationCount": 5678, "paperCount": 41}, {"authorId": "1717179", "name": "Chen Change Loy", "hIndex": 113, "citationCount": 70830, "paperCount": 341}, {"authorId": "50295995", "name": "Xiaoou Tang", "hIndex": 132, "citationCount": 108044, "paperCount": 429}], "tldr": {"model": "tldr@v2.0.0", "text": "The proposed approach improves the mean averaged precision obtained by RCNN, which was the state-of-the-art, from 31% to 50.3% on the ILSVRC2014 detection test set."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Industrial Vision Systems and Defect Detection"], "keywords": ["Pooling", "Feature (linguistics)"], "mesh": [], "referenced_works_count": 64}, "referenced_works": ["https://openalex.org/W1516887802", "https://openalex.org/W1517303303", "https://openalex.org/W1524680991", "https://openalex.org/W1560380655", "https://openalex.org/W1686810756", "https://openalex.org/W1799366690", "https://openalex.org/W1942214758", "https://openalex.org/W1960289438", "https://openalex.org/W1970183457", "https://openalex.org/W1976948919", "https://openalex.org/W1977470347", "https://openalex.org/W1980163762", "https://openalex.org/W1986460963", "https://openalex.org/W1986905809", "https://openalex.org/W1987118352", "https://openalex.org/W1994529670", "https://openalex.org/W1996478295", "https://openalex.org/W1998808035", "https://openalex.org/W2010340098", "https://openalex.org/W2013640163", "https://openalex.org/W2024665880", "https://openalex.org/W2028742349", "https://openalex.org/W2030536784", "https://openalex.org/W2037511607", "https://openalex.org/W2046589395", "https://openalex.org/W2049705550", "https://openalex.org/W2062118960", "https://openalex.org/W2077493928", "https://openalex.org/W2084997728", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2109255472", "https://openalex.org/W2110226160", "https://openalex.org/W2117539524", "https://openalex.org/W2129305389", "https://openalex.org/W2133444763", "https://openalex.org/W2136579260", "https://openalex.org/W2141357020", "https://openalex.org/W2141364309", "https://openalex.org/W2142037471", "https://openalex.org/W2143352446", "https://openalex.org/W2150385913", "https://openalex.org/W2151454023", "https://openalex.org/W2153410696", "https://openalex.org/W2155541015", "https://openalex.org/W2156547346", "https://openalex.org/W2161106546", "https://openalex.org/W2161969291", "https://openalex.org/W2163605009", "https://openalex.org/W2166127773", "https://openalex.org/W2168356304", "https://openalex.org/W2179352600", "https://openalex.org/W2206858481", "https://openalex.org/W2535410496", "https://openalex.org/W2949883907", "https://openalex.org/W2951627457", "https://openalex.org/W2962851944", "https://openalex.org/W2963173190", "https://openalex.org/W2963542991", "https://openalex.org/W4241200240", "https://openalex.org/W4294375521", "https://openalex.org/W56385144", "https://openalex.org/W7746136", "https://openalex.org/W94414152"]}, {"ref_id": "b30", "matched_paper_id": 195908774, "title": "Imagenet classification with deep convolutional neural networks", "metadata": {"corpusId": "195908774", "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "doi": "10.1145/3065386", "url": "https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff", "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "year": 2012, "referenceCount": 71, "citationCount": 117192, "influentialCitationCount": 12885, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2012-12-03", "publicationTypes": ["JournalArticle"], "journal": {"name": "Communications of the ACM", "volume": "60", "issue": "", "pages": "84 - 90", "id": "https://openalex.org/S103482838", "h_index": 434, "i10_index": 7084, "2yr_mean_citedness": 2.3032928942807627, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2064160", "name": "A. Krizhevsky", "hIndex": 15, "citationCount": 204417, "paperCount": 22}, {"authorId": "1701686", "name": "I. Sutskever", "hIndex": 72, "citationCount": 408620, "paperCount": 140}, {"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}], "tldr": {"model": "tldr@v2.0.0", "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."}, "topics": ["Advanced Neural Network Applications", "Domain Adaptation and Few-Shot Learning", "Advanced Image and Video Retrieval Techniques"], "keywords": ["Softmax function", "Overfitting", "Pooling", "Dropout (neural networks)", "Regularization", "Convolution (computer science)", "Deep Neural Networks", "Word error rate"], "mesh": [], "referenced_works_count": 34}, "referenced_works": ["https://openalex.org/W1499991161", "https://openalex.org/W1573503290", "https://openalex.org/W1576445103", "https://openalex.org/W1665214252", "https://openalex.org/W1904365287", "https://openalex.org/W1994530392", "https://openalex.org/W2015861736", "https://openalex.org/W2018435387", "https://openalex.org/W2026942141", "https://openalex.org/W2053229256", "https://openalex.org/W2061212083", "https://openalex.org/W2097117768", "https://openalex.org/W2097356275", "https://openalex.org/W2101926813", "https://openalex.org/W2108069432", "https://openalex.org/W2108598243", "https://openalex.org/W2110764733", "https://openalex.org/W2130325614", "https://openalex.org/W2134557905", "https://openalex.org/W2141125852", "https://openalex.org/W2144161366", "https://openalex.org/W2154579312", "https://openalex.org/W2156163116", "https://openalex.org/W2166049352", "https://openalex.org/W2169805405", "https://openalex.org/W2194775991", "https://openalex.org/W2396976214", "https://openalex.org/W2546302380", "https://openalex.org/W2565808444", "https://openalex.org/W2766736793", "https://openalex.org/W2911964244", "https://openalex.org/W3118608800", "https://openalex.org/W3121926921", "https://openalex.org/W4205241946"]}, {"ref_id": "b31", "matched_paper_id": 215827080, "title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "metadata": {"corpusId": "215827080", "paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "doi": "10.1109/CVPR.2014.81", "url": "https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8", "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.", "year": 2013, "referenceCount": 56, "citationCount": 25459, "influentialCitationCount": 2780, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-11-11", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2014 IEEE Conference on Computer Vision and Pattern Recognition", "volume": "", "issue": "", "pages": "580-587", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2983898", "name": "Ross B. Girshick", "hIndex": 78, "citationCount": 333369, "paperCount": 112}, {"authorId": "7408951", "name": "Jeff Donahue", "hIndex": 31, "citationCount": 75567, "paperCount": 49}, {"authorId": "1753210", "name": "Trevor Darrell", "hIndex": 149, "citationCount": 201432, "paperCount": 630}, {"authorId": "153652147", "name": "J. Malik", "hIndex": 56, "citationCount": 58357, "paperCount": 98}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Pascal (unit)"], "mesh": [], "referenced_works_count": 49}, "referenced_works": ["https://openalex.org/W1555385401", "https://openalex.org/W1566135517", "https://openalex.org/W1832500336", "https://openalex.org/W1964005749", "https://openalex.org/W1982428585", "https://openalex.org/W1991367009", "https://openalex.org/W2016215417", "https://openalex.org/W2020308406", "https://openalex.org/W2022508996", "https://openalex.org/W2031489346", "https://openalex.org/W2046382188", "https://openalex.org/W2046875449", "https://openalex.org/W2056695679", "https://openalex.org/W2066624635", "https://openalex.org/W2088049833", "https://openalex.org/W2101926813", "https://openalex.org/W2103897297", "https://openalex.org/W2108598243", "https://openalex.org/W2110226160", "https://openalex.org/W2112796928", "https://openalex.org/W2115150266", "https://openalex.org/W2122146326", "https://openalex.org/W2130306094", "https://openalex.org/W2141200610", "https://openalex.org/W2142299364", "https://openalex.org/W2144794286", "https://openalex.org/W2147800946", "https://openalex.org/W2151049637", "https://openalex.org/W2151103935", "https://openalex.org/W2153185908", "https://openalex.org/W2155541015", "https://openalex.org/W2159686933", "https://openalex.org/W2161106546", "https://openalex.org/W2161969291", "https://openalex.org/W2162741153", "https://openalex.org/W2163605009", "https://openalex.org/W2163922914", "https://openalex.org/W2168356304", "https://openalex.org/W22040386", "https://openalex.org/W2217896605", "https://openalex.org/W2535410496", "https://openalex.org/W2538008885", "https://openalex.org/W2673062467", "https://openalex.org/W2766736793", "https://openalex.org/W3118608800", "https://openalex.org/W4239072543", "https://openalex.org/W4256462001", "https://openalex.org/W4294375521", "https://openalex.org/W78159342"]}, {"ref_id": "b32", "matched_paper_id": 207178999, "title": "Learning deep architectures for AI", "metadata": {"corpusId": "207178999", "paperId": "d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "doi": "10.1561/2200000006", "url": "https://www.semanticscholar.org/paper/d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "abstract": "Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.", "year": 2007, "referenceCount": 248, "citationCount": 8531, "influentialCitationCount": 504, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle"], "journal": {"name": "Found. Trends Mach. Learn.", "volume": "2", "issue": "", "pages": "1-127", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}], "tldr": {"model": "tldr@v2.0.0", "text": "The motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer modelssuch as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks are discussed."}, "topics": ["Anomaly Detection Techniques and Applications"], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b33", "matched_paper_id": 533055, "title": "Information processing in dynamical systems: Foundations of harmony theory", "metadata": {"corpusId": "533055", "paperId": "4f7476037408ac3d993f5088544aab427bc319c1", "doi": "", "url": "https://www.semanticscholar.org/paper/4f7476037408ac3d993f5088544aab427bc319c1", "abstract": null, "year": 1986, "referenceCount": 18, "citationCount": 2126, "influentialCitationCount": 177, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "1986-01-03", "publicationTypes": null, "journal": {"name": "", "volume": "", "issue": "", "pages": "194-281", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1748557", "name": "P. Smolensky", "hIndex": 52, "citationCount": 19551, "paperCount": 220}], "tldr": {"model": "tldr@v2.0.0", "text": "The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b34", "matched_paper_id": null, "title": ""}, {"ref_id": "b35", "matched_paper_id": 17861266, "title": "On contrastive divergence learning", "metadata": {"corpusId": "17861266", "paperId": "e270bfa5b662c531a61a5b274da636603c23a734", "doi": "", "url": "https://www.semanticscholar.org/paper/e270bfa5b662c531a61a5b274da636603c23a734", "abstract": null, "year": 2005, "referenceCount": 16, "citationCount": 827, "influentialCitationCount": 52, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "33-40", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1400347470", "name": "M. A. Carreira-Perpiñán", "hIndex": 37, "citationCount": 7162, "paperCount": 134}, {"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}], "tldr": {"model": "tldr@v2.0.0", "text": "The properties of CD learning are studied and it is shown that it provides biased estimates in general, but that the bias is typically very small."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b36", "matched_paper_id": 21145246, "title": "A practical guide to training restricted Boltzmann machines", "metadata": {"corpusId": "21145246", "paperId": "e95d3934e51107da7610acd0b1bcb6551671f9f1", "doi": "10.1007/978-3-642-35289-8_32", "url": "https://www.semanticscholar.org/paper/e95d3934e51107da7610acd0b1bcb6551671f9f1", "abstract": null, "year": 2012, "referenceCount": 27, "citationCount": 3085, "influentialCitationCount": 332, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": null, "journal": {"name": "", "volume": "", "issue": "", "pages": "599-619", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}], "tldr": {"model": "tldr@v2.0.0", "text": "This guide is an attempt to share expertise at training restricted Boltzmann machines with other machine learning researchers."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Model Reduction and Neural Networks", "Neural Networks and Applications"], "keywords": ["Boltzmann machine", "Training set", "Divergence (linguistics)"], "mesh": [], "referenced_works_count": 29}, "referenced_works": ["https://openalex.org/W145818128", "https://openalex.org/W1511867968", "https://openalex.org/W1543614656", "https://openalex.org/W1581975000", "https://openalex.org/W1662191912", "https://openalex.org/W1665214252", "https://openalex.org/W1813659000", "https://openalex.org/W2029949252", "https://openalex.org/W2064082346", "https://openalex.org/W2096192494", "https://openalex.org/W2099866409", "https://openalex.org/W2100002341", "https://openalex.org/W2108581046", "https://openalex.org/W2114153178", "https://openalex.org/W2116064496", "https://openalex.org/W2116825644", "https://openalex.org/W2124914669", "https://openalex.org/W2128084896", "https://openalex.org/W2136922672", "https://openalex.org/W2150529939", "https://openalex.org/W2158164339", "https://openalex.org/W2161893161", "https://openalex.org/W2165225968", "https://openalex.org/W2595697910", "https://openalex.org/W2598912124", "https://openalex.org/W2913668833", "https://openalex.org/W4300402905", "https://openalex.org/W645920547", "https://openalex.org/W66838807"]}, {"ref_id": "b37", "matched_paper_id": 11878505, "title": "Enhanced gradient for training restricted Boltzmann machines", "metadata": {"corpusId": "11878505", "paperId": "1ee03cbf30ba273ee9ec1995d1958732df0161f3", "doi": "10.1162/NECO_a_00397", "url": "https://www.semanticscholar.org/paper/1ee03cbf30ba273ee9ec1995d1958732df0161f3", "abstract": "Restricted Boltzmann machines (RBMs) are often used as building blocks in greedy learning of deep networks. However, training this simple model can be laborious. Traditional learning algorithms often converge only with the right choice of metaparameters that specify, for example, learning rate scheduling and the scale of the initial weights. They are also sensitive to specific data representation. An equivalent RBM can be obtained by flipping some bits and changing the weights and biases accordingly, but traditional learning rules are not invariant to such transformations. Without careful tuning of these training settings, traditional algorithms can easily get stuck or even diverge. In this letter, we present an enhanced gradient that is derived to be invariant to bit-flipping transformations. We experimentally show that the enhanced gradient yields more stable training of RBMs both when used with a fixed learning rate and an adaptive one.", "year": 2013, "referenceCount": 32, "citationCount": 67, "influentialCitationCount": 7, "fieldsOfStudy": ["Mathematics", "Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2013-03-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Neural Computation", "volume": "25", "issue": "", "pages": "805-831", "id": "https://openalex.org/S207023548", "h_index": 248, "i10_index": 2520, "2yr_mean_citedness": 2.7464788732394365, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1979489", "name": "Kyunghyun Cho", "hIndex": 90, "citationCount": 117197, "paperCount": 328}, {"authorId": "2785022", "name": "T. Raiko", "hIndex": 32, "citationCount": 6822, "paperCount": 136}, {"authorId": "145096481", "name": "A. Ilin", "hIndex": 26, "citationCount": 2381, "paperCount": 119}], "tldr": {"model": "tldr@v2.0.0", "text": "This letter presents an enhanced gradient that is derived to be invariant to bit-flipping transformations and experimentally shows that the enhanced gradient yields more stable training of RBMs both when used with a fixed learning rate and an adaptive one."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Lattice Boltzmann Simulation Studies", "Model Reduction and Neural Networks"], "keywords": ["Boltzmann machine", "Restricted Boltzmann machine", "Boltzmann constant", "Representation"], "mesh": ["Algorithms/None", "Artificial Intelligence/None", "Computer Simulation/None"], "referenced_works_count": 36}, "referenced_works": ["https://openalex.org/W1495672967", "https://openalex.org/W1562353105", "https://openalex.org/W1652505363", "https://openalex.org/W1813659000", "https://openalex.org/W189596042", "https://openalex.org/W193851967", "https://openalex.org/W2029719968", "https://openalex.org/W2043285245", "https://openalex.org/W2054912984", "https://openalex.org/W2064487597", "https://openalex.org/W2072128103", "https://openalex.org/W2076063813", "https://openalex.org/W2097998348", "https://openalex.org/W2099939455", "https://openalex.org/W2100495367", "https://openalex.org/W2103819961", "https://openalex.org/W2112796928", "https://openalex.org/W2116064496", "https://openalex.org/W2116825644", "https://openalex.org/W2130325614", "https://openalex.org/W2133257461", "https://openalex.org/W2136936677", "https://openalex.org/W2138857742", "https://openalex.org/W2139427956", "https://openalex.org/W2156740722", "https://openalex.org/W2171282218", "https://openalex.org/W2184970173", "https://openalex.org/W2189142260", "https://openalex.org/W2595431794", "https://openalex.org/W2597289420", "https://openalex.org/W2606321545", "https://openalex.org/W2990138404", "https://openalex.org/W3207342693", "https://openalex.org/W4231109964", "https://openalex.org/W44815768", "https://openalex.org/W66838807"]}, {"ref_id": "b38", "matched_paper_id": 1658773, "title": "Reducing the dimensionality of data with neural networks", "metadata": {"corpusId": "1658773", "paperId": "268b8f10a45e71f63daab6403bb453da31ae28a7", "doi": "", "url": "https://www.semanticscholar.org/paper/268b8f10a45e71f63daab6403bb453da31ae28a7", "abstract": null, "year": 2009, "referenceCount": 0, "citationCount": 9931, "influentialCitationCount": 660, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category": "Geology", "source": "s2-fos-model"}, {"category": "Physics", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": null, "journal": {"name": "", "volume": "", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [], "tldr": {"model": "tldr@v2.0.0", "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b39", "matched_paper_id": 10663248, "title": "Deep machine learning-a new frontier in artificial intelligence research", "metadata": {"corpusId": "10663248", "paperId": "ea58af907495e97c93997119db4a59fab5cd3683", "doi": "10.1109/MCI.2010.938364", "url": "https://www.semanticscholar.org/paper/ea58af907495e97c93997119db4a59fab5cd3683", "abstract": "This article provides an overview of the mainstream deep learning approaches and research directions proposed over the past decade. It is important to emphasize that each approach has strengths and \"weaknesses, depending on the application and context in \"which it is being used. Thus, this article presents a summary on the current state of the deep machine learning field and some perspective into how it may evolve. Convolutional Neural Networks (CNNs) and Deep Belief Networks (DBNs) (and their respective variations) are focused on primarily because they are well established in the deep learning field and show great promise for future work.", "year": 2010, "referenceCount": 57, "citationCount": 1141, "influentialCitationCount": 23, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2010-11-01", "publicationTypes": ["JournalArticle", "Review"], "journal": {"name": "IEEE Computational Intelligence Magazine", "volume": "5", "issue": "", "pages": "13-18", "id": "https://openalex.org/S104797584", "h_index": 88, "i10_index": 367, "2yr_mean_citedness": 3.3692307692307693, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1804314", "name": "I. Arel", "hIndex": 15, "citationCount": 2661, "paperCount": 58}, {"authorId": "2483864", "name": "Derek C. Rose", "hIndex": 11, "citationCount": 1861, "paperCount": 19}, {"authorId": "1970334", "name": "T. Karnowski", "hIndex": 28, "citationCount": 4253, "paperCount": 147}], "tldr": {"model": "tldr@v2.0.0", "text": "An overview of the mainstream deep learning approaches and research directions proposed over the past decade is provided and some perspective into how it may evolve is presented."}, "topics": ["Anomaly Detection Techniques and Applications", "Generative Adversarial Networks and Image Synthesis", "Neural Networks and Applications"], "keywords": ["Frontier", "Strengths and weaknesses", "Deep belief network"], "mesh": [], "referenced_works_count": 56}, "referenced_works": ["https://openalex.org/W1538725615", "https://openalex.org/W1597739853", "https://openalex.org/W1600790096", "https://openalex.org/W1601963269", "https://openalex.org/W1656096371", "https://openalex.org/W1963597874", "https://openalex.org/W1970958875", "https://openalex.org/W1977058707", "https://openalex.org/W1994197834", "https://openalex.org/W2025768430", "https://openalex.org/W2032442397", "https://openalex.org/W2048060899", "https://openalex.org/W2072128103", "https://openalex.org/W2077910828", "https://openalex.org/W2088495765", "https://openalex.org/W2100495367", "https://openalex.org/W2101926813", "https://openalex.org/W2107789863", "https://openalex.org/W2108463990", "https://openalex.org/W2110798204", "https://openalex.org/W2112504244", "https://openalex.org/W2112796928", "https://openalex.org/W2113625916", "https://openalex.org/W2116064496", "https://openalex.org/W2116360511", "https://openalex.org/W2117671523", "https://openalex.org/W2119554284", "https://openalex.org/W2125663122", "https://openalex.org/W2127661044", "https://openalex.org/W2130325614", "https://openalex.org/W2136922672", "https://openalex.org/W2137105523", "https://openalex.org/W2139427956", "https://openalex.org/W2140262144", "https://openalex.org/W2144982973", "https://openalex.org/W2145038566", "https://openalex.org/W2147010501", "https://openalex.org/W2149194912", "https://openalex.org/W2149753900", "https://openalex.org/W2156163116", "https://openalex.org/W2159080219", "https://openalex.org/W2159291644", "https://openalex.org/W2161363194", "https://openalex.org/W2169771895", "https://openalex.org/W2287948962", "https://openalex.org/W2326588846", "https://openalex.org/W2341171179", "https://openalex.org/W2341514930", "https://openalex.org/W2406777949", "https://openalex.org/W2616465717", "https://openalex.org/W37458164", "https://openalex.org/W4231109964", "https://openalex.org/W56465887", "https://openalex.org/W68611592", "https://openalex.org/W73247952", "https://openalex.org/W87976740"]}, {"ref_id": "b40", "matched_paper_id": 393948, "title": "Representation learning: a review and new perspectives", "metadata": {"corpusId": "393948", "paperId": "184ac0766262312ba76bbdece4e7ffad0aa8180b", "doi": "10.1109/TPAMI.2013.50", "url": "https://www.semanticscholar.org/paper/184ac0766262312ba76bbdece4e7ffad0aa8180b", "abstract": "The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.", "year": 2012, "referenceCount": 264, "citationCount": 12146, "influentialCitationCount": 556, "fieldsOfStudy": ["Computer Science", "Medicine", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2012-06-24", "publicationTypes": ["Review", "JournalArticle"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "35", "issue": "", "pages": "1798-1828", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}, {"authorId": "1760871", "name": "Aaron C. Courville", "hIndex": 90, "citationCount": 116603, "paperCount": 242}, {"authorId": "145467703", "name": "Pascal Vincent", "hIndex": 43, "citationCount": 32351, "paperCount": 85}], "tldr": {"model": "tldr@v2.0.0", "text": "Recent work in the area of unsupervised feature learning and deep learning is reviewed, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks."}, "topics": ["Face and Expression Recognition", "Neural Networks and Applications", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Feature Learning", "Representation", "External Data Representation", "Feature (linguistics)"], "mesh": ["Artificial Intelligence/trends", "Algorithms/None", "Artificial Intelligence/None", "Humans/None", "Neural Networks, Computer/None"], "referenced_works_count": 256}, "referenced_works": ["https://openalex.org/W110825707", "https://openalex.org/W116068320", "https://openalex.org/W1408639475", "https://openalex.org/W142185896", "https://openalex.org/W145476170", "https://openalex.org/W1489081407", "https://openalex.org/W1496559305", "https://openalex.org/W1505878979", "https://openalex.org/W1511867968", "https://openalex.org/W1526741802", "https://openalex.org/W1533072162", "https://openalex.org/W1533861849", "https://openalex.org/W1536231199", "https://openalex.org/W1544211475", "https://openalex.org/W1548802052", "https://openalex.org/W1576278180", "https://openalex.org/W1586730761", "https://openalex.org/W1592735339", "https://openalex.org/W1596986901", "https://openalex.org/W16016350", "https://openalex.org/W1665214252", "https://openalex.org/W169539560", "https://openalex.org/W17525587", "https://openalex.org/W1761606332", "https://openalex.org/W177847060", "https://openalex.org/W1806891645", "https://openalex.org/W1811734137", "https://openalex.org/W1813659000", "https://openalex.org/W1819710477", "https://openalex.org/W1838657242", "https://openalex.org/W1876224860", "https://openalex.org/W189596042", "https://openalex.org/W193851967", "https://openalex.org/W195465510", "https://openalex.org/W1964155876", "https://openalex.org/W196761320", "https://openalex.org/W1970789124", "https://openalex.org/W1979185006", "https://openalex.org/W1983334819", "https://openalex.org/W1990838964", "https://openalex.org/W1993882792", "https://openalex.org/W1994906459", "https://openalex.org/W1995314086", "https://openalex.org/W1995997122", "https://openalex.org/W1996355918", "https://openalex.org/W1999192586", "https://openalex.org/W2001141328", "https://openalex.org/W2003289302", "https://openalex.org/W2013035813", "https://openalex.org/W2017257315", "https://openalex.org/W2020719522", "https://openalex.org/W2025768430", "https://openalex.org/W2049633694", "https://openalex.org/W2051144468", "https://openalex.org/W2053186076", "https://openalex.org/W2054217036", "https://openalex.org/W2063971957", "https://openalex.org/W2071128523", "https://openalex.org/W2072128103", "https://openalex.org/W2076094076", "https://openalex.org/W2079182758", "https://openalex.org/W2083380015", "https://openalex.org/W2091886411", "https://openalex.org/W2091987367", "https://openalex.org/W2096873754", "https://openalex.org/W2097308346", "https://openalex.org/W2097998348", "https://openalex.org/W2098477387", "https://openalex.org/W2099741732", "https://openalex.org/W2099866409", "https://openalex.org/W2099939455", "https://openalex.org/W2100495367", "https://openalex.org/W2101926813", "https://openalex.org/W2102017903", "https://openalex.org/W2102409316", "https://openalex.org/W2102765684", "https://openalex.org/W2103212315", "https://openalex.org/W2103305545", "https://openalex.org/W2103359087", "https://openalex.org/W2103819961", "https://openalex.org/W2105464873", "https://openalex.org/W2105728138", "https://openalex.org/W2106004777", "https://openalex.org/W2106411961", "https://openalex.org/W2106439909", "https://openalex.org/W2106869737", "https://openalex.org/W2107789863", "https://openalex.org/W2107878631", "https://openalex.org/W2107998050", "https://openalex.org/W2108581046", "https://openalex.org/W2108665656", "https://openalex.org/W2110361616", "https://openalex.org/W2110798204", "https://openalex.org/W2111304802", "https://openalex.org/W2111494971", "https://openalex.org/W2112148214", "https://openalex.org/W2112274848", "https://openalex.org/W2112796928", "https://openalex.org/W2114570910", "https://openalex.org/W2115096495", "https://openalex.org/W2116064496", "https://openalex.org/W2116516955", "https://openalex.org/W2116825644", "https://openalex.org/W2117130368", "https://openalex.org/W2118103795", "https://openalex.org/W2121331909", "https://openalex.org/W2122922389", "https://openalex.org/W2123131857", "https://openalex.org/W2123284177", "https://openalex.org/W2123496278", "https://openalex.org/W2124237441", "https://openalex.org/W2124386111", "https://openalex.org/W2124486835", "https://openalex.org/W2125027820", "https://openalex.org/W2125569215", "https://openalex.org/W2126760242", "https://openalex.org/W2130325614", "https://openalex.org/W2131241448", "https://openalex.org/W2131672785", "https://openalex.org/W2132283655", "https://openalex.org/W2132424367", "https://openalex.org/W2133257461", "https://openalex.org/W2134563198", "https://openalex.org/W2135341757", "https://openalex.org/W2136163184", "https://openalex.org/W2136922672", "https://openalex.org/W2137234026", "https://openalex.org/W2137291015", "https://openalex.org/W2137510948", "https://openalex.org/W2137595331", "https://openalex.org/W2138265962", "https://openalex.org/W2138448681", "https://openalex.org/W2138857742", "https://openalex.org/W2140095548", "https://openalex.org/W2140262144", "https://openalex.org/W2140622310", "https://openalex.org/W2140793251", "https://openalex.org/W2140833774", "https://openalex.org/W2141006018", "https://openalex.org/W2141125852", "https://openalex.org/W2141132211", "https://openalex.org/W2144982973", "https://openalex.org/W2145038566", "https://openalex.org/W2145094598", "https://openalex.org/W2145889472", "https://openalex.org/W2146444479", "https://openalex.org/W2146672645", "https://openalex.org/W2147768505", "https://openalex.org/W2147800946", "https://openalex.org/W2147860648", "https://openalex.org/W2148553367", "https://openalex.org/W2149194912", "https://openalex.org/W2150529939", "https://openalex.org/W2152424459", "https://openalex.org/W2152790380", "https://openalex.org/W2153052520", "https://openalex.org/W2153934661", "https://openalex.org/W2156047073", "https://openalex.org/W2156163116", "https://openalex.org/W2156387975", "https://openalex.org/W2156740722", "https://openalex.org/W2156838815", "https://openalex.org/W2157002241", "https://openalex.org/W2157444450", "https://openalex.org/W2158834214", "https://openalex.org/W2158867000", "https://openalex.org/W2158899491", "https://openalex.org/W2159291644", "https://openalex.org/W2160142299", "https://openalex.org/W2160306971", "https://openalex.org/W2160692033", "https://openalex.org/W2160815625", "https://openalex.org/W2161000554", "https://openalex.org/W2161366100", "https://openalex.org/W2161977692", "https://openalex.org/W2162747531", "https://openalex.org/W2162915993", "https://openalex.org/W2162931300", "https://openalex.org/W2162950292", "https://openalex.org/W2163202312", "https://openalex.org/W2163605009", "https://openalex.org/W2164273299", "https://openalex.org/W2164587673", "https://openalex.org/W2165225968", "https://openalex.org/W2165293955", "https://openalex.org/W2165337236", "https://openalex.org/W2166093887", "https://openalex.org/W2168013545", "https://openalex.org/W2168345951", "https://openalex.org/W2169488311", "https://openalex.org/W2169805405", "https://openalex.org/W2171282218", "https://openalex.org/W2171490498", "https://openalex.org/W2172174689", "https://openalex.org/W2183660452", "https://openalex.org/W2184045248", "https://openalex.org/W2184852195", "https://openalex.org/W2185528074", "https://openalex.org/W2185726469", "https://openalex.org/W2186489521", "https://openalex.org/W2186629860", "https://openalex.org/W2187089797", "https://openalex.org/W2188492526", "https://openalex.org/W2191540403", "https://openalex.org/W2200708944", "https://openalex.org/W2218318129", "https://openalex.org/W2250379827", "https://openalex.org/W2252143850", "https://openalex.org/W22861983", "https://openalex.org/W2289330286", "https://openalex.org/W2293078015", "https://openalex.org/W2294798173", "https://openalex.org/W2295582178", "https://openalex.org/W2296073425", "https://openalex.org/W2394932179", "https://openalex.org/W2400065095", "https://openalex.org/W2406196141", "https://openalex.org/W2546302380", "https://openalex.org/W2584401907", "https://openalex.org/W2606321545", "https://openalex.org/W2606748186", "https://openalex.org/W2613634265", "https://openalex.org/W2616180702", "https://openalex.org/W2726367589", "https://openalex.org/W28766783", "https://openalex.org/W2913932916", "https://openalex.org/W2914484425", "https://openalex.org/W2949821452", "https://openalex.org/W2950320139", "https://openalex.org/W2952230511", "https://openalex.org/W2952402222", "https://openalex.org/W2952722152", "https://openalex.org/W2952742172", "https://openalex.org/W2962936867", "https://openalex.org/W2962968839", "https://openalex.org/W2963654815", "https://openalex.org/W2963909185", "https://openalex.org/W2964300310", "https://openalex.org/W2966661", "https://openalex.org/W2997574889", "https://openalex.org/W2998704965", "https://openalex.org/W3013880646", "https://openalex.org/W3118608800", "https://openalex.org/W3122936144", "https://openalex.org/W413857758", "https://openalex.org/W4205778870", "https://openalex.org/W4231109964", "https://openalex.org/W4240768087", "https://openalex.org/W4285719527", "https://openalex.org/W4293652559", "https://openalex.org/W4300198444", "https://openalex.org/W4300402905", "https://openalex.org/W44815768", "https://openalex.org/W625466704", "https://openalex.org/W66838807", "https://openalex.org/W71795751"]}, {"ref_id": "b41", "matched_paper_id": 12008458, "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "metadata": {"corpusId": "12008458", "paperId": "1e80f755bcbf10479afd2338cec05211fdbd325c", "doi": "10.1145/1553374.1553453", "url": "https://www.semanticscholar.org/paper/1e80f755bcbf10479afd2338cec05211fdbd325c", "abstract": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.", "year": 2009, "referenceCount": 28, "citationCount": 2675, "influentialCitationCount": 209, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2009-06-14", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "609-616", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1697141", "name": "Honglak Lee", "hIndex": 88, "citationCount": 53607, "paperCount": 187}, {"authorId": "1785346", "name": "R. Grosse", "hIndex": 49, "citationCount": 14867, "paperCount": 114}, {"authorId": "2615814", "name": "R. Ranganath", "hIndex": 40, "citationCount": 10565, "paperCount": 127}, {"authorId": "34699434", "name": "A. Ng", "hIndex": 127, "citationCount": 173098, "paperCount": 279}], "tldr": {"model": "tldr@v2.0.0", "text": "The convolutional deep belief network is presented, a hierarchical generative model which scales to realistic image sizes and is translation-invariant and supports efficient bottom-up and top-down probabilistic inference."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Advanced Image and Video Retrieval Techniques", "Image Retrieval and Classification Techniques"], "keywords": ["Pooling", "Deep belief network", "Generative model"], "mesh": [], "referenced_works_count": 27}, "referenced_works": ["https://openalex.org/W146900863", "https://openalex.org/W2089933214", "https://openalex.org/W2100495367", "https://openalex.org/W2102116870", "https://openalex.org/W2105464770", "https://openalex.org/W2108138754", "https://openalex.org/W2110798204", "https://openalex.org/W2116064496", "https://openalex.org/W2120432001", "https://openalex.org/W2122808326", "https://openalex.org/W2122922389", "https://openalex.org/W2125663122", "https://openalex.org/W2133257461", "https://openalex.org/W2136922672", "https://openalex.org/W2137234026", "https://openalex.org/W2139427956", "https://openalex.org/W2145889472", "https://openalex.org/W2147800946", "https://openalex.org/W2155904486", "https://openalex.org/W2158164339", "https://openalex.org/W2159291644", "https://openalex.org/W2162915993", "https://openalex.org/W2165828254", "https://openalex.org/W2168002178", "https://openalex.org/W2172174689", "https://openalex.org/W2330388069", "https://openalex.org/W2963909185"]}, {"ref_id": "b42", "matched_paper_id": 9511725, "title": "Unsupervised learning of hierarchical representations with convolutional deep belief networks", "metadata": {"corpusId": "9511725", "paperId": "ad8c2721ef54c9326684762db7c9fc1378e83797", "doi": "10.1145/2001269.2001295", "url": "https://www.semanticscholar.org/paper/ad8c2721ef54c9326684762db7c9fc1378e83797", "abstract": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks (DBNs); however, scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network , a hierarchical generative model that scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling , a novel technique that shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.", "year": 2011, "referenceCount": 44, "citationCount": 385, "influentialCitationCount": 28, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2011-10-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Communications of the ACM", "volume": "54", "issue": "", "pages": "95 - 103", "id": "https://openalex.org/S103482838", "h_index": 434, "i10_index": 7084, "2yr_mean_citedness": 2.3032928942807627, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1697141", "name": "Honglak Lee", "hIndex": 88, "citationCount": 53607, "paperCount": 187}, {"authorId": "1785346", "name": "R. Grosse", "hIndex": 49, "citationCount": 14867, "paperCount": 114}, {"authorId": "2615814", "name": "R. Ranganath", "hIndex": 40, "citationCount": 10565, "paperCount": 127}, {"authorId": "34699434", "name": "A. Ng", "hIndex": 127, "citationCount": 173098, "paperCount": 279}], "tldr": {"model": "tldr@v2.0.0", "text": "The convolutional deep belief network is presented, a hierarchical generative model that scales to realistic image sizes and is translation-invariant and supports efficient bottom-up and top-down probabilistic inference."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Advanced Image and Video Retrieval Techniques", "Image Retrieval and Classification Techniques"], "keywords": ["Deep belief network", "Pooling", "Generative model"], "mesh": [], "referenced_works_count": 38}, "referenced_works": ["https://openalex.org/W1511986666", "https://openalex.org/W1798871656", "https://openalex.org/W189596042", "https://openalex.org/W1994197834", "https://openalex.org/W2043285245", "https://openalex.org/W2099866409", "https://openalex.org/W2100495367", "https://openalex.org/W2101933716", "https://openalex.org/W2102116870", "https://openalex.org/W2105464770", "https://openalex.org/W2108138754", "https://openalex.org/W2108665656", "https://openalex.org/W2110361616", "https://openalex.org/W2110798204", "https://openalex.org/W2116064496", "https://openalex.org/W2116825644", "https://openalex.org/W2120432001", "https://openalex.org/W2122922389", "https://openalex.org/W2124372976", "https://openalex.org/W2125663122", "https://openalex.org/W2133257461", "https://openalex.org/W2136922672", "https://openalex.org/W2137234026", "https://openalex.org/W2139427956", "https://openalex.org/W2142615865", "https://openalex.org/W2145889472", "https://openalex.org/W2147800946", "https://openalex.org/W2155904486", "https://openalex.org/W2158164339", "https://openalex.org/W2159291644", "https://openalex.org/W2162915993", "https://openalex.org/W2165720259", "https://openalex.org/W2165828254", "https://openalex.org/W2168002178", "https://openalex.org/W2597289420", "https://openalex.org/W2963909185", "https://openalex.org/W2990138404", "https://openalex.org/W66118917"]}, {"ref_id": "b43", "matched_paper_id": 206591781, "title": "Learning hierarchical representations for face verification with convolutional deep belief networks", "metadata": {"corpusId": "206591781", "paperId": "21346e7fdffe3a388a62ef5edeb3a0a9736b903b", "doi": "10.1109/CVPR.2012.6247968", "url": "https://www.semanticscholar.org/paper/21346e7fdffe3a388a62ef5edeb3a0a9736b903b", "abstract": "Most modern face recognition systems rely on a feature representation given by a hand-crafted image descriptor, such as Local Binary Patterns (LBP), and achieve improved performance by combining several such representations. In this paper, we propose deep learning as a natural source for obtaining additional, complementary representations. To learn features in high-resolution images, we make use of convolutional deep belief networks. Moreover, to take advantage of global structure in an object class, we develop local convolutional restricted Boltzmann machines, a novel convolutional learning model that exploits the global structure by not assuming stationarity of features across the image, while maintaining scalability and robustness to small misalignments. We also present a novel application of deep learning to descriptors other than pixel intensity values, such as LBP. In addition, we compare performance of networks trained using unsupervised learning against networks with random filters, and empirically show that learning weights not only is necessary for obtaining good multilayer representations, but also provides robustness to the choice of the network architecture parameters. Finally, we show that a recognition system using only representations obtained from deep learning can achieve comparable accuracy with a system using a combination of hand-crafted image descriptors. Moreover, by combining these representations, we achieve state-of-the-art results on a real-world face verification database.", "year": 2012, "referenceCount": 43, "citationCount": 424, "influentialCitationCount": 26, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2012-06-16", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2012 IEEE Conference on Computer Vision and Pattern Recognition", "volume": "", "issue": "", "pages": "2518-2525", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3219900", "name": "Gary B. Huang", "hIndex": 9, "citationCount": 8598, "paperCount": 15}, {"authorId": "1697141", "name": "Honglak Lee", "hIndex": 88, "citationCount": 53607, "paperCount": 187}, {"authorId": "1389846455", "name": "E. Learned-Miller", "hIndex": 43, "citationCount": 13730, "paperCount": 148}], "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that a recognition system using only representations obtained from deep learning can achieve comparable accuracy with a system using a combination of hand-crafted image descriptors, and empirically show that learning weights not only is necessary for obtaining good multilayer representations, but also provides robustness to the choice of the network architecture parameters."}, "topics": ["Face recognition and analysis", "Face and Expression Recognition", "Advanced Image and Video Retrieval Techniques"], "keywords": ["Robustness", "Feature Learning"], "mesh": [], "referenced_works_count": 42}, "referenced_works": ["https://openalex.org/W1479807131", "https://openalex.org/W1498305593", "https://openalex.org/W1509928947", "https://openalex.org/W1571024744", "https://openalex.org/W1665214252", "https://openalex.org/W1782590233", "https://openalex.org/W1971014294", "https://openalex.org/W1982048725", "https://openalex.org/W1983334819", "https://openalex.org/W1989975849", "https://openalex.org/W1994197834", "https://openalex.org/W1995997122", "https://openalex.org/W2008932806", "https://openalex.org/W2020315425", "https://openalex.org/W2039051707", "https://openalex.org/W2090042335", "https://openalex.org/W2097018403", "https://openalex.org/W2097089247", "https://openalex.org/W2105728138", "https://openalex.org/W2108665656", "https://openalex.org/W2109824782", "https://openalex.org/W2110798204", "https://openalex.org/W2113606819", "https://openalex.org/W2116064496", "https://openalex.org/W2120002154", "https://openalex.org/W2122922389", "https://openalex.org/W2130184048", "https://openalex.org/W2130325614", "https://openalex.org/W2136922672", "https://openalex.org/W2137313500", "https://openalex.org/W2138448681", "https://openalex.org/W2139427956", "https://openalex.org/W2142947774", "https://openalex.org/W2145889472", "https://openalex.org/W2151103935", "https://openalex.org/W2165052637", "https://openalex.org/W2169495281", "https://openalex.org/W2172174689", "https://openalex.org/W2293078015", "https://openalex.org/W2536626143", "https://openalex.org/W2546302380", "https://openalex.org/W78356000"]}, {"ref_id": "b44", "matched_paper_id": 877639, "title": "Deep boltzmann machines", "metadata": {"corpusId": "877639", "paperId": "ddc45fad8d15771d9f1f8579331458785b2cdd93", "doi": "", "url": "https://www.semanticscholar.org/paper/ddc45fad8d15771d9f1f8579331458785b2cdd93", "abstract": null, "year": 2009, "referenceCount": 22, "citationCount": 2254, "influentialCitationCount": 237, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2009-04-15", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "448-455", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "145124475", "name": "R. Salakhutdinov", "hIndex": 115, "citationCount": 153851, "paperCount": 363}, {"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}], "tldr": {"model": "tldr@v2.0.0", "text": "A new learning algorithm for Boltzmann machines that contain many layers of hidden variables that is made more efficient by using a layer-by-layer “pre-training” phase that allows variational inference to be initialized with a single bottomup pass."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b45", "matched_paper_id": 15419929, "title": "On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates", "metadata": {"corpusId": "15419929", "paperId": "ca9b21e84ffc7e193d1b3bb45fb7c4e48226b59e", "doi": "10.1080/17442509908834179", "url": "https://www.semanticscholar.org/paper/ca9b21e84ffc7e193d1b3bb45fb7c4e48226b59e", "abstract": "We analyse the convergence of stochastic algorithms with Markovian noise when the ergodicity of the Markov chain governing the noise rapidly decreases as the control parameter tends to infinity. In such a case, there may be a positive probability of divergence of the algorithm in the classic Robbins-Monro form. We provide sufficient condition which ensure convergence. Moreover, we analyse the asymptotic behaviour of these algorithms and state a diffusion approximation theorem", "year": 1999, "referenceCount": 24, "citationCount": 166, "influentialCitationCount": 21, "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "1999-02-01", "publicationTypes": null, "journal": {"name": "Stochastics and Stochastics Reports", "volume": "65", "issue": "", "pages": "177-228", "id": "https://openalex.org/S175432185", "h_index": 61, "i10_index": 348, "2yr_mean_citedness": 0.0, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1721284", "name": "L. Younes", "hIndex": 54, "citationCount": 11584, "paperCount": 222}], "tldr": {"model": "tldr@v2.0.0", "text": "This work analyses the convergence of stochastic algorithms with Markovian noise when the ergodicity of the Markov chain governing the noise rapidly decreases as the control parameter tends to infinity and provides sufficient condition which ensure convergence."}, "topics": ["Markov Chains and Monte Carlo Methods", "Stochastic processes and statistical mechanics", "Stochastic processes and financial applications"], "keywords": ["Ergodicity", "Divergence (linguistics)", "Infinity", "Weak convergence"], "mesh": [], "referenced_works_count": 19}, "referenced_works": ["https://openalex.org/W107938046", "https://openalex.org/W125195847", "https://openalex.org/W1568229137", "https://openalex.org/W1604521381", "https://openalex.org/W1605620359", "https://openalex.org/W1969238664", "https://openalex.org/W1994616650", "https://openalex.org/W2020999234", "https://openalex.org/W2043285245", "https://openalex.org/W2055649245", "https://openalex.org/W2088794759", "https://openalex.org/W2090340215", "https://openalex.org/W2114220616", "https://openalex.org/W2120170476", "https://openalex.org/W2132353975", "https://openalex.org/W2132565565", "https://openalex.org/W2168727351", "https://openalex.org/W2235056388", "https://openalex.org/W75971611"]}, {"ref_id": "b46", "matched_paper_id": 9383489, "title": "Efficient learning of deep Boltzmann machines", "metadata": {"corpusId": "9383489", "paperId": "00cd1dab559a9671b692f39f14c1573ab2d1416b", "doi": "", "url": "https://www.semanticscholar.org/paper/00cd1dab559a9671b692f39f14c1573ab2d1416b", "abstract": null, "year": 2010, "referenceCount": 18, "citationCount": 401, "influentialCitationCount": 27, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2010-03-31", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "693-700", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "145124475", "name": "R. Salakhutdinov", "hIndex": 115, "citationCount": 153851, "paperCount": 363}, {"authorId": "1777528", "name": "H. Larochelle", "hIndex": 67, "citationCount": 66479, "paperCount": 147}], "tldr": {"model": "tldr@v2.0.0", "text": "A new approximate inference algorithm for Deep Boltzmann Machines (DBM’s), a generative model with many layers of hidden variables, that learns a separate “recognition” model that is used to quickly initialize, in a single bottom-up pass, the values of the latent variables in all hidden layers."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b47", "matched_paper_id": 710430, "title": "Multimodal learning with deep Boltzmann machines", "metadata": {"corpusId": "710430", "paperId": "adb4ea2c0f3eff8a17c97a67f28b923e8e5bdff1", "doi": "10.5555/2627435.2697059", "url": "https://www.semanticscholar.org/paper/adb4ea2c0f3eff8a17c97a67f28b923e8e5bdff1", "abstract": "Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct st...", "year": 2012, "referenceCount": 44, "citationCount": 1709, "influentialCitationCount": 118, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2012-12-03", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "2231-2239", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2897313", "name": "Nitish Srivastava", "hIndex": 23, "citationCount": 53935, "paperCount": 42}, {"authorId": "145124475", "name": "R. Salakhutdinov", "hIndex": 115, "citationCount": 153851, "paperCount": 363}], "tldr": {"model": "tldr@v2.0.0", "text": "A Deep Boltzmann Machine is proposed for learning a generative model of multimodal data and it is shown that the model can be used to create fused representations by combining features across modalities, which are useful for classification and information retrieval."}, "topics": ["Generative Adversarial Networks and Image Synthesis"], "keywords": ["Boltzmann machine", "Restricted Boltzmann machine"], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b48", "matched_paper_id": 12487239, "title": "An efficient learning procedure for deep Boltzmann machines", "metadata": {"corpusId": "12487239", "paperId": "d4599b177559dd5ede4dda9d6d96aa149fc71942", "doi": "10.1162/NECO_a_00311", "url": "https://www.semanticscholar.org/paper/d4599b177559dd5ede4dda9d6d96aa149fc71942", "abstract": "We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent statistics are estimated using a variational approximation that tends to focus on a single mode, and data-independent statistics are estimated using persistent Markov chains. The use of two quite different techniques for estimating the two types of statistic that enter into the gradient of the log likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer pretraining phase that initializes the weights sensibly. The pretraining also allows the variational inference to be initialized sensibly with a single bottom-up pass. We present results on the MNIST and NORB data sets showing that deep Boltzmann machines learn very good generative models of handwritten digits and 3D objects. We also show that the features discovered by deep Boltzmann machines are a very effective way to initialize the hidden layers of feedforward neural nets, which are then discriminatively fine-tuned.", "year": 2012, "referenceCount": 62, "citationCount": 438, "influentialCitationCount": 38, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2012-08-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Neural Computation", "volume": "24", "issue": "", "pages": "1967-2006", "id": "https://openalex.org/S207023548", "h_index": 248, "i10_index": 2520, "2yr_mean_citedness": 2.7464788732394365, "is_core": true, "type": "journal"}, "authors": [{"authorId": "145124475", "name": "R. Salakhutdinov", "hIndex": 115, "citationCount": 153851, "paperCount": 363}, {"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}], "tldr": {"model": "tldr@v2.0.0", "text": "A new learning algorithm for Boltzmann machines that contain many layers of hidden variables is presented and results on the MNIST and NORB data sets are presented showing that deep BoltZmann machines learn very good generative models of handwritten digits and 3D objects."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Music and Audio Processing", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Boltzmann machine", "Restricted Boltzmann machine", "MNIST database", "Boltzmann constant", "Deep belief network"], "mesh": [], "referenced_works_count": 74}, "referenced_works": ["https://openalex.org/W142185896", "https://openalex.org/W145818128", "https://openalex.org/W1513873506", "https://openalex.org/W1516111018", "https://openalex.org/W1526741802", "https://openalex.org/W1543614656", "https://openalex.org/W1578739277", "https://openalex.org/W1665214252", "https://openalex.org/W1746680969", "https://openalex.org/W177847060", "https://openalex.org/W1813659000", "https://openalex.org/W189596042", "https://openalex.org/W193851967", "https://openalex.org/W1981276685", "https://openalex.org/W1990838964", "https://openalex.org/W1993882792", "https://openalex.org/W1994616650", "https://openalex.org/W1997865285", "https://openalex.org/W1999817190", "https://openalex.org/W2020999234", "https://openalex.org/W2024060531", "https://openalex.org/W2025768430", "https://openalex.org/W2029949252", "https://openalex.org/W2037048515", "https://openalex.org/W2043285245", "https://openalex.org/W205159212", "https://openalex.org/W2064487597", "https://openalex.org/W2072128103", "https://openalex.org/W2081801065", "https://openalex.org/W2083380015", "https://openalex.org/W2084336274", "https://openalex.org/W2096192494", "https://openalex.org/W2099866409", "https://openalex.org/W2099939455", "https://openalex.org/W2100002341", "https://openalex.org/W2100495367", "https://openalex.org/W2100618437", "https://openalex.org/W2102409316", "https://openalex.org/W2103359087", "https://openalex.org/W2110361616", "https://openalex.org/W2110798204", "https://openalex.org/W2116064496", "https://openalex.org/W2116825644", "https://openalex.org/W2124914669", "https://openalex.org/W2129363682", "https://openalex.org/W2132172482", "https://openalex.org/W2134557905", "https://openalex.org/W2134653808", "https://openalex.org/W2135884179", "https://openalex.org/W2136922672", "https://openalex.org/W2139427956", "https://openalex.org/W2142773971", "https://openalex.org/W2144935315", "https://openalex.org/W2149845449", "https://openalex.org/W2150529939", "https://openalex.org/W2157002241", "https://openalex.org/W2157629899", "https://openalex.org/W2159737176", "https://openalex.org/W2246822104", "https://openalex.org/W2346626577", "https://openalex.org/W2567948266", "https://openalex.org/W2595697910", "https://openalex.org/W2596585349", "https://openalex.org/W2597289420", "https://openalex.org/W2612972698", "https://openalex.org/W2613634265", "https://openalex.org/W2725061391", "https://openalex.org/W2990138404", "https://openalex.org/W3014462022", "https://openalex.org/W4231109964", "https://openalex.org/W4236965008", "https://openalex.org/W44815768", "https://openalex.org/W645920547", "https://openalex.org/W66838807"]}, {"ref_id": "b49", "matched_paper_id": 8717922, "title": "A better way to pretrain Deep Boltzmann Machines", "metadata": {"corpusId": "8717922", "paperId": "9e2fd6034db8d0c733cd17f8e76372b86b0d35bf", "doi": "", "url": "https://www.semanticscholar.org/paper/9e2fd6034db8d0c733cd17f8e76372b86b0d35bf", "abstract": null, "year": 2012, "referenceCount": 15, "citationCount": 132, "influentialCitationCount": 12, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2012-12-03", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "2456-2464", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "145124475", "name": "R. Salakhutdinov", "hIndex": 115, "citationCount": 153851, "paperCount": 363}, {"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}], "tldr": {"model": "tldr@v2.0.0", "text": "A different method of pretraining DBMs is developed that distributes the modelling work more evenly over the hidden layers and demonstrates that the new pretraining algorithm allows us to learn better generative models."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b50", "matched_paper_id": 7178848, "title": "A two-stage pretraining algorithm for deep boltzmann machines", "metadata": {"corpusId": "7178848", "paperId": "4e0f2f7aefed61bebe686a9c188506f848958581", "doi": "10.1007/978-3-642-40728-4_14", "url": "https://www.semanticscholar.org/paper/4e0f2f7aefed61bebe686a9c188506f848958581", "abstract": null, "year": 2013, "referenceCount": 52, "citationCount": 25, "influentialCitationCount": 2, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2013-09-10", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "106-113", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1979489", "name": "Kyunghyun Cho", "hIndex": 90, "citationCount": 117197, "paperCount": 328}, {"authorId": "2785022", "name": "T. Raiko", "hIndex": 32, "citationCount": 6822, "paperCount": 136}, {"authorId": "145096481", "name": "A. Ilin", "hIndex": 26, "citationCount": 2381, "paperCount": 119}, {"authorId": "1703769", "name": "J. Karhunen", "hIndex": 42, "citationCount": 16753, "paperCount": 245}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper shows empirically that the proposed method overcomes the difficulty in training DBMs from randomly initialized parameters and results in a better, or comparable, generative model when compared to the conventional pretraining algorithm."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Music and Audio Processing", "Advanced Neural Network Applications"], "keywords": ["Boltzmann machine", "Restricted Boltzmann machine", "Boltzmann constant", "Generative model", "Markov random field"], "mesh": [], "referenced_works_count": 50}, "referenced_works": ["https://openalex.org/W115070352", "https://openalex.org/W142185896", "https://openalex.org/W1498436455", "https://openalex.org/W1506806321", "https://openalex.org/W1569512666", "https://openalex.org/W1598712055", "https://openalex.org/W1663973292", "https://openalex.org/W177847060", "https://openalex.org/W1813659000", "https://openalex.org/W1835073532", "https://openalex.org/W1844261860", "https://openalex.org/W1876224860", "https://openalex.org/W189596042", "https://openalex.org/W1904365287", "https://openalex.org/W193851967", "https://openalex.org/W196761320", "https://openalex.org/W2013035813", "https://openalex.org/W2051144468", "https://openalex.org/W2054912984", "https://openalex.org/W2071709160", "https://openalex.org/W2098617596", "https://openalex.org/W2099939455", "https://openalex.org/W2100495367", "https://openalex.org/W2103819961", "https://openalex.org/W2106272619", "https://openalex.org/W2110798204", "https://openalex.org/W2112796928", "https://openalex.org/W2116064496", "https://openalex.org/W2116825644", "https://openalex.org/W2125113755", "https://openalex.org/W2132023809", "https://openalex.org/W2134842679", "https://openalex.org/W2136922672", "https://openalex.org/W2136936677", "https://openalex.org/W2145094598", "https://openalex.org/W2148862211", "https://openalex.org/W2150529939", "https://openalex.org/W2152424459", "https://openalex.org/W2155111216", "https://openalex.org/W2163922914", "https://openalex.org/W2171282218", "https://openalex.org/W2184970173", "https://openalex.org/W2200708944", "https://openalex.org/W2289330286", "https://openalex.org/W2522381472", "https://openalex.org/W2601260342", "https://openalex.org/W28766783", "https://openalex.org/W3106144113", "https://openalex.org/W4285719527", "https://openalex.org/W60493759"]}, {"ref_id": "b51", "matched_paper_id": 6087730, "title": "Deep Boltzmann Machines and the Centering Trick", "metadata": {"corpusId": "6087730", "paperId": "68e3fca8f6f60ca1c70854b9d09228ece37f02b2", "doi": "10.1007/978-3-642-35289-8_33", "url": "https://www.semanticscholar.org/paper/68e3fca8f6f60ca1c70854b9d09228ece37f02b2", "abstract": null, "year": 2012, "referenceCount": 26, "citationCount": 85, "influentialCitationCount": 12, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2012-12-01", "publicationTypes": null, "journal": {"name": "", "volume": "", "issue": "", "pages": "621-637", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "144535526", "name": "G. Montavon", "hIndex": 37, "citationCount": 18133, "paperCount": 105}, {"authorId": "145034054", "name": "K. Müller", "hIndex": 130, "citationCount": 95666, "paperCount": 655}], "tldr": {"model": "tldr@v2.0.0", "text": "This chapter presents the \"centering trick\" that consists of rewriting the energy of the system as a function of centered states, which improves the conditioning of the underlying optimization problem and makes learning more stable, leading to models with better generative and discriminative properties."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Model Reduction and Neural Networks", "Music and Audio Processing"], "keywords": ["Boltzmann machine", "Discriminative model", "Representation", "Restricted Boltzmann machine", "Generative model"], "mesh": [], "referenced_works_count": 29}, "referenced_works": ["https://openalex.org/W1480347379", "https://openalex.org/W1493372406", "https://openalex.org/W1513873506", "https://openalex.org/W1533861849", "https://openalex.org/W1547224907", "https://openalex.org/W1576278180", "https://openalex.org/W1629097610", "https://openalex.org/W1811843574", "https://openalex.org/W189596042", "https://openalex.org/W2006903949", "https://openalex.org/W2071709160", "https://openalex.org/W2086161653", "https://openalex.org/W2088032561", "https://openalex.org/W2096192494", "https://openalex.org/W2116064496", "https://openalex.org/W2116825644", "https://openalex.org/W2122565151", "https://openalex.org/W2140095548", "https://openalex.org/W2150529939", "https://openalex.org/W2158413235", "https://openalex.org/W2188343820", "https://openalex.org/W2200708944", "https://openalex.org/W2294861638", "https://openalex.org/W2584957546", "https://openalex.org/W2914484425", "https://openalex.org/W3207342693", "https://openalex.org/W4212915314", "https://openalex.org/W4238404964", "https://openalex.org/W44815768"]}, {"ref_id": "b52", "matched_paper_id": 6442575, "title": "Multi-prediction deep Boltzmann machines", "metadata": {"corpusId": "6442575", "paperId": "5656fa5aa6e1beeb98703fc53ec112ad227c49ca", "doi": "", "url": "https://www.semanticscholar.org/paper/5656fa5aa6e1beeb98703fc53ec112ad227c49ca", "abstract": null, "year": 2013, "referenceCount": 25, "citationCount": 138, "influentialCitationCount": 18, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-12-05", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "548-556", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "153440022", "name": "I. Goodfellow", "hIndex": 64, "citationCount": 142902, "paperCount": 103}, {"authorId": "153583218", "name": "Mehdi Mirza", "hIndex": 19, "citationCount": 60214, "paperCount": 25}, {"authorId": "1760871", "name": "Aaron C. Courville", "hIndex": 90, "citationCount": 116603, "paperCount": 242}, {"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}], "tldr": {"model": "tldr@v2.0.0", "text": "The multi-prediction deep Boltzmann machine does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b53", "matched_paper_id": 206775335, "title": "Auto-association by multilayer perceptrons and singular value decomposition", "metadata": {"corpusId": "206775335", "paperId": "f5821548720901c89b3b7481f7500d7cd64e99bd", "doi": "10.1007/BF00332918", "url": "https://www.semanticscholar.org/paper/f5821548720901c89b3b7481f7500d7cd64e99bd", "abstract": null, "year": 1988, "referenceCount": 13, "citationCount": 1144, "influentialCitationCount": 56, "fieldsOfStudy": ["Mathematics", "Medicine"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "1988-09-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Biological Cybernetics", "volume": "59", "issue": "", "pages": "291-294", "id": "https://openalex.org/S87357125", "h_index": 204, "i10_index": 2899, "2yr_mean_citedness": 1.7692307692307692, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2065228513", "name": "H. Bourlard", "hIndex": 14, "citationCount": 2312, "paperCount": 34}, {"authorId": "2396055", "name": "Y. Kamp", "hIndex": 5, "citationCount": 1379, "paperCount": 11}], "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that, for auto-association, the nonlinearities of the hidden units are useless and that the optimal parameter values can be derived directly by purely linear techniques relying on singular value decomposition and low rank matrix approximation, similar in spirit to the well-known Karhunen-Loève transform."}, "topics": ["Neural Networks and Applications", "Blind Source Separation Techniques", "Image and Signal Denoising Methods"], "keywords": ["Perceptron", "Singular value", "Rank (graph theory)", "Matrix (chemical analysis)"], "mesh": ["Models, Neurological/None", "Nerve Net/physiology", "Nervous System Physiological Phenomena/None", "Mathematics/None", "Nerve Net/None"], "referenced_works_count": 13}, "referenced_works": ["https://openalex.org/W1587863748", "https://openalex.org/W2016059698", "https://openalex.org/W2046432185", "https://openalex.org/W2062481674", "https://openalex.org/W2101927907", "https://openalex.org/W2135622428", "https://openalex.org/W2163165400", "https://openalex.org/W2743834670", "https://openalex.org/W2766736793", "https://openalex.org/W2798909945", "https://openalex.org/W3207342693", "https://openalex.org/W4239894305", "https://openalex.org/W4300402905"]}, {"ref_id": "b54", "matched_paper_id": 18490972, "title": "Nonlinear autoassociation is not equivalent to PCA", "metadata": {"corpusId": "18490972", "paperId": "36473661a17a4b97a92ce9c4324ee669bd0a59d5", "doi": "10.1162/089976600300015691", "url": "https://www.semanticscholar.org/paper/36473661a17a4b97a92ce9c4324ee669bd0a59d5", "abstract": "A common misperception within the neural network community is that even with nonlinearities in their hidden layer, autoassociators trained with backpropagation are equivalent to linear methods such as principal component analysis (PCA). Our purpose is to demonstrate that nonlinear autoassociators actually behave differently from linear methods and that they can outperform these methods when used for latent extraction, projection, and classification. While linear autoassociators emulate PCA, and thus exhibit a flat or unimodal reconstruction error surface, autoassociators with nonlinearities in their hidden layer learn domains by building error reconstruction surfaces that, depending on the task, contain multiple local valleys. This interpolation bias allows nonlinear autoassociators to represent appropriate classifications of nonlinear multimodal domains, in contrast to linear autoassociators, which are inappropriate for such tasks. In fact, autoassociators with hidden unit nonlinearities can be shown to perform nonlinear classification and nonlinear recognition.", "year": 2000, "referenceCount": 16, "citationCount": 184, "influentialCitationCount": 10, "fieldsOfStudy": ["Mathematics", "Medicine", "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2000-03-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Neural Computation", "volume": "12", "issue": "", "pages": "531-545", "id": "https://openalex.org/S207023548", "h_index": 248, "i10_index": 2520, "2yr_mean_citedness": 2.7464788732394365, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1743642", "name": "N. Japkowicz", "hIndex": 42, "citationCount": 17446, "paperCount": 228}, {"authorId": "1727849", "name": "S. Hanson", "hIndex": 33, "citationCount": 5397, "paperCount": 156}, {"authorId": "1738203", "name": "M. Gluck", "hIndex": 50, "citationCount": 13255, "paperCount": 212}], "tldr": {"model": "tldr@v2.0.0", "text": "It is demonstrated that nonlinear autoassociators actually behave differently from linear methods and that they can outperform these methods when used for latent extraction, projection, and classification."}, "topics": ["Neural Networks and Applications", "Neural Networks and Reservoir Computing", "Model Reduction and Neural Networks"], "keywords": ["Backpropagation", "Interpolation"], "mesh": ["Neural Networks, Computer/None", "Nonlinear Dynamics/None", "Linear Models/None", "Normal Distribution/None", "Reproducibility of Results/None"], "referenced_works_count": 12}, "referenced_works": ["https://openalex.org/W1224536253", "https://openalex.org/W1503432700", "https://openalex.org/W1564660545", "https://openalex.org/W2017257315", "https://openalex.org/W2045817341", "https://openalex.org/W2078626246", "https://openalex.org/W2082037239", "https://openalex.org/W2111278976", "https://openalex.org/W2129916169", "https://openalex.org/W2151928390", "https://openalex.org/W2766736793", "https://openalex.org/W584589991"]}, {"ref_id": "b55", "matched_paper_id": 207168299, "title": "Extracting and composing robust features with denoising autoencoders", "metadata": {"corpusId": "207168299", "paperId": "843959ffdccf31c6694d135fad07425924f785b1", "doi": "10.1145/1390156.1390294", "url": "https://www.semanticscholar.org/paper/843959ffdccf31c6694d135fad07425924f785b1", "abstract": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.", "year": 2008, "referenceCount": 29, "citationCount": 7413, "influentialCitationCount": 475, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2008-07-05", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "1096-1103", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "120247189", "name": "Pascal Vincent", "hIndex": 21, "citationCount": 22753, "paperCount": 61}, {"authorId": "1777528", "name": "H. Larochelle", "hIndex": 67, "citationCount": 66479, "paperCount": 147}, {"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}, {"authorId": "1798462", "name": "Pierre-Antoine Manzagol", "hIndex": 12, "citationCount": 18225, "paperCount": 15}], "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Music and Audio Processing", "Image Processing and 3D Reconstruction"], "keywords": ["Discriminative model", "Benchmark (surveying)", "Representation", "Feature Learning"], "mesh": [], "referenced_works_count": 23}, "referenced_works": ["https://openalex.org/W1498436455", "https://openalex.org/W1526741802", "https://openalex.org/W1586881595", "https://openalex.org/W1994197834", "https://openalex.org/W2072128103", "https://openalex.org/W2100495367", "https://openalex.org/W2108665656", "https://openalex.org/W2110798204", "https://openalex.org/W2111406701", "https://openalex.org/W2112812053", "https://openalex.org/W2128076038", "https://openalex.org/W2128084896", "https://openalex.org/W2131686571", "https://openalex.org/W2133257461", "https://openalex.org/W2136922672", "https://openalex.org/W2149384588", "https://openalex.org/W2153014441", "https://openalex.org/W2153663612", "https://openalex.org/W2172174689", "https://openalex.org/W2176028050", "https://openalex.org/W2609208295", "https://openalex.org/W2613634265", "https://openalex.org/W3207342693"]}, {"ref_id": "b56", "matched_paper_id": null, "title": "Memoires associatives distribuees"}, {"ref_id": "b57", "matched_paper_id": 14805281, "title": "An empirical evaluation of deep architectures on problems with many factors of variation", "metadata": {"corpusId": "14805281", "paperId": "b8012351bc5ebce4a4b3039bbbba3ce393bc3315", "doi": "10.1145/1273496.1273556", "url": "https://www.semanticscholar.org/paper/b8012351bc5ebce4a4b3039bbbba3ce393bc3315", "abstract": "Recently, several learning algorithms relying on models with deep architectures have been proposed. Though they have demonstrated impressive performance, to date, they have only been evaluated on relatively simple problems such as digit recognition in a controlled environment, for which many machine learning algorithms already report reasonable results. Here, we present a series of experiments which indicate that these models show promise in solving harder learning problems that exhibit many factors of variation. These models are compared with well-established algorithms such as Support Vector Machines and single hidden-layer feed-forward neural networks.", "year": 2007, "referenceCount": 13, "citationCount": 1155, "influentialCitationCount": 113, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2007-06-20", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "473-480", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1777528", "name": "H. Larochelle", "hIndex": 67, "citationCount": 66479, "paperCount": 147}, {"authorId": "1761978", "name": "D. Erhan", "hIndex": 37, "citationCount": 113969, "paperCount": 60}, {"authorId": "1760871", "name": "Aaron C. Courville", "hIndex": 90, "citationCount": 116603, "paperCount": 242}, {"authorId": "32837403", "name": "J. Bergstra", "hIndex": 26, "citationCount": 27083, "paperCount": 43}, {"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}], "tldr": {"model": "tldr@v2.0.0", "text": "A series of experiments indicate that these models with deep architectures show promise in solving harder learning problems that exhibit many factors of variation."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Neural Networks and Applications", "Anomaly Detection Techniques and Applications"], "keywords": ["Variation (astronomy)"], "mesh": [], "referenced_works_count": 13}, "referenced_works": ["https://openalex.org/W1526741802", "https://openalex.org/W1543614656", "https://openalex.org/W205159212", "https://openalex.org/W2100495367", "https://openalex.org/W2110798204", "https://openalex.org/W2116064496", "https://openalex.org/W2124914669", "https://openalex.org/W2134557905", "https://openalex.org/W2136922672", "https://openalex.org/W2147800946", "https://openalex.org/W2153635508", "https://openalex.org/W2159737176", "https://openalex.org/W2613634265"]}, {"ref_id": "b58", "matched_paper_id": 14201947, "title": "Greedy layer-wise training of deep networks", "metadata": {"corpusId": "14201947", "paperId": "355d44f53428b1ac4fb2ab468d593c720640e5bd", "doi": "10.7551/mitpress/7503.003.0024", "url": "https://www.semanticscholar.org/paper/355d44f53428b1ac4fb2ab468d593c720640e5bd", "abstract": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization.", "year": 2006, "referenceCount": 18, "citationCount": 5256, "influentialCitationCount": 311, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2006-12-04", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "153-160", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1751762", "name": "Yoshua Bengio", "hIndex": 208, "citationCount": 510079, "paperCount": 817}, {"authorId": "3087941", "name": "Pascal Lamblin", "hIndex": 13, "citationCount": 13134, "paperCount": 18}, {"authorId": "32384143", "name": "D. Popovici", "hIndex": 19, "citationCount": 7045, "paperCount": 82}, {"authorId": "1777528", "name": "H. Larochelle", "hIndex": 67, "citationCount": 66479, "paperCount": 147}], "tldr": {"model": "tldr@v2.0.0", "text": "These experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization."}, "topics": ["Generative Adversarial Networks and Image Synthesis", "Stochastic Gradient Optimization Techniques", "Adversarial Robustness in Machine Learning"], "keywords": [], "mesh": [], "referenced_works_count": 16}, "referenced_works": ["https://openalex.org/W1509849361", "https://openalex.org/W1966347487", "https://openalex.org/W1993845689", "https://openalex.org/W2017290750", "https://openalex.org/W2100495367", "https://openalex.org/W2103369448", "https://openalex.org/W2103626435", "https://openalex.org/W2109779438", "https://openalex.org/W2116064496", "https://openalex.org/W2124914669", "https://openalex.org/W2125569215", "https://openalex.org/W2128076038", "https://openalex.org/W2130313186", "https://openalex.org/W2136922672", "https://openalex.org/W2167967601", "https://openalex.org/W2613634265"]}, {"ref_id": "b59", "matched_paper_id": 216077384, "title": "Selective search for object recognition", "metadata": {"corpusId": "216077384", "paperId": "9b223c8a31e0ea1d1f2c9787ffd8416dfc90c912", "doi": "10.1007/s11263-013-0620-5", "url": "https://www.semanticscholar.org/paper/9b223c8a31e0ea1d1f2c9787ffd8416dfc90c912", "abstract": null, "year": 2013, "referenceCount": 49, "citationCount": 5430, "influentialCitationCount": 452, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-04-02", "publicationTypes": ["JournalArticle"], "journal": {"name": "International Journal of Computer Vision", "volume": "104", "issue": "", "pages": "154 - 171", "id": "https://openalex.org/S25538012", "h_index": 283, "i10_index": 2338, "2yr_mean_citedness": 10.77304964539007, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2242508491", "name": "Jasper R. R. Uijlings", "hIndex": 4, "citationCount": 5468, "paperCount": 5}, {"authorId": "1756979", "name": "K. V. D. Sande", "hIndex": 24, "citationCount": 9919, "paperCount": 41}, {"authorId": "2257152645", "name": "Theo Gevers", "hIndex": 4, "citationCount": 5496, "paperCount": 5}, {"authorId": "144638781", "name": "A. Smeulders", "hIndex": 65, "citationCount": 40936, "paperCount": 493}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces selective search which combines the strength of both an exhaustive search and segmentation, and shows that its selective search enables the use of the powerful Bag-of-Words model for recognition."}, "topics": ["Advanced Image and Video Retrieval Techniques", "Robotics and Sensor-Based Localization", "Image Retrieval and Classification Techniques"], "keywords": [], "mesh": [], "referenced_works_count": 37}, "referenced_works": ["https://openalex.org/W1551774182", "https://openalex.org/W1555385401", "https://openalex.org/W1571024744", "https://openalex.org/W1606858007", "https://openalex.org/W1625255723", "https://openalex.org/W1673033634", "https://openalex.org/W1999478155", "https://openalex.org/W2017691720", "https://openalex.org/W2031489346", "https://openalex.org/W2056860348", "https://openalex.org/W2066624635", "https://openalex.org/W2067191022", "https://openalex.org/W2071527584", "https://openalex.org/W2091068168", "https://openalex.org/W2106255337", "https://openalex.org/W2106874006", "https://openalex.org/W2109370419", "https://openalex.org/W2110158442", "https://openalex.org/W2118087936", "https://openalex.org/W2120369594", "https://openalex.org/W2121947440", "https://openalex.org/W2128715914", "https://openalex.org/W2131846894", "https://openalex.org/W2134380836", "https://openalex.org/W2141357020", "https://openalex.org/W2151103935", "https://openalex.org/W2161969291", "https://openalex.org/W2162762921", "https://openalex.org/W2162915993", "https://openalex.org/W2163352848", "https://openalex.org/W2164598857", "https://openalex.org/W2168356304", "https://openalex.org/W2186094539", "https://openalex.org/W2296249689", "https://openalex.org/W2534457893", "https://openalex.org/W2538008885", "https://openalex.org/W3097096317"]}, {"ref_id": "b60", "matched_paper_id": 206770307, "title": "Fast R-CNN", "metadata": {"corpusId": "206770307", "paperId": "7ffdbc358b63378f07311e883dddacc9faeeaf4b", "doi": "", "url": "https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b", "abstract": "This paper proposes Fast R-CNN, a clean and fast framework for object detection. Compared to traditional R-CNN, and its accelerated version SPPnet, Fast R-CNN trains networks using a multi-task loss in a single training stage. The multi-task loss simplifies learning and improves detection accuracy. Unlike SPPnet, all network layers can be updated during fine-tuning. We show that this difference has practical ramifications for very deep networks, such as VGG16, where mAP suffers when only the fully-connected layers are updated. Compared to\"slow\"R-CNN, Fast R-CNN is 9x faster at training VGG16 for detection, 213x faster at test-time, and achieves a significantly higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn", "year": 2015, "referenceCount": 23, "citationCount": 24163, "influentialCitationCount": 3244, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-04-29", "publicationTypes": null, "journal": {"name": "", "volume": "", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2983898", "name": "Ross B. Girshick", "hIndex": 78, "citationCount": 333369, "paperCount": 112}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes Fast R-CNN, a clean and fast framework for object detection that trains networks using a multi-task loss in a single training stage and achieves a significantly higher mAP on PASCAL VOC 2012."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b61", "matched_paper_id": 10328909, "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "metadata": {"corpusId": "10328909", "paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "doi": "10.1109/TPAMI.2016.2577031", "url": "https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network(RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features-using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3], our detection system has a frame rate of 5 fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.", "year": 2015, "referenceCount": 47, "citationCount": 59766, "influentialCitationCount": 8925, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-06-04", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "39", "issue": "", "pages": "1137-1149", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "3080683", "name": "Shaoqing Ren", "hIndex": 13, "citationCount": 285050, "paperCount": 18}, {"authorId": "39353098", "name": "Kaiming He", "hIndex": 67, "citationCount": 454471, "paperCount": 84}, {"authorId": "2983898", "name": "Ross B. Girshick", "hIndex": 78, "citationCount": 333369, "paperCount": 112}, {"authorId": "2032184078", "name": "Jian Sun", "hIndex": 37, "citationCount": 72723, "paperCount": 57}], "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals and further merge RPN and Fast R-CNN into a single network by sharing their convolutionAL features."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Video Surveillance and Tracking Methods"], "keywords": [], "mesh": [], "referenced_works_count": 43}, "referenced_works": ["https://openalex.org/W1536680647", "https://openalex.org/W1594098193", "https://openalex.org/W1665214252", "https://openalex.org/W1686810756", "https://openalex.org/W1790312427", "https://openalex.org/W1832500336", "https://openalex.org/W1861492603", "https://openalex.org/W1903029394", "https://openalex.org/W1923115158", "https://openalex.org/W1958328135", "https://openalex.org/W1991367009", "https://openalex.org/W2031489346", "https://openalex.org/W2046382188", "https://openalex.org/W2066624635", "https://openalex.org/W2068730032", "https://openalex.org/W2088049833", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2104446196", "https://openalex.org/W2117287331", "https://openalex.org/W2117539524", "https://openalex.org/W2130306094", "https://openalex.org/W2147800946", "https://openalex.org/W2155893237", "https://openalex.org/W2168356304", "https://openalex.org/W2174407577", "https://openalex.org/W2179352600", "https://openalex.org/W2194775991", "https://openalex.org/W2206858481", "https://openalex.org/W2216125271", "https://openalex.org/W2229637417", "https://openalex.org/W2255499165", "https://openalex.org/W2618530766", "https://openalex.org/W2952009708", "https://openalex.org/W2962835968", "https://openalex.org/W2963542991", "https://openalex.org/W2963690996", "https://openalex.org/W2963758027", "https://openalex.org/W4309299128", "https://openalex.org/W639708223", "https://openalex.org/W7746136", "https://openalex.org/W809122546", "https://openalex.org/W854541894"]}, {"ref_id": "b62", "matched_paper_id": 5819909, "title": "How good are detection proposals, really", "metadata": {"corpusId": "5819909", "paperId": "7b1e6ed85dae91843f3d986a001fb59439adbc39", "doi": "10.5244/C.28.24", "url": "https://www.semanticscholar.org/paper/7b1e6ed85dae91843f3d986a001fb59439adbc39", "abstract": "Current top performing Pascal VOC object detectors employ detection proposals to guide the search for objects thereby avoiding exhaustive sliding window search across images. Despite the popularity of detection proposals, it is unclear which trade-offs are made when using them during object detection. We provide an in depth analysis of ten object proposal methods along with four baselines regarding ground truth annotation recall (on Pascal VOC 2007 and ImageNet 2013), repeatability, and impact on DPM detector performance. Our findings show common weaknesses of existing methods, and provide insights to choose the most adequate method for different settings.", "year": 2014, "referenceCount": 38, "citationCount": 272, "influentialCitationCount": 13, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-06-26", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "ArXiv", "volume": "abs/1406.6962", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2536361", "name": "J. Hosang", "hIndex": 15, "citationCount": 4420, "paperCount": 19}, {"authorId": "1798000", "name": "Rodrigo Benenson", "hIndex": 34, "citationCount": 20808, "paperCount": 61}, {"authorId": "48920094", "name": "B. Schiele", "hIndex": 132, "citationCount": 85527, "paperCount": 604}], "tldr": {"model": "tldr@v2.0.0", "text": "An in depth analysis of ten object proposal methods along with four baselines regarding ground truth annotation recall (on Pascal VOC 2007 and ImageNet 2013), repeatability, and impact on DPM detector performance are provided."}, "topics": ["Advanced Image and Video Retrieval Techniques", "Advanced Neural Network Applications", "Visual Attention and Saliency Detection"], "keywords": ["Pascal (unit)", "Popularity", "Sliding window protocol", "Ground truth", "Strengths and weaknesses"], "mesh": [], "referenced_works_count": 33}, "referenced_works": ["https://openalex.org/W1555385401", "https://openalex.org/W1832500336", "https://openalex.org/W1950935069", "https://openalex.org/W1991367009", "https://openalex.org/W1999478155", "https://openalex.org/W2008541429", "https://openalex.org/W2010181071", "https://openalex.org/W2017691720", "https://openalex.org/W2031489346", "https://openalex.org/W2035784046", "https://openalex.org/W2037227137", "https://openalex.org/W2042316011", "https://openalex.org/W2046382188", "https://openalex.org/W2061035601", "https://openalex.org/W2066624635", "https://openalex.org/W2088049833", "https://openalex.org/W2089359462", "https://openalex.org/W2102605133", "https://openalex.org/W2103897297", "https://openalex.org/W2106248527", "https://openalex.org/W2108598243", "https://openalex.org/W2110226160", "https://openalex.org/W2121660792", "https://openalex.org/W2128715914", "https://openalex.org/W2129305389", "https://openalex.org/W2159680539", "https://openalex.org/W2161198271", "https://openalex.org/W2163267793", "https://openalex.org/W2168356304", "https://openalex.org/W2534457893", "https://openalex.org/W25437484", "https://openalex.org/W3097096317", "https://openalex.org/W7746136"]}, {"ref_id": "b63", "matched_paper_id": 9272368, "title": "Simultaneous detection and segmentation", "metadata": {"corpusId": "9272368", "paperId": "342786659379879f58bf5c4ff43c84c83a6a7389", "doi": "10.1007/978-3-319-10584-0_20", "url": "https://www.semanticscholar.org/paper/342786659379879f58bf5c4ff43c84c83a6a7389", "abstract": "We aim to detect all instances of a category in an image and, for each instance, mark the pixels that belong to it. We call this task Simultaneous Detection and Segmentation (SDS). Unlike classical bounding box detection, SDS requires a segmentation and not just a box. Unlike classical semantic segmentation, we require individual object instances. We build on recent work that uses convolutional neural networks to classify category-independent region proposals (R-CNN [16]), introducing a novel architecture tailored for SDS. We then use category-specific, top-down figure-ground predictions to refine our bottom-up proposals. We show a 7 point boost (16% relative) over our baselines on SDS, a 5 point boost (10% relative) over state-of-the-art on semantic segmentation, and state-of-the-art performance in object detection. Finally, we provide diagnostic tools that unpack performance and provide directions for future work.", "year": 2014, "referenceCount": 36, "citationCount": 1279, "influentialCitationCount": 102, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-07-07", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "ArXiv", "volume": "abs/1407.1808", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "1790580", "name": "Bharath Hariharan", "hIndex": 37, "citationCount": 33925, "paperCount": 67}, {"authorId": "1778133", "name": "Pablo Arbeláez", "hIndex": 31, "citationCount": 19039, "paperCount": 64}, {"authorId": "2983898", "name": "Ross B. Girshick", "hIndex": 78, "citationCount": 333369, "paperCount": 112}, {"authorId": "143751119", "name": "Jitendra Malik", "hIndex": 137, "citationCount": 106659, "paperCount": 397}], "tldr": {"model": "tldr@v2.0.0", "text": "This work builds on recent work that uses convolutional neural networks to classify category-independent region proposals (R-CNN), introducing a novel architecture tailored for SDS, and uses category-specific, top-down figure-ground predictions to refine the bottom-up proposals."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Multimodal Machine Learning Applications"], "keywords": ["Minimum bounding box", "Bounding overwatch", "Segmentation-based object categorization"], "mesh": [], "referenced_works_count": 32}, "referenced_works": ["https://openalex.org/W1528789833", "https://openalex.org/W1610707153", "https://openalex.org/W1832500336", "https://openalex.org/W1864464506", "https://openalex.org/W191249702", "https://openalex.org/W1964005749", "https://openalex.org/W1991367009", "https://openalex.org/W2013777358", "https://openalex.org/W2017691720", "https://openalex.org/W2022508996", "https://openalex.org/W2031489346", "https://openalex.org/W2039507552", "https://openalex.org/W2056933870", "https://openalex.org/W2076874408", "https://openalex.org/W2083542343", "https://openalex.org/W2101926813", "https://openalex.org/W2102605133", "https://openalex.org/W2112357820", "https://openalex.org/W2115150266", "https://openalex.org/W2117539524", "https://openalex.org/W2129305389", "https://openalex.org/W2144794286", "https://openalex.org/W2147800946", "https://openalex.org/W2151103935", "https://openalex.org/W2155541015", "https://openalex.org/W2155893237", "https://openalex.org/W2161969291", "https://openalex.org/W2162741153", "https://openalex.org/W2163605009", "https://openalex.org/W2168356304", "https://openalex.org/W2963542991", "https://openalex.org/W78159342"]}, {"ref_id": "b64", "matched_paper_id": 3792560, "title": "Towards unified object detection and semantic segmentation", "metadata": {"corpusId": "3792560", "paperId": "aff7cad88753aa4af0b801c9ae32980fcddd6284", "doi": "10.1007/978-3-319-10602-1_20", "url": "https://www.semanticscholar.org/paper/aff7cad88753aa4af0b801c9ae32980fcddd6284", "abstract": null, "year": 2014, "referenceCount": 46, "citationCount": 70, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-09-06", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "299-314", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "145550812", "name": "Jian Dong", "hIndex": 16, "citationCount": 2278, "paperCount": 25}, {"authorId": "35370244", "name": "Qiang Chen", "hIndex": 16, "citationCount": 7892, "paperCount": 34}, {"authorId": "143653681", "name": "Shuicheng Yan", "hIndex": 135, "citationCount": 79394, "paperCount": 769}, {"authorId": "145081362", "name": "A. Yuille", "hIndex": 125, "citationCount": 94360, "paperCount": 758}], "tldr": {"model": "tldr@v2.0.0", "text": "Extensive experiments on the PASCAL VOC 2010 and 2012 datasets demonstrate encouraging performance of the proposed unified framework for both object detection and semantic segmentation tasks."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Multimodal Machine Learning Applications"], "keywords": ["Pascal (unit)", "Leverage (statistics)"], "mesh": [], "referenced_works_count": 46}, "referenced_works": ["https://openalex.org/W129876169", "https://openalex.org/W1542534308", "https://openalex.org/W1603728330", "https://openalex.org/W1606858007", "https://openalex.org/W1610707153", "https://openalex.org/W1832500336", "https://openalex.org/W1964005749", "https://openalex.org/W1974138240", "https://openalex.org/W1976921161", "https://openalex.org/W2013777358", "https://openalex.org/W2031489346", "https://openalex.org/W2037227137", "https://openalex.org/W2037511607", "https://openalex.org/W2039507552", "https://openalex.org/W2046382188", "https://openalex.org/W2055349880", "https://openalex.org/W2056933870", "https://openalex.org/W2066650804", "https://openalex.org/W2083542343", "https://openalex.org/W2088049833", "https://openalex.org/W2106317217", "https://openalex.org/W2106471914", "https://openalex.org/W2115150266", "https://openalex.org/W2117132237", "https://openalex.org/W2118585731", "https://openalex.org/W2125215748", "https://openalex.org/W2127194945", "https://openalex.org/W2130350952", "https://openalex.org/W2135706578", "https://openalex.org/W2141357020", "https://openalex.org/W2143729633", "https://openalex.org/W2144794286", "https://openalex.org/W2147196093", "https://openalex.org/W2151103935", "https://openalex.org/W2153185908", "https://openalex.org/W2154644822", "https://openalex.org/W2161561128", "https://openalex.org/W2161969291", "https://openalex.org/W2166765763", "https://openalex.org/W2168356304", "https://openalex.org/W2186094539", "https://openalex.org/W2296770417", "https://openalex.org/W2533218643", "https://openalex.org/W25437484", "https://openalex.org/W78159342", "https://openalex.org/W95916464"]}, {"ref_id": "b65", "matched_paper_id": 542190, "title": "SegDeepM: Exploiting segmentation and context in deep neural networks for object detection", "metadata": {"corpusId": "542190", "paperId": "9a29e4d43e94985c1d152e621764be93c286a78d", "doi": "10.1109/CVPR.2015.7299102", "url": "https://www.semanticscholar.org/paper/9a29e4d43e94985c1d152e621764be93c286a78d", "abstract": "In this paper, we propose an approach that exploits object segmentation in order to improve the accuracy of object detection. We frame the problem as inference in a Markov Random Field, in which each detection hypothesis scores object appearance as well as contextual information using Convolutional Neural Networks, and allows the hypothesis to choose and score a segment out of a large pool of accurate object segmentation proposals. This enables the detector to incorporate additional evidence when it is available and thus results in more accurate detections. Our experiments show an improvement of 4.1% in mAP over the R-CNN baseline on PASCAL VOC 2010, and 3.4% over the current state-of-the-art, demonstrating the power of our approach.", "year": 2015, "referenceCount": 26, "citationCount": 154, "influentialCitationCount": 11, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-02-14", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "4703-4711", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2334885409", "name": "Yukun Zhu", "hIndex": 6, "citationCount": 6902, "paperCount": 8}, {"authorId": "2422559", "name": "R. Urtasun", "hIndex": 110, "citationCount": 68767, "paperCount": 378}, {"authorId": "145124475", "name": "R. Salakhutdinov", "hIndex": 115, "citationCount": 153851, "paperCount": 363}, {"authorId": "37895334", "name": "S. Fidler", "hIndex": 87, "citationCount": 38649, "paperCount": 236}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper frames the problem as inference in a Markov Random Field, in which each detection hypothesis scores object appearance as well as contextual information using Convolutional Neural Networks, and allows the hypothesis to choose and score a segment out of a large pool of accurate object segmentation proposals."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Pascal (unit)", "Markov random field"], "mesh": [], "referenced_works_count": 26}, "referenced_works": ["https://openalex.org/W1507506748", "https://openalex.org/W1610707153", "https://openalex.org/W1686810756", "https://openalex.org/W1832500336", "https://openalex.org/W1864464506", "https://openalex.org/W1964005749", "https://openalex.org/W2017691720", "https://openalex.org/W2039507552", "https://openalex.org/W2056933870", "https://openalex.org/W2083542343", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2103897297", "https://openalex.org/W2104408738", "https://openalex.org/W2113221323", "https://openalex.org/W2125215748", "https://openalex.org/W2127251585", "https://openalex.org/W2129305389", "https://openalex.org/W2137881638", "https://openalex.org/W2161236525", "https://openalex.org/W2163605009", "https://openalex.org/W2168356304", "https://openalex.org/W2171361956", "https://openalex.org/W2952793010", "https://openalex.org/W78159342", "https://openalex.org/W95258188"]}, {"ref_id": "b66", "matched_paper_id": 11916543, "title": "Colitis detection on abdominal CT scans by rich feature hierarchies", "metadata": {"corpusId": "11916543", "paperId": "79c6d5a6795ded1801c8f6a8e6926cd14fa7cb64", "doi": "10.1117/12.2217681", "url": "https://www.semanticscholar.org/paper/79c6d5a6795ded1801c8f6a8e6926cd14fa7cb64", "abstract": "Colitis is inflammation of the colon due to neutropenia, inflammatory bowel disease (such as Crohn disease), infection and immune compromise. Colitis is often associated with thickening of the colon wall. The wall of a colon afflicted with colitis is much thicker than normal. For example, the mean wall thickness in Crohn disease is 11-13 mm compared to the wall of the normal colon that should measure less than 3 mm. Colitis can be debilitating or life threatening, and early detection is essential to initiate proper treatment. In this work, we apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals to detect potential colitis on CT scans. Our method first generates around 3000 category-independent region proposals for each slice of the input CT scan using selective search. Then, a fixed-length feature vector is extracted from each region proposal using a CNN. Finally, each region proposal is classified and assigned a confidence score with linear SVMs. We applied the detection method to 260 images from 26 CT scans of patients with colitis for evaluation. The detection system can achieve 0.85 sensitivity at 1 false positive per image.", "year": 2016, "referenceCount": 14, "citationCount": 11, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science", "Medicine", "Engineering"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Engineering", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Medicine", "source": "s2-fos-model"}], "publicationDate": "2016-03-24", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "9785", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "49722262", "name": "Jiamin Liu", "hIndex": 26, "citationCount": 3615, "paperCount": 89}, {"authorId": "2230628", "name": "Nathan S. Lay", "hIndex": 19, "citationCount": 1546, "paperCount": 70}, {"authorId": "1748328", "name": "Zhuoshi Wei", "hIndex": 10, "citationCount": 533, "paperCount": 24}, {"authorId": "50706692", "name": "Le Lu", "hIndex": 53, "citationCount": 21747, "paperCount": 269}, {"authorId": "144615064", "name": "Lauren Kim", "hIndex": 11, "citationCount": 1169, "paperCount": 22}, {"authorId": "2434122", "name": "E. Turkbey", "hIndex": 35, "citationCount": 6139, "paperCount": 139}, {"authorId": "144838131", "name": "R. Summers", "hIndex": 76, "citationCount": 28851, "paperCount": 533}], "tldr": {"model": "tldr@v2.0.0", "text": "This work applies high-capacity convolutional neural networks to bottom-up region proposals to detect potential colitis on CT scans and applies the detection method to 260 images from 26 CT scans of patients with colitis for evaluation."}, "topics": ["COVID-19 diagnosis using AI", "Radiomics and Machine Learning in Medical Imaging", "AI in cancer detection"], "keywords": ["Feature (linguistics)"], "mesh": [], "referenced_works_count": 12}, "referenced_works": ["https://openalex.org/W1946119117", "https://openalex.org/W1999478155", "https://openalex.org/W2031489346", "https://openalex.org/W2067794541", "https://openalex.org/W2082526668", "https://openalex.org/W2086185111", "https://openalex.org/W2088049833", "https://openalex.org/W2102605133", "https://openalex.org/W2163605009", "https://openalex.org/W2163922914", "https://openalex.org/W317170363", "https://openalex.org/W4205098750"]}, {"ref_id": "b67", "matched_paper_id": 14162688, "title": "A Deep Learning Network for Right Ventricle Segmentation in Short:Axis MRI", "metadata": {"corpusId": "14162688", "paperId": "062473959b61d94553c9e1416036c69ae6f9f2cb", "doi": "10.22489/CINC.2016.139-406", "url": "https://www.semanticscholar.org/paper/062473959b61d94553c9e1416036c69ae6f9f2cb", "abstract": "The segmentation of the right ventricle (RV) myocardium on MRI is a prerequisite step for the evaluation of RV structure and function, which is of great importance in the diagnose of most cardiac diseases, such as pulmonary hypertension, congenital heart disease, coronary heart disease, and dysplasia.However, RV segmentation is considered challenging, mainly because of the complex crescent shape of the RV across slices and phases.Hence this study aims to propose a new approach to segment RV endocardium and epicardium based on deep learning.The proposed method contains two subtasks: (1) localizing the region of interest (ROI), the biventricular region which contains more meaningful features and can facilitate the RV segmentation, and (2) segmenting the RV myocardium based on the localization.The two subtasks are integrated into a joint task learning framework, in which each task is solved via two multilayer convolutional neural networks.The experiments results show that the proposed method has big potential to be further researched and applied in clinical diagnosis.", "year": 2016, "referenceCount": 21, "citationCount": 59, "influentialCitationCount": 2, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}, {"category": "Medicine", "source": "s2-fos-model"}], "publicationDate": "2016-09-14", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2016 Computing in Cardiology Conference (CinC)", "volume": "", "issue": "", "pages": "485-488", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2918346", "name": "Gongning Luo", "hIndex": 20, "citationCount": 1089, "paperCount": 76}, {"authorId": "2061141895", "name": "R. An", "hIndex": 3, "citationCount": 83, "paperCount": 6}, {"authorId": "1711542", "name": "Kuanquan Wang", "hIndex": 48, "citationCount": 9243, "paperCount": 420}, {"authorId": "8753469", "name": "Suyu Dong", "hIndex": 12, "citationCount": 453, "paperCount": 34}, {"authorId": "2835293", "name": "Henggui Zhang", "hIndex": 49, "citationCount": 8956, "paperCount": 493}], "tldr": {"model": "tldr@v2.0.0", "text": "This study aims to propose a new approach to segment RV endocardium and epicardium based on deep learning and shows that the proposed method has big potential to be further researched and applied in clinical diagnosis."}, "topics": ["Non-Destructive Testing Techniques", "Cardiac Valve Diseases and Treatments", "Venous Thromboembolism Diagnosis and Management"], "keywords": [], "mesh": [], "referenced_works_count": 20}, "referenced_works": ["https://openalex.org/W1038736503", "https://openalex.org/W1987512289", "https://openalex.org/W2049554108", "https://openalex.org/W2057441779", "https://openalex.org/W2071151688", "https://openalex.org/W2086297115", "https://openalex.org/W2092465019", "https://openalex.org/W2123345492", "https://openalex.org/W2154554359", "https://openalex.org/W2163605009", "https://openalex.org/W2253429366", "https://openalex.org/W2255189008", "https://openalex.org/W2334919579", "https://openalex.org/W2337438617", "https://openalex.org/W2338803784", "https://openalex.org/W2343881908", "https://openalex.org/W2511065100", "https://openalex.org/W2592958993", "https://openalex.org/W2593223207", "https://openalex.org/W2593690483"]}, {"ref_id": "b68", "matched_paper_id": 26108190, "title": "S-CNN: Subcategory-aware convolutional networks for object detection", "metadata": {"corpusId": "26108190", "paperId": "86824ba374daff17ff2235484055b3bb9c464555", "doi": "10.1109/TPAMI.2017.2756936", "url": "https://www.semanticscholar.org/paper/86824ba374daff17ff2235484055b3bb9c464555", "abstract": "The marriage between the deep convolutional neural network (CNN) and region proposals has made breakthroughs for object detection in recent years. While the discriminative object features are learned via a deep CNN for classification, the large intra-class variation and deformation still limit the performance of the CNN based object detection. We propose a subcategory-aware CNN (S-CNN) to solve the object intra-class variation problem. In the proposed technique, the training samples are first grouped into multiple subcategories automatically through a novel instance sharing maximum margin clustering process. A multi-component Aggregated Channel Feature (ACF) detector is then trained to produce more latent training samples, where each ACF component corresponds to one clustered subcategory. The produced latent samples together with their subcategory labels are further fed into a CNN classifier to filter out false proposals for object detection. An iterative learning algorithm is designed for the joint optimization of image subcategorization, multi-component ACF detector, and subcategory-aware CNN classifier. Experiments on INRIA Person dataset, Pascal VOC 2007 dataset and MS COCO dataset show that the proposed technique clearly outperforms the state-of-the-art methods for generic object detection.", "year": 2018, "referenceCount": 34, "citationCount": 41, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2018-10-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "40", "issue": "", "pages": "2522-2528", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "145456137", "name": "Tao Chen", "hIndex": 19, "citationCount": 1316, "paperCount": 64}, {"authorId": "1771189", "name": "Shijian Lu", "hIndex": 61, "citationCount": 13660, "paperCount": 249}, {"authorId": "2304036", "name": "Jiayuan Fan", "hIndex": 19, "citationCount": 1038, "paperCount": 74}], "tldr": {"model": "tldr@v2.0.0", "text": "A subcategory-aware CNN (S-CNN) is proposed to solve the object intra-class variation problem and clearly outperforms the state-of-the-art methods for generic object detection."}, "topics": ["Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques", "Video Surveillance and Tracking Methods"], "keywords": ["Subcategory", "Pascal (unit)", "Discriminative model", "Boosting"], "mesh": [], "referenced_works_count": 36}, "referenced_works": ["https://openalex.org/W1536680647", "https://openalex.org/W1644641054", "https://openalex.org/W1686810756", "https://openalex.org/W1835666251", "https://openalex.org/W1861492603", "https://openalex.org/W1896395893", "https://openalex.org/W1904365287", "https://openalex.org/W1932624639", "https://openalex.org/W1968405646", "https://openalex.org/W2008678101", "https://openalex.org/W2031454541", "https://openalex.org/W2031489346", "https://openalex.org/W2047418599", "https://openalex.org/W2047508432", "https://openalex.org/W2076063813", "https://openalex.org/W2088049833", "https://openalex.org/W2100912617", "https://openalex.org/W2102605133", "https://openalex.org/W2114623790", "https://openalex.org/W2117069191", "https://openalex.org/W2117539524", "https://openalex.org/W2125556102", "https://openalex.org/W2136724559", "https://openalex.org/W2141357020", "https://openalex.org/W2149951699", "https://openalex.org/W2161969291", "https://openalex.org/W2165826763", "https://openalex.org/W2168356304", "https://openalex.org/W2342976462", "https://openalex.org/W2345272516", "https://openalex.org/W2613718673", "https://openalex.org/W2962835968", "https://openalex.org/W2963037989", "https://openalex.org/W3106250896", "https://openalex.org/W639708223", "https://openalex.org/W845365781"]}, {"ref_id": "b69", "matched_paper_id": 32085416, "title": "Efficient Saliency-Based Object Detection in Remote Sensing Images Using Deep Belief Networks", "metadata": {"corpusId": "32085416", "paperId": "92ad9f8a47a9a60bce0e04c67e2041109c6e25de", "doi": "10.1109/LGRS.2015.2498644", "url": "https://www.semanticscholar.org/paper/92ad9f8a47a9a60bce0e04c67e2041109c6e25de", "abstract": "Object detection has been one of the hottest issues in the field of remote sensing image analysis. In this letter, an efficient object detection framework is proposed, which combines the strength of the unsupervised feature learning of deep belief networks (DBNs) and visual saliency. In particular, we propose an efficient coarse object locating method based on a saliency mechanism. The method could avoid an exhaustive search across the image and generate a small number of bounding boxes, which can locate the object quickly and precisely. After that, the trained DBN is used for feature extraction and classification on subimages. The feature learning of the DBN is operated by pretraining each layer of restricted Boltzmann machines (RBMs) using the general layerwise training algorithm. An unsupervised blockwise pretraining strategy is introduced to train the first layer of RBMs, which combines the raw pixels with a saliency map as inputs. This makes an RBM generate local and edge filters. The precise edge position information and pixel value information are more efficient to build a good model of images. Comparative experiments are conducted on the data set acquired by QuickBird with a 60-cm resolution. The results demonstrate the accuracy and efficiency of our method.", "year": 2016, "referenceCount": 14, "citationCount": 157, "influentialCitationCount": 11, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Environmental Science", "source": "s2-fos-model"}], "publicationDate": "2016-01-11", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Geoscience and Remote Sensing Letters", "volume": "13", "issue": "", "pages": "137-141", "id": "https://openalex.org/S126920919", "h_index": 164, "i10_index": 4969, "2yr_mean_citedness": 3.9556061468412067, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2600667", "name": "W. Diao", "hIndex": 27, "citationCount": 2708, "paperCount": 137}, {"authorId": "2946890", "name": "Xian Sun", "hIndex": 48, "citationCount": 9406, "paperCount": 245}, {"authorId": "37149703", "name": "Xinwei Zheng", "hIndex": 9, "citationCount": 611, "paperCount": 15}, {"authorId": "3000336", "name": "Fangzheng Dou", "hIndex": 7, "citationCount": 282, "paperCount": 8}, {"authorId": "2109602634", "name": "Hongqi Wang", "hIndex": 30, "citationCount": 3202, "paperCount": 87}, {"authorId": "2266415", "name": "Kun Fu", "hIndex": 48, "citationCount": 9312, "paperCount": 223}], "tldr": {"model": "tldr@v2.0.0", "text": "An efficient object detection framework is proposed, which combines the strength of the unsupervised feature learning of deep belief networks (DBNs) and visual saliency and an efficient coarse object locating method based on a saliency mechanism is proposed."}, "topics": ["Visual Attention and Saliency Detection", "Advanced Neural Network Applications", "Advanced Image and Video Retrieval Techniques"], "keywords": ["Deep belief network", "Feature (linguistics)", "Restricted Boltzmann machine", "Minimum bounding box"], "mesh": [], "referenced_works_count": 15}, "referenced_works": ["https://openalex.org/W1995997122", "https://openalex.org/W2010181071", "https://openalex.org/W2013081398", "https://openalex.org/W2022508996", "https://openalex.org/W2037954058", "https://openalex.org/W2048250827", "https://openalex.org/W2049677900", "https://openalex.org/W2084465266", "https://openalex.org/W2088049833", "https://openalex.org/W2103384342", "https://openalex.org/W2110798204", "https://openalex.org/W2136922672", "https://openalex.org/W2161969291", "https://openalex.org/W2169109920", "https://openalex.org/W44815768"]}, {"ref_id": "b70", "matched_paper_id": 2416787, "title": "3D object recognition with deep belief nets", "metadata": {"corpusId": "2416787", "paperId": "5a2668bf420d8509a4dfa28e1cdcdac14c649975", "doi": "", "url": "https://www.semanticscholar.org/paper/5a2668bf420d8509a4dfa28e1cdcdac14c649975", "abstract": null, "year": 2009, "referenceCount": 21, "citationCount": 365, "influentialCitationCount": 25, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2009-12-07", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "1339-1347", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2073603971", "name": "Vinod Nair", "hIndex": 15, "citationCount": 18516, "paperCount": 24}, {"authorId": "1695689", "name": "Geoffrey E. Hinton", "hIndex": 159, "citationCount": 524207, "paperCount": 468}], "tldr": {"model": "tldr@v2.0.0", "text": "A new type of top-level model for Deep Belief Nets is introduced, a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients that substantially outperforms shallow models such as SVMs."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b71", "matched_paper_id": 21070027, "title": "Fast and adaptive deep fusion learning for detecting visual objects", "metadata": {"corpusId": "21070027", "paperId": "94269bceebc273b92f013da104b10f416f919470", "doi": "10.1007/978-3-642-33885-4_35", "url": "https://www.semanticscholar.org/paper/94269bceebc273b92f013da104b10f416f919470", "abstract": null, "year": 2012, "referenceCount": 20, "citationCount": 23, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2012-10-07", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "345-354", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "120205775", "name": "N. Doulamis", "hIndex": 45, "citationCount": 10014, "paperCount": 454}, {"authorId": "1746705", "name": "A. Doulamis", "hIndex": 44, "citationCount": 9793, "paperCount": 450}], "tldr": {"model": "tldr@v2.0.0", "text": "A novel fast (in real-time) and adaptive information fusion strategy that exploits the deep learning paradigm that integrates optimization strategies able to update in real- time the non-linear model parameters according in a way to trust the current changes of the environment, while providing a minimal degradation of the previous gained experience."}, "topics": ["Video Surveillance and Tracking Methods", "Advanced Image and Video Retrieval Techniques", "Infrared Target Detection Methodologies"], "keywords": ["Robustness", "Fusion mechanism", "Sensor Fusion"], "mesh": [], "referenced_works_count": 20}, "referenced_works": ["https://openalex.org/W1807914171", "https://openalex.org/W1973445088", "https://openalex.org/W1999680748", "https://openalex.org/W2034276366", "https://openalex.org/W2053181242", "https://openalex.org/W2088012302", "https://openalex.org/W2102625004", "https://openalex.org/W2111644456", "https://openalex.org/W2121332494", "https://openalex.org/W2126108553", "https://openalex.org/W2131296063", "https://openalex.org/W2136922672", "https://openalex.org/W2143715815", "https://openalex.org/W2153715347", "https://openalex.org/W2158164339", "https://openalex.org/W2161160446", "https://openalex.org/W2161893161", "https://openalex.org/W2163532725", "https://openalex.org/W2171932356", "https://openalex.org/W2339558981"]}, {"ref_id": "b72", "matched_paper_id": null, "title": ""}, {"ref_id": "b73", "matched_paper_id": 8772285, "title": "Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data", "metadata": {"corpusId": "8772285", "paperId": "22d6d9c1b7ac2738b51d93be45ac8f753f81867c", "doi": "10.1109/TPAMI.2012.277", "url": "https://www.semanticscholar.org/paper/22d6d9c1b7ac2738b51d93be45ac8f753f81867c", "abstract": "Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning, obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities, as tissue types and the shapes of the organs in these datasets differ widely. However, organ detection in such an abnormal dataset may have many promising potential real-world applications, such as automatic diagnosis, automated radiotherapy planning, and medical image retrieval, where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here, we test the application of deep learning methods to organ identification in magnetic resonance medical images, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ detection, with the features learned from the deep learning model. This shows the potential of the deep learning model for application to medical images, despite the difficulty of obtaining libraries of correctly labeled training datasets and despite the intrinsic abnormalities present in patient datasets.", "year": 2013, "referenceCount": 63, "citationCount": 488, "influentialCitationCount": 14, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Medicine", "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}], "publicationDate": "2013-08-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "35", "issue": "", "pages": "1930-1943", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1797022", "name": "Hoo-Chang Shin", "hIndex": 19, "citationCount": 12943, "paperCount": 35}, {"authorId": "145945500", "name": "M. Orton", "hIndex": 32, "citationCount": 3999, "paperCount": 118}, {"authorId": "50070934", "name": "D. Collins", "hIndex": 57, "citationCount": 16118, "paperCount": 287}, {"authorId": "97784505", "name": "S. Doran", "hIndex": 32, "citationCount": 4694, "paperCount": 136}, {"authorId": "144544800", "name": "M. Leach", "hIndex": 75, "citationCount": 28146, "paperCount": 587}], "tldr": {"model": "tldr@v2.0.0", "text": "The application of deep learning methods to organ identification in magnetic resonance medical images is tested, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier."}, "topics": ["AI in cancer detection", "Radiomics and Machine Learning in Medical Imaging", "Medical Image Segmentation Techniques"], "keywords": ["Ground truth", "Supervised Learning"], "mesh": ["Image Processing, Computer-Assisted/methods", "Magnetic Resonance Imaging/methods", "Artificial Intelligence/None", "Databases, Factual/None", "Humans/None", "Image Enhancement/methods", "Pattern Recognition, Automated/None", "Pilot Projects/None"], "referenced_works_count": 58}, "referenced_works": ["https://openalex.org/W1498436455", "https://openalex.org/W1526682349", "https://openalex.org/W1536929369", "https://openalex.org/W1547035658", "https://openalex.org/W1576445103", "https://openalex.org/W1589990798", "https://openalex.org/W1594551768", "https://openalex.org/W1676308325", "https://openalex.org/W1677409904", "https://openalex.org/W1803207300", "https://openalex.org/W1965555277", "https://openalex.org/W1971014294", "https://openalex.org/W1983364832", "https://openalex.org/W1999192586", "https://openalex.org/W2003875143", "https://openalex.org/W2025768430", "https://openalex.org/W2049633694", "https://openalex.org/W2051434435", "https://openalex.org/W2056460330", "https://openalex.org/W2072246398", "https://openalex.org/W2097998348", "https://openalex.org/W2098056602", "https://openalex.org/W2102116870", "https://openalex.org/W2103658758", "https://openalex.org/W2105464873", "https://openalex.org/W2105728138", "https://openalex.org/W2108665656", "https://openalex.org/W2110798204", "https://openalex.org/W2112274848", "https://openalex.org/W2112717538", "https://openalex.org/W2115733720", "https://openalex.org/W2118858186", "https://openalex.org/W2122922389", "https://openalex.org/W2124386111", "https://openalex.org/W2131241448", "https://openalex.org/W2133257461", "https://openalex.org/W2133467637", "https://openalex.org/W2133708491", "https://openalex.org/W2136922672", "https://openalex.org/W2137313500", "https://openalex.org/W2139427956", "https://openalex.org/W2140833774", "https://openalex.org/W2141200610", "https://openalex.org/W2154422044", "https://openalex.org/W2158169396", "https://openalex.org/W2159680539", "https://openalex.org/W2161596514", "https://openalex.org/W2161969291", "https://openalex.org/W2162747531", "https://openalex.org/W2162915993", "https://openalex.org/W2167828171", "https://openalex.org/W2168356304", "https://openalex.org/W2171896402", "https://openalex.org/W2181643798", "https://openalex.org/W2183231851", "https://openalex.org/W2184188583", "https://openalex.org/W22861983", "https://openalex.org/W2566427651"]}, {"ref_id": "b74", "matched_paper_id": 6988818, "title": "A benchmark dataset and saliencyguided stacked autoencoders for video-based salient object detection", "metadata": {"corpusId": "6988818", "paperId": "55604c73022a40953ed0ff67c8b0e543ae6e9451", "doi": "10.1109/TIP.2017.2762594", "url": "https://www.semanticscholar.org/paper/55604c73022a40953ed0ff67c8b0e543ae6e9451", "abstract": "Image-based salient object detection (SOD) has been extensively studied in past decades. However, video-based SOD is much less explored due to the lack of large-scale video datasets within which salient objects are unambiguously defined and annotated. Toward this end, this paper proposes a video-based SOD dataset that consists of 200 videos. In constructing the dataset, we manually annotate all objects and regions over 7650 uniformly sampled keyframes and collect the eye-tracking data of 23 subjects who free-view all videos. From the user data, we find that salient objects in a video can be defined as objects that consistently pop-out throughout the video, and objects with such attributes can be unambiguously annotated by combining manually annotated object/region masks with eye-tracking data of multiple subjects. To the best of our knowledge, it is currently the largest dataset for video-based salient object detection. Based on this dataset, this paper proposes an unsupervised baseline approach for video-based SOD by using saliency-guided stacked autoencoders. In the proposed approach, multiple spatiotemporal saliency cues are first extracted at the pixel, superpixel, and object levels. With these saliency cues, stacked autoencoders are constructed in an unsupervised manner that automatically infers a saliency score for each pixel by progressively encoding the high-dimensional saliency cues gathered from the pixel and its spatiotemporal neighbors. In experiments, the proposed unsupervised approach is compared with 31 state-of-the-art models on the proposed dataset and outperforms 30 of them, including 19 image-based classic (unsupervised or non-deep learning) models, six image-based deep learning models, and five video-based unsupervised models. Moreover, benchmarking results show that the proposed dataset is very challenging and has the potential to boost the development of video-based SOD.", "year": 2016, "referenceCount": 75, "citationCount": 126, "influentialCitationCount": 28, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2016-11-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Image Processing", "volume": "27", "issue": "", "pages": "349-364", "id": "https://openalex.org/S4210173141", "h_index": 375, "i10_index": 8245, "2yr_mean_citedness": 11.40652818991098, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2118372693", "name": "Jia Li", "hIndex": 26, "citationCount": 1943, "paperCount": 63}, {"authorId": "2749565", "name": "Changqun Xia", "hIndex": 12, "citationCount": 1013, "paperCount": 29}, {"authorId": "1425091532", "name": "Xiaowu Chen", "hIndex": 32, "citationCount": 3213, "paperCount": 137}], "tldr": {"model": "tldr@v2.0.0", "text": "The proposed unsupervised baseline approach for video-based SOD is compared with 31 state-of-the-art models on the proposed dataset and outperforms 30 of them, including 19 image-based classic (unsupervised or non-deep learning) models, six image- based deep learning models, and five video- based unsuper supervised models."}, "topics": ["Visual Attention and Saliency Detection", "Gaze Tracking and Assistive Technology", "Face Recognition and Perception"], "keywords": ["Benchmark (surveying)"], "mesh": [], "referenced_works_count": 77}, "referenced_works": ["https://openalex.org/W1496571393", "https://openalex.org/W1534510265", "https://openalex.org/W1686810756", "https://openalex.org/W1772076007", "https://openalex.org/W1894057436", "https://openalex.org/W1897243830", "https://openalex.org/W1918837316", "https://openalex.org/W1942214758", "https://openalex.org/W1947031653", "https://openalex.org/W1954128991", "https://openalex.org/W1986811142", "https://openalex.org/W1990802205", "https://openalex.org/W1992992668", "https://openalex.org/W1996326832", "https://openalex.org/W2002574940", "https://openalex.org/W2002781701", "https://openalex.org/W2004362043", "https://openalex.org/W2010399676", "https://openalex.org/W2011900468", "https://openalex.org/W2018946093", "https://openalex.org/W2020523103", "https://openalex.org/W2032258487", "https://openalex.org/W2034740917", "https://openalex.org/W2037954058", "https://openalex.org/W2038913936", "https://openalex.org/W2039313011", "https://openalex.org/W2047670868", "https://openalex.org/W2063093722", "https://openalex.org/W20683899", "https://openalex.org/W2076756823", "https://openalex.org/W2080142539", "https://openalex.org/W2081239020", "https://openalex.org/W2081534675", "https://openalex.org/W2086791339", "https://openalex.org/W2097878628", "https://openalex.org/W2098702446", "https://openalex.org/W2100470808", "https://openalex.org/W2105454024", "https://openalex.org/W2110019070", "https://openalex.org/W2113708607", "https://openalex.org/W2118490033", "https://openalex.org/W2122076510", "https://openalex.org/W2122194171", "https://openalex.org/W2122465129", "https://openalex.org/W2128340050", "https://openalex.org/W2131427930", "https://openalex.org/W2131747574", "https://openalex.org/W2137110664", "https://openalex.org/W2138682569", "https://openalex.org/W2152233525", "https://openalex.org/W2157554677", "https://openalex.org/W2159772167", "https://openalex.org/W2161185676", "https://openalex.org/W2164869561", "https://openalex.org/W2166650627", "https://openalex.org/W2168804568", "https://openalex.org/W2201780148", "https://openalex.org/W2211996548", "https://openalex.org/W2214871046", "https://openalex.org/W2284593976", "https://openalex.org/W2293332611", "https://openalex.org/W2338972621", "https://openalex.org/W2346506533", "https://openalex.org/W2358876993", "https://openalex.org/W2398757039", "https://openalex.org/W2402395722", "https://openalex.org/W2437041077", "https://openalex.org/W2461475918", "https://openalex.org/W2470139095", "https://openalex.org/W2519528544", "https://openalex.org/W2567978322", "https://openalex.org/W2754188632", "https://openalex.org/W2962835968", "https://openalex.org/W2963299740", "https://openalex.org/W2963635628", "https://openalex.org/W3104979525", "https://openalex.org/W4239147634"]}, {"ref_id": "b75", "matched_paper_id": 5785086, "title": "Blessing of dimensionality: high-dimensional feature and its efficient compression for face verification", "metadata": {"corpusId": "5785086", "paperId": "168c64fa2f42f1683ee2cdba9621ac825f5d946d", "doi": "10.1109/CVPR.2013.389", "url": "https://www.semanticscholar.org/paper/168c64fa2f42f1683ee2cdba9621ac825f5d946d", "abstract": "Making a high-dimensional (e.g., 100K-dim) feature for face recognition seems not a good idea because it will bring difficulties on consequent training, computation, and storage. This prevents further exploration of the use of a high dimensional feature. In this paper, we study the performance of a high dimensional feature. We first empirically show that high dimensionality is critical to high performance. A 100K-dim feature, based on a single-type Local Binary Pattern (LBP) descriptor, can achieve significant improvements over both its low-dimensional version and the state-of-the-art. We also make the high-dimensional feature practical. With our proposed sparse projection method, named rotated sparse regression, both computation and model storage can be reduced by over 100 times without sacrificing accuracy quality.", "year": 2013, "referenceCount": 42, "citationCount": 696, "influentialCitationCount": 97, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-06-23", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2013 IEEE Conference on Computer Vision and Pattern Recognition", "volume": "", "issue": "", "pages": "3025-3032", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "47514557", "name": "Dong Chen", "hIndex": 48, "citationCount": 11647, "paperCount": 71}, {"authorId": "47300766", "name": "Xudong Cao", "hIndex": 16, "citationCount": 5130, "paperCount": 28}, {"authorId": "1716835", "name": "Fang Wen", "hIndex": 52, "citationCount": 12924, "paperCount": 76}, {"authorId": null, "name": "Jian Sun"}], "tldr": {"model": "tldr@v2.0.0", "text": "It is empirically shown that high dimensionality is critical to high performance, and a 100K-dim feature, based on a single-type Local Binary Pattern descriptor, can achieve significant improvements over both its low-dimensional version and the state-of-the-art."}, "topics": ["Face and Expression Recognition", "Advanced Image and Video Retrieval Techniques", "Face recognition and analysis"], "keywords": ["Feature (linguistics)", "Local Binary Patterns", "High dimensional"], "mesh": [], "referenced_works_count": 45}, "referenced_works": ["https://openalex.org/W1561974264", "https://openalex.org/W1573965745", "https://openalex.org/W1678356000", "https://openalex.org/W170472577", "https://openalex.org/W1782590233", "https://openalex.org/W1854859904", "https://openalex.org/W1871180460", "https://openalex.org/W1975900269", "https://openalex.org/W1982048725", "https://openalex.org/W2001519147", "https://openalex.org/W2008932806", "https://openalex.org/W2020308406", "https://openalex.org/W2024688311", "https://openalex.org/W2027717478", "https://openalex.org/W2032558548", "https://openalex.org/W2053229256", "https://openalex.org/W2062104878", "https://openalex.org/W2090042335", "https://openalex.org/W2097018403", "https://openalex.org/W2097360283", "https://openalex.org/W2098693229", "https://openalex.org/W2100500227", "https://openalex.org/W2109824782", "https://openalex.org/W2117553576", "https://openalex.org/W2118858186", "https://openalex.org/W2119479037", "https://openalex.org/W2121647436", "https://openalex.org/W2122825543", "https://openalex.org/W2127807804", "https://openalex.org/W2128554449", "https://openalex.org/W2138406903", "https://openalex.org/W2151103935", "https://openalex.org/W2159786793", "https://openalex.org/W2160692033", "https://openalex.org/W2161969291", "https://openalex.org/W2162708633", "https://openalex.org/W2162915993", "https://openalex.org/W2163808566", "https://openalex.org/W2165731615", "https://openalex.org/W2167327733", "https://openalex.org/W2296659146", "https://openalex.org/W2536626143", "https://openalex.org/W4232730838", "https://openalex.org/W4285719527", "https://openalex.org/W4294541781"]}, {"ref_id": "b76", "matched_paper_id": 5726206, "title": "A practical transfer learning algorithm for face verification", "metadata": {"corpusId": "5726206", "paperId": "f11dda255eedb4674425b2b0a20acfa7b8d28300", "doi": "10.1109/ICCV.2013.398", "url": "https://www.semanticscholar.org/paper/f11dda255eedb4674425b2b0a20acfa7b8d28300", "abstract": "Face verification involves determining whether a pair of facial images belongs to the same or different subjects. This problem can prove to be quite challenging in many important applications where labeled training data is scarce, e.g., family album photo organization software. Herein we propose a principled transfer learning approach for merging plentiful source-domain data with limited samples from some target domain of interest to create a classifier that ideally performs nearly as well as if rich target-domain data were present. Based upon a surprisingly simple generative Bayesian model, our approach combines a KL-divergence based regularizer/prior with a robust likelihood function leading to a scalable implementation via the EM algorithm. As justification for our design choices, we later use principles from convex analysis to recast our algorithm as an equivalent structured rank minimization problem leading to a number of interesting insights related to solution structure and feature-transform invariance. These insights help to both explain the effectiveness of our algorithm as well as elucidate a wide variety of related Bayesian approaches. Experimental testing with challenging datasets validate the utility of the proposed algorithm.", "year": 2013, "referenceCount": 29, "citationCount": 216, "influentialCitationCount": 12, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-12-01", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2013 IEEE International Conference on Computer Vision", "volume": "", "issue": "", "pages": "3208-3215", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "47300766", "name": "Xudong Cao", "hIndex": 16, "citationCount": 5130, "paperCount": 28}, {"authorId": "2242717", "name": "D. Wipf", "hIndex": 43, "citationCount": 9429, "paperCount": 144}, {"authorId": "1716835", "name": "Fang Wen", "hIndex": 52, "citationCount": 12924, "paperCount": 76}, {"authorId": "3168114", "name": "Genquan Duan", "hIndex": 5, "citationCount": 345, "paperCount": 13}, {"authorId": null, "name": "Jian Sun"}], "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a principled transfer learning approach for merging plentiful source-domain data with limited samples from some target domain of interest to create a classifier that ideally performs nearly as well as if rich target- domain data were present."}, "topics": ["Face and Expression Recognition", "Face recognition and analysis", "Domain Adaptation and Few-Shot Learning"], "keywords": ["Transfer of learning"], "mesh": [], "referenced_works_count": 28}, "referenced_works": ["https://openalex.org/W170472577", "https://openalex.org/W1722318740", "https://openalex.org/W1782590233", "https://openalex.org/W1991278573", "https://openalex.org/W2001519147", "https://openalex.org/W2024688311", "https://openalex.org/W2034136097", "https://openalex.org/W2049485546", "https://openalex.org/W2062104878", "https://openalex.org/W2089685866", "https://openalex.org/W2090923791", "https://openalex.org/W2103519186", "https://openalex.org/W2107250100", "https://openalex.org/W2107298017", "https://openalex.org/W2114588272", "https://openalex.org/W2121647436", "https://openalex.org/W2121812409", "https://openalex.org/W2128053425", "https://openalex.org/W2137607319", "https://openalex.org/W2141581971", "https://openalex.org/W2149466042", "https://openalex.org/W2159786793", "https://openalex.org/W2162854380", "https://openalex.org/W2163147858", "https://openalex.org/W2167144347", "https://openalex.org/W2167327733", "https://openalex.org/W2169495281", "https://openalex.org/W2536626143"]}, {"ref_id": "b77", "matched_paper_id": 11757052, "title": "Tom-vs-Pete classifiers and identity-preserving alignment for face verification", "metadata": {"corpusId": "11757052", "paperId": "5f14a9595b0796ce6e5338f157b763326c1f632f", "doi": "10.5244/C.26.129", "url": "https://www.semanticscholar.org/paper/5f14a9595b0796ce6e5338f157b763326c1f632f", "abstract": "We propose a method of face verification that takes advantage of a reference set of faces, disjoint by identity from the test faces, labeled with identity and face part locations. The reference set is used in two ways. First, we use it to perform an “identity-preserving” alignment, warping the faces in a way that reduces differences due to pose and expression but preserves differences that indicate identity. Second, using the aligned faces, we learn a large set of identity classifiers, each trained on images of just two people. We call these “Tom-vs-Pete” classifiers to stress their binary nature. We assemble a collection of these classifiers able to discriminate among a wide variety of subjects and use their outputs as features in a same-or-different classifier on face pairs. We evaluate our method on the Labeled Faces in the Wild benchmark, achieving an accuracy of 93.10%, significantly improving on the published state of the art.", "year": 2012, "referenceCount": 37, "citationCount": 166, "influentialCitationCount": 17, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "1-11", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2053402806", "name": "Thomas Berg", "hIndex": 4, "citationCount": 968, "paperCount": 5}, {"authorId": "1767767", "name": "P. Belhumeur", "hIndex": 58, "citationCount": 36522, "paperCount": 128}], "tldr": {"model": "tldr@v2.0.0", "text": "A method of face verification that takes advantage of a reference set of faces, disjoint by identity from the test faces, labeled with identity and face part locations, to perform an “identity-preserving” alignment."}, "topics": ["Face recognition and analysis", "Face and Expression Recognition", "Biometric Identification and Security"], "keywords": ["Image warping", "Disjoint sets", "Benchmark (surveying)", "Binary classification"], "mesh": [], "referenced_works_count": 33}, "referenced_works": ["https://openalex.org/W140777655", "https://openalex.org/W1498305593", "https://openalex.org/W1499329969", "https://openalex.org/W1509928947", "https://openalex.org/W1769974409", "https://openalex.org/W1782590233", "https://openalex.org/W1854859904", "https://openalex.org/W1986772615", "https://openalex.org/W1988790447", "https://openalex.org/W2001519147", "https://openalex.org/W2008932806", "https://openalex.org/W2029835507", "https://openalex.org/W2032558548", "https://openalex.org/W2109824782", "https://openalex.org/W2110654099", "https://openalex.org/W2118585731", "https://openalex.org/W2126448884", "https://openalex.org/W2137821246", "https://openalex.org/W2142947774", "https://openalex.org/W2151103935", "https://openalex.org/W2152475608", "https://openalex.org/W2158051493", "https://openalex.org/W2158213899", "https://openalex.org/W2158396493", "https://openalex.org/W2158844819", "https://openalex.org/W2160126058", "https://openalex.org/W2160663297", "https://openalex.org/W2162458225", "https://openalex.org/W2165052637", "https://openalex.org/W2168996682", "https://openalex.org/W2536626143", "https://openalex.org/W2652751060", "https://openalex.org/W4285719527"]}, {"ref_id": "b78", "matched_paper_id": 1345207, "title": "Bayesian face revisited: a joint formulation", "metadata": {"corpusId": "1345207", "paperId": "a0d6390dd28d802152f207940c7716fe5fae8760", "doi": "10.1007/978-3-642-33712-3_41", "url": "https://www.semanticscholar.org/paper/a0d6390dd28d802152f207940c7716fe5fae8760", "abstract": null, "year": 2012, "referenceCount": 28, "citationCount": 435, "influentialCitationCount": 76, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationDate": "2012-10-07", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "566-579", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "47514557", "name": "Dong Chen", "hIndex": 48, "citationCount": 11647, "paperCount": 71}, {"authorId": "47300766", "name": "Xudong Cao", "hIndex": 16, "citationCount": 5130, "paperCount": 28}, {"authorId": "2143440503", "name": "Liwei Wang", "hIndex": 3, "citationCount": 933, "paperCount": 6}, {"authorId": "1716835", "name": "Fang Wen", "hIndex": 52, "citationCount": 12924, "paperCount": 76}, {"authorId": null, "name": "Jian Sun"}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper revisits the classical Bayesian face recognition method by Baback Moghaddam et al. and proposes a new joint formulation that leads to an EM-like model learning at the training time and an efficient, closed-formed computation at the test time."}, "topics": ["Face recognition and analysis", "Face and Expression Recognition", "Speech and Audio Processing"], "keywords": ["Representation"], "mesh": [], "referenced_works_count": 28}, "referenced_works": ["https://openalex.org/W1498305593", "https://openalex.org/W1524981236", "https://openalex.org/W1589137271", "https://openalex.org/W1782590233", "https://openalex.org/W1855204404", "https://openalex.org/W1982048725", "https://openalex.org/W2001519147", "https://openalex.org/W2008932806", "https://openalex.org/W2020315425", "https://openalex.org/W2029008524", "https://openalex.org/W2033419168", "https://openalex.org/W2062104878", "https://openalex.org/W2106053110", "https://openalex.org/W2109824782", "https://openalex.org/W2110654099", "https://openalex.org/W2121647436", "https://openalex.org/W2130556178", "https://openalex.org/W2152015690", "https://openalex.org/W2155162820", "https://openalex.org/W2159786793", "https://openalex.org/W2163352848", "https://openalex.org/W2164617909", "https://openalex.org/W2166602928", "https://openalex.org/W2167144347", "https://openalex.org/W2167327733", "https://openalex.org/W2169495281", "https://openalex.org/W2493402089", "https://openalex.org/W2536626143"]}, {"ref_id": "b79", "matched_paper_id": 2883848, "title": "Face recognition: a convolutional neural-network approach", "metadata": {"corpusId": "2883848", "paperId": "86890c82b589e24007c56e1f40c5f928a0e04183", "doi": "10.1109/72.554195", "url": "https://www.semanticscholar.org/paper/86890c82b589e24007c56e1f40c5f928a0e04183", "abstract": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.", "year": 1997, "referenceCount": 52, "citationCount": 3124, "influentialCitationCount": 124, "fieldsOfStudy": ["Medicine", "Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category": "Medicine", "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE transactions on neural networks", "volume": "8 1", "issue": "", "pages": "\n          98-113\n        ", "id": "https://openalex.org/S42080949", "h_index": 265, "i10_index": 2857, "2yr_mean_citedness": 15.0, "is_core": true, "type": "journal"}, "authors": [{"authorId": "145840115", "name": "S. Lawrence", "hIndex": 55, "citationCount": 22709, "paperCount": 102}, {"authorId": "145157784", "name": "C. Lee Giles", "hIndex": 98, "citationCount": 39248, "paperCount": 605}, {"authorId": "1733691", "name": "A. Tsoi", "hIndex": 38, "citationCount": 16740, "paperCount": 192}, {"authorId": "144288586", "name": "A. Back", "hIndex": 21, "citationCount": 5107, "paperCount": 55}], "tldr": {"model": "tldr@v2.0.0", "text": "A hybrid neural-network for human face recognition which compares favourably with other methods and analyzes the computational complexity and discusses how new classes could be added to the trained recognizer."}, "topics": ["Face and Expression Recognition", "Image Retrieval and Classification Techniques", "Remote-Sensing Image Classification"], "keywords": ["Multilayer perceptron"], "mesh": [], "referenced_works_count": 46}, "referenced_works": ["https://openalex.org/W1480865305", "https://openalex.org/W1508371546", "https://openalex.org/W1538131130", "https://openalex.org/W1557981788", "https://openalex.org/W1679913846", "https://openalex.org/W169539560", "https://openalex.org/W1709413781", "https://openalex.org/W1770825568", "https://openalex.org/W1844103434", "https://openalex.org/W1966754847", "https://openalex.org/W1973436000", "https://openalex.org/W1990517717", "https://openalex.org/W1994335526", "https://openalex.org/W2002011878", "https://openalex.org/W2006572133", "https://openalex.org/W2012352340", "https://openalex.org/W2019179299", "https://openalex.org/W2033432003", "https://openalex.org/W2084362125", "https://openalex.org/W2095539364", "https://openalex.org/W2095757522", "https://openalex.org/W2098947662", "https://openalex.org/W2103560185", "https://openalex.org/W2111123712", "https://openalex.org/W2113341759", "https://openalex.org/W2114766824", "https://openalex.org/W2115689562", "https://openalex.org/W2116360511", "https://openalex.org/W2123421115", "https://openalex.org/W2124776405", "https://openalex.org/W2125713050", "https://openalex.org/W2134616619", "https://openalex.org/W2135346934", "https://openalex.org/W2138451337", "https://openalex.org/W2139314678", "https://openalex.org/W2144004768", "https://openalex.org/W2147647517", "https://openalex.org/W2148695089", "https://openalex.org/W2168228682", "https://openalex.org/W2171225845", "https://openalex.org/W2203760685", "https://openalex.org/W2250112899", "https://openalex.org/W2586915103", "https://openalex.org/W3040828298", "https://openalex.org/W3041461622", "https://openalex.org/W4213332169"]}, {"ref_id": "b80", "matched_paper_id": null, "title": ""}, {"ref_id": "b81", "matched_paper_id": 4637184, "title": "Deep Face Recognition", "metadata": {"corpusId": "4637184", "paperId": "162ea969d1929ed180cc6de9f0bf116993ff6e06", "doi": "10.5244/C.29.41", "url": "https://www.semanticscholar.org/paper/162ea969d1929ed180cc6de9f0bf116993ff6e06", "abstract": "The goal of this paper is face recognition – from either a single photograph or from a set of faces tracked in a video. Recent progress in this area has been due to two factors: (i) end to end learning for the task using a convolutional neural network (CNN), and (ii) the availability of very large scale training datasets. We make two contributions: first, we show how a very large scale dataset (2.6M images, over 2.6K people) can be assembled by a combination of automation and human in the loop, and discuss the trade off between data purity and time; second, we traverse through the complexities of deep network training and face recognition to present methods and procedures to achieve comparable state of the art results on the standard LFW and YTF face benchmarks.", "year": 2015, "referenceCount": 32, "citationCount": 5248, "influentialCitationCount": 832, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "41.1-41.12", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3188342", "name": "Omkar M. Parkhi", "hIndex": 17, "citationCount": 11120, "paperCount": 29}, {"authorId": "1687524", "name": "A. Vedaldi", "hIndex": 101, "citationCount": 84990, "paperCount": 304}, {"authorId": "1688869", "name": "Andrew Zisserman", "hIndex": 182, "citationCount": 293313, "paperCount": 842}], "tldr": {"model": "tldr@v2.0.0", "text": "It is shown how a very large scale dataset can be assembled by a combination of automation and human in the loop, and the trade off between data purity and time is discussed."}, "topics": ["Face recognition and analysis", "Face and Expression Recognition", "Video Surveillance and Tracking Methods"], "keywords": ["Traverse", "Training set", "Data set"], "mesh": [], "referenced_works_count": 31}, "referenced_works": ["https://openalex.org/W1537451167", "https://openalex.org/W170472577", "https://openalex.org/W1782590233", "https://openalex.org/W1827297289", "https://openalex.org/W1849007038", "https://openalex.org/W1861492603", "https://openalex.org/W1921147789", "https://openalex.org/W1975780119", "https://openalex.org/W1984309565", "https://openalex.org/W1998808035", "https://openalex.org/W2007178811", "https://openalex.org/W2019464758", "https://openalex.org/W2056829492", "https://openalex.org/W2103924867", "https://openalex.org/W2111440402", "https://openalex.org/W2115546586", "https://openalex.org/W2117539524", "https://openalex.org/W2121027212", "https://openalex.org/W2138761194", "https://openalex.org/W2140609507", "https://openalex.org/W2144172034", "https://openalex.org/W2145287260", "https://openalex.org/W2147800946", "https://openalex.org/W2163605009", "https://openalex.org/W2950179405", "https://openalex.org/W2952304308", "https://openalex.org/W2953066166", "https://openalex.org/W2962835968", "https://openalex.org/W2963173190", "https://openalex.org/W2963542991", "https://openalex.org/W3099206234"]}, {"ref_id": "b82", "matched_paper_id": 206592766, "title": "FaceNet: a unified embedding for face recognition and clustering", "metadata": {"corpusId": "206592766", "paperId": "5aa26299435bdf7db874ef1640a6c3b5a4a2c394", "doi": "10.1109/CVPR.2015.7298682", "url": "https://www.semanticscholar.org/paper/5aa26299435bdf7db874ef1640a6c3b5a4a2c394", "abstract": "Despite significant recent advances in the field of face recognition [10, 14, 15, 17], implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure offace similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings asfeature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-artface recognition performance using only 128-bytes perface. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result [15] by 30% on both datasets.", "year": 2015, "referenceCount": 24, "citationCount": 12773, "influentialCitationCount": 1730, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-03-12", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "815-823", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3302320", "name": "Florian Schroff", "hIndex": 22, "citationCount": 38469, "paperCount": 37}, {"authorId": "2741985", "name": "Dmitry Kalenichenko", "hIndex": 6, "citationCount": 35548, "paperCount": 7}, {"authorId": "2066819269", "name": "James Philbin", "hIndex": 15, "citationCount": 22174, "paperCount": 23}], "tldr": {"model": "tldr@v2.0.0", "text": "A system that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure offace similarity, and achieves state-of-the-art face recognition performance using only 128-bytes perface."}, "topics": ["Face recognition and analysis", "Face and Expression Recognition", "Biometric Identification and Security"], "keywords": [], "mesh": [], "referenced_works_count": 30}, "referenced_works": ["https://openalex.org/W1498436455", "https://openalex.org/W170472577", "https://openalex.org/W1780066064", "https://openalex.org/W1782590233", "https://openalex.org/W1799366690", "https://openalex.org/W1849277567", "https://openalex.org/W1950843348", "https://openalex.org/W1975517671", "https://openalex.org/W2019464758", "https://openalex.org/W204612701", "https://openalex.org/W2097117768", "https://openalex.org/W2106053110", "https://openalex.org/W2111440402", "https://openalex.org/W2118393783", "https://openalex.org/W2130556178", "https://openalex.org/W2144172034", "https://openalex.org/W2145287260", "https://openalex.org/W2146502635", "https://openalex.org/W2147800946", "https://openalex.org/W2154987621", "https://openalex.org/W2155759509", "https://openalex.org/W2168231600", "https://openalex.org/W2294059674", "https://openalex.org/W2296073425", "https://openalex.org/W2950005842", "https://openalex.org/W2950179405", "https://openalex.org/W2952186574", "https://openalex.org/W2952304308", "https://openalex.org/W2952309299", "https://openalex.org/W3037950864"]}, {"ref_id": "b83", "matched_paper_id": 2814088, "title": "DeepFace: closing the gap to human-level performance in face verification", "metadata": {"corpusId": "2814088", "paperId": "9f2efadf66817f1b38f58b3f50c7c8f34c69d89a", "doi": "10.1109/CVPR.2014.220", "url": "https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a", "abstract": "In modern face recognition, the conventional pipeline consists of four stages: detect => align => represent => classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4, 000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.35% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27%, closely approaching human-level performance.", "year": 2014, "referenceCount": 33, "citationCount": 6105, "influentialCitationCount": 453, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-06-01", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2014 IEEE Conference on Computer Vision and Pattern Recognition", "volume": "", "issue": "", "pages": "1701-1708", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2188620", "name": "Yaniv Taigman", "hIndex": 27, "citationCount": 12589, "paperCount": 41}, {"authorId": "41216159", "name": "Ming Yang", "hIndex": 42, "citationCount": 17074, "paperCount": 85}, {"authorId": "1706809", "name": "Marc'Aurelio Ranzato", "hIndex": 58, "citationCount": 42275, "paperCount": 118}, {"authorId": "145128145", "name": "Lior Wolf", "hIndex": 62, "citationCount": 24182, "paperCount": 261}], "tldr": {"model": "tldr@v2.0.0", "text": "This work revisits both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network."}, "topics": ["Face recognition and analysis", "Face and Expression Recognition", "Biometric Identification and Security"], "keywords": ["Representation"], "mesh": [], "referenced_works_count": 36}, "referenced_works": ["https://openalex.org/W1489081407", "https://openalex.org/W1498436455", "https://openalex.org/W170472577", "https://openalex.org/W1782590233", "https://openalex.org/W1963589611", "https://openalex.org/W1975780119", "https://openalex.org/W1976948919", "https://openalex.org/W1980216075", "https://openalex.org/W1980732600", "https://openalex.org/W2001519147", "https://openalex.org/W2005286252", "https://openalex.org/W2019464758", "https://openalex.org/W2024688311", "https://openalex.org/W2042210654", "https://openalex.org/W2047389622", "https://openalex.org/W2047508432", "https://openalex.org/W2062227835", "https://openalex.org/W2072128103", "https://openalex.org/W2097729189", "https://openalex.org/W2098554822", "https://openalex.org/W2112796928", "https://openalex.org/W2114588272", "https://openalex.org/W2124143113", "https://openalex.org/W2127661044", "https://openalex.org/W2136863438", "https://openalex.org/W2157364932", "https://openalex.org/W2157558673", "https://openalex.org/W2158844819", "https://openalex.org/W2163605009", "https://openalex.org/W2163808566", "https://openalex.org/W2167327733", "https://openalex.org/W2168231600", "https://openalex.org/W2175582831", "https://openalex.org/W2536626143", "https://openalex.org/W2616465717", "https://openalex.org/W4231109964"]}, {"ref_id": "b84", "matched_paper_id": null, "title": ""}, {"ref_id": "b85", "matched_paper_id": 11489291, "title": "A top-down event-driven approach for concurrent activity recognition", "metadata": {"corpusId": "11489291", "paperId": "b3e48ac7405d3c07bcc240f35e1b41dda20dea8e", "doi": "10.1007/s11042-012-0993-4", "url": "https://www.semanticscholar.org/paper/b3e48ac7405d3c07bcc240f35e1b41dda20dea8e", "abstract": null, "year": 2014, "referenceCount": 33, "citationCount": 26, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-03-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Multimedia Tools and Applications", "volume": "69", "issue": "", "pages": "293-311", "id": "https://openalex.org/S110206669", "h_index": 134, "i10_index": 7247, "2yr_mean_citedness": 3.9574852265265923, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2594647", "name": "A. Voulodimos", "hIndex": 30, "citationCount": 5323, "paperCount": 160}, {"authorId": "1750988", "name": "D. Kosmopoulos", "hIndex": 26, "citationCount": 2012, "paperCount": 119}, {"authorId": "120205775", "name": "N. Doulamis", "hIndex": 45, "citationCount": 10014, "paperCount": 454}, {"authorId": "145122221", "name": "T. Varvarigou", "hIndex": 35, "citationCount": 5192, "paperCount": 355}], "tldr": {"model": "tldr@v2.0.0", "text": "A framework for automatic online workflow recognition in industrial environments where the issue of concurrent activities rises, which employs a string matching based technique to confirm the validity of the observed sequence of events or correct any detection or classification errors."}, "topics": ["Anomaly Detection Techniques and Applications", "Human Pose and Action Recognition", "Elevator Systems and Control"], "keywords": ["Representation", "Feature (linguistics)", "Sequence (biology)", "Activity Recognition"], "mesh": [], "referenced_works_count": 34}, "referenced_works": ["https://openalex.org/W1548935184", "https://openalex.org/W1636244751", "https://openalex.org/W1647671624", "https://openalex.org/W1953802779", "https://openalex.org/W1964395255", "https://openalex.org/W1967320926", "https://openalex.org/W1970026646", "https://openalex.org/W1971712513", "https://openalex.org/W1974995050", "https://openalex.org/W1979606776", "https://openalex.org/W2017656341", "https://openalex.org/W2023093000", "https://openalex.org/W2075408774", "https://openalex.org/W2078605801", "https://openalex.org/W2088012302", "https://openalex.org/W2099600129", "https://openalex.org/W2102558090", "https://openalex.org/W2108883127", "https://openalex.org/W2113856781", "https://openalex.org/W2118572719", "https://openalex.org/W2119871181", "https://openalex.org/W2121281594", "https://openalex.org/W2125838338", "https://openalex.org/W2129666410", "https://openalex.org/W2130843763", "https://openalex.org/W2134518303", "https://openalex.org/W2135030552", "https://openalex.org/W2140170007", "https://openalex.org/W2140223865", "https://openalex.org/W2143036568", "https://openalex.org/W2146136606", "https://openalex.org/W2160978457", "https://openalex.org/W2163026698", "https://openalex.org/W2172207578"]}, {"ref_id": "b86", "matched_paper_id": 888778, "title": "Improving multi-camera activity recognition by employing neural network based readjustment", "metadata": {"corpusId": "888778", "paperId": "23d97e6ee39853e3781f1adf110104eef5bbbcb5", "doi": "10.1080/08839514.2012.629540", "url": "https://www.semanticscholar.org/paper/23d97e6ee39853e3781f1adf110104eef5bbbcb5", "abstract": "In this paper, we propose a method to enhance activity recognition in complex environments, where problems like occlusions, outliers and illumination changes occur. In order to address the problems induced by the dependency on the camera's viewpoint, multiple cameras are used in an endeavor to exploit redundancies. We initially examine the effectiveness of various information stream fusion approaches based on hidden Markov models, including Student's t-endowed models for tolerance to outliers. Following, we introduce a neural network-based readjustment mechanism that fits these fusion schemes and aims at dynamically correcting erroneous classification results for image sequences, thus improving the overall recognition rates. The proposed approaches are evaluated under complex real life activity recognition scenarios, and the acquired results are compared and discussed.", "year": 2012, "referenceCount": 53, "citationCount": 27, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2012-01-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Applied Artificial Intelligence", "volume": "26", "issue": "", "pages": "118 - 97", "id": "https://openalex.org/S125501549", "h_index": 82, "i10_index": 795, "2yr_mean_citedness": 5.555984555984556, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2594647", "name": "A. Voulodimos", "hIndex": 30, "citationCount": 5323, "paperCount": 160}, {"authorId": "120205775", "name": "N. Doulamis", "hIndex": 45, "citationCount": 10014, "paperCount": 454}, {"authorId": "1750988", "name": "D. Kosmopoulos", "hIndex": 26, "citationCount": 2012, "paperCount": 119}, {"authorId": "145122221", "name": "T. Varvarigou", "hIndex": 35, "citationCount": 5192, "paperCount": 355}], "tldr": {"model": "tldr@v2.0.0", "text": "A neural network-based readjustment mechanism is introduced that fits information stream fusion approaches based on hidden Markov models and aims at dynamically correcting erroneous classification results for image sequences, thus improving the overall recognition rates."}, "topics": ["Anomaly Detection Techniques and Applications", "Video Surveillance and Tracking Methods", "Human Pose and Action Recognition"], "keywords": ["Activity Recognition", "Fusion mechanism"], "mesh": [], "referenced_works_count": 53}, "referenced_works": ["https://openalex.org/W1498436455", "https://openalex.org/W1509691074", "https://openalex.org/W1522456329", "https://openalex.org/W1528388225", "https://openalex.org/W1537400602", "https://openalex.org/W1557757161", "https://openalex.org/W1953802779", "https://openalex.org/W1964395255", "https://openalex.org/W1972187661", "https://openalex.org/W1973693867", "https://openalex.org/W1978799052", "https://openalex.org/W1979606776", "https://openalex.org/W2006153260", "https://openalex.org/W2019658043", "https://openalex.org/W2020969241", "https://openalex.org/W2026140901", "https://openalex.org/W2037865596", "https://openalex.org/W2049061493", "https://openalex.org/W2068970468", "https://openalex.org/W2075408774", "https://openalex.org/W2088012302", "https://openalex.org/W2093568410", "https://openalex.org/W2096418885", "https://openalex.org/W2097501508", "https://openalex.org/W2099000909", "https://openalex.org/W2102558090", "https://openalex.org/W2106996050", "https://openalex.org/W2112119539", "https://openalex.org/W2113856781", "https://openalex.org/W2118572719", "https://openalex.org/W2119871181", "https://openalex.org/W2121486117", "https://openalex.org/W2125838338", "https://openalex.org/W2129666410", "https://openalex.org/W2130843763", "https://openalex.org/W2132199310", "https://openalex.org/W2134518303", "https://openalex.org/W2135030552", "https://openalex.org/W2139301100", "https://openalex.org/W2140170007", "https://openalex.org/W2143036568", "https://openalex.org/W2148857358", "https://openalex.org/W2152239535", "https://openalex.org/W2156485661", "https://openalex.org/W2160517719", "https://openalex.org/W2160978457", "https://openalex.org/W2161017465", "https://openalex.org/W2161969291", "https://openalex.org/W2163026698", "https://openalex.org/W2164450870", "https://openalex.org/W2164547069", "https://openalex.org/W2172207578", "https://openalex.org/W2213103737"]}, {"ref_id": "b87", "matched_paper_id": 16983288, "title": "Deep learning based human behavior recognition in industrial workflows", "metadata": {"corpusId": "16983288", "paperId": "16e3cdfa546ac7f77167d2602b4ebf2711237a35", "doi": "10.1109/ICIP.2016.7532630", "url": "https://www.semanticscholar.org/paper/16e3cdfa546ac7f77167d2602b4ebf2711237a35", "abstract": "We consider the fully automated behavior understanding through visual cues in industrial environments. In contrast to most existing work, which relies on domain knowledge to construct complex handcrafted features from inputs, we exploit a Convolutional Neural Network (CNN), which is a type of deep model and can act directly on the raw inputs, to automate the process of feature construction. Although such models are limited to handle still 2D inputs, in this paper we appropriately transform video input to incorporate temporal information into each frame. This way our model hierarchically constructs features from both spatial and temporal dimensions. We apply our model in real-world environment, on data taken from Nissan factory, and it achieves superior performance without relying on handcrafted features.", "year": 2016, "referenceCount": 21, "citationCount": 31, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}], "publicationDate": "2016-08-19", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2016 IEEE International Conference on Image Processing (ICIP)", "volume": "", "issue": "", "pages": "1609-1613", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2879272", "name": "Konstantinos Makantasis", "hIndex": 19, "citationCount": 1860, "paperCount": 59}, {"authorId": "1746705", "name": "A. Doulamis", "hIndex": 44, "citationCount": 9793, "paperCount": 450}, {"authorId": "120205775", "name": "N. Doulamis", "hIndex": 45, "citationCount": 10014, "paperCount": 454}, {"authorId": "2961977", "name": "Konstantinos Psychas", "hIndex": 9, "citationCount": 275, "paperCount": 21}], "tldr": {"model": "tldr@v2.0.0", "text": "This work exploits a Convolutional Neural Network, which is a type of deep model and can act directly on the raw inputs, to automate the process of feature construction, and appropriately transform video input to incorporate temporal information into each frame."}, "topics": ["Anomaly Detection Techniques and Applications", "Human Pose and Action Recognition", "Video Surveillance and Tracking Methods"], "keywords": ["Factory (object-oriented programming)", "Feature (linguistics)", "Feature Engineering", "Feature Learning"], "mesh": [], "referenced_works_count": 20}, "referenced_works": ["https://openalex.org/W1528388225", "https://openalex.org/W1564947197", "https://openalex.org/W1570963478", "https://openalex.org/W1606347560", "https://openalex.org/W189596042", "https://openalex.org/W1978799052", "https://openalex.org/W1980353703", "https://openalex.org/W1983364832", "https://openalex.org/W2088012302", "https://openalex.org/W2096691069", "https://openalex.org/W2100495367", "https://openalex.org/W2112796928", "https://openalex.org/W2121281594", "https://openalex.org/W2129623330", "https://openalex.org/W2129666410", "https://openalex.org/W2136853139", "https://openalex.org/W2138256834", "https://openalex.org/W2148603752", "https://openalex.org/W2293753897", "https://openalex.org/W3141200356"]}, {"ref_id": "b88", "matched_paper_id": 7508190, "title": "DevNet: A Deep Event Network for multimedia event detection and evidence recounting", "metadata": {"corpusId": "7508190", "paperId": "3de050d1707524512eeab99780df3cbdee09670c", "doi": "10.1109/CVPR.2015.7298872", "url": "https://www.semanticscholar.org/paper/3de050d1707524512eeab99780df3cbdee09670c", "abstract": "In this paper, we focus on complex event detection in internet videos while also providing the key evidences of the detection results. Convolutional Neural Networks (CNNs) have achieved promising performance in image classification and action recognition tasks. However, it remains an open problem how to use CNNs for video event detection and recounting, mainly due to the complexity and diversity of video events. In this work, we propose a flexible deep CNN infrastructure, namely Deep Event Network (DevNet), that simultaneously detects pre-defined events and provides key spatial-temporal evidences. Taking key frames of videos as input, we first detect the event of interest at the video level by aggregating the CNN features of the key frames. The pieces of evidences which recount the detection results, are also automatically localized, both temporally and spatially. The challenge is that we only have video level labels, while the key evidences usually take place at the frame levels. Based on the intrinsic property of CNNs, we first generate a spatial-temporal saliency map by back passing through DevNet, which then can be used to find the key frames which are most indicative to the event, as well as to localize the specific spatial position, usually an object, in the frame of the highly indicative area. Experiments on the large scale TRECVID 2014 MEDTest dataset demonstrate the promising performance of our method, both for event detection and evidence recounting.", "year": 2015, "referenceCount": 50, "citationCount": 329, "influentialCitationCount": 9, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2015-06-07", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "volume": "", "issue": "", "pages": "2568-2577", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "144158271", "name": "Chuang Gan", "hIndex": 60, "citationCount": 15014, "paperCount": 133}, {"authorId": "48246959", "name": "Naiyan Wang", "hIndex": 40, "citationCount": 16480, "paperCount": 61}, {"authorId": "2143684966", "name": "Yi Yang", "hIndex": 46, "citationCount": 8356, "paperCount": 94}, {"authorId": "1739816", "name": "D. Yeung", "hIndex": 67, "citationCount": 28924, "paperCount": 245}, {"authorId": "7661726", "name": "Alexander Hauptmann", "hIndex": 82, "citationCount": 26424, "paperCount": 525}], "tldr": {"model": "tldr@v2.0.0", "text": "A flexible deep CNN infrastructure, namely Deep Event Network (DevNet), is proposed that simultaneously detects pre-defined events and provides key spatial-temporal evidences, both for event detection and evidence recounting."}, "topics": ["Human Pose and Action Recognition", "Multimodal Machine Learning Applications", "Anomaly Detection Techniques and Applications"], "keywords": ["Key frame"], "mesh": [], "referenced_works_count": 51}, "referenced_works": ["https://openalex.org/W1513753641", "https://openalex.org/W1567302070", "https://openalex.org/W1595717062", "https://openalex.org/W1686810756", "https://openalex.org/W176909285", "https://openalex.org/W1849277567", "https://openalex.org/W1899309388", "https://openalex.org/W1950136256", "https://openalex.org/W1971695614", "https://openalex.org/W2002657139", "https://openalex.org/W2007731511", "https://openalex.org/W2016053056", "https://openalex.org/W2020163092", "https://openalex.org/W2021899621", "https://openalex.org/W2022508996", "https://openalex.org/W2034654291", "https://openalex.org/W2043727559", "https://openalex.org/W2047670868", "https://openalex.org/W2063438554", "https://openalex.org/W2102605133", "https://openalex.org/W2105101328", "https://openalex.org/W2106229755", "https://openalex.org/W2108598243", "https://openalex.org/W2112796928", "https://openalex.org/W2120480077", "https://openalex.org/W2120645068", "https://openalex.org/W2126574503", "https://openalex.org/W2131042978", "https://openalex.org/W2139009685", "https://openalex.org/W2141355815", "https://openalex.org/W2142194269", "https://openalex.org/W2150979491", "https://openalex.org/W2151103935", "https://openalex.org/W2153635508", "https://openalex.org/W2154554359", "https://openalex.org/W2156303437", "https://openalex.org/W2161969291", "https://openalex.org/W2163605009", "https://openalex.org/W2169551590", "https://openalex.org/W2179352600", "https://openalex.org/W2308045930", "https://openalex.org/W243985932", "https://openalex.org/W2504108613", "https://openalex.org/W2529272619", "https://openalex.org/W2950789693", "https://openalex.org/W2962835968", "https://openalex.org/W2962851944", "https://openalex.org/W2963173190", "https://openalex.org/W3047580935", "https://openalex.org/W4239072543", "https://openalex.org/W841113906"]}, {"ref_id": "b89", "matched_paper_id": 16170944, "title": "Activity recognition in beach volleyball using a DEEp Convolutional Neural NETwork: leveraging the potential of DEEp Learning in sports", "metadata": {"corpusId": "16170944", "paperId": "025381c394e2c44807df1a83ee3239def4ead903", "doi": "10.1007/s10618-017-0495-0", "url": "https://www.semanticscholar.org/paper/025381c394e2c44807df1a83ee3239def4ead903", "abstract": null, "year": 2017, "referenceCount": 71, "citationCount": 135, "influentialCitationCount": 7, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}], "publicationDate": "2017-11-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Data Mining and Knowledge Discovery", "volume": "31", "issue": "", "pages": "1678-1705", "id": "https://openalex.org/S121920818", "h_index": 136, "i10_index": 761, "2yr_mean_citedness": 5.56989247311828, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2821100", "name": "T. Kautz", "hIndex": 14, "citationCount": 834, "paperCount": 27}, {"authorId": "2954791", "name": "B. Groh", "hIndex": 12, "citationCount": 428, "paperCount": 27}, {"authorId": "2715588", "name": "J. Hannink", "hIndex": 15, "citationCount": 1049, "paperCount": 31}, {"authorId": "50325975", "name": "Ulf Jensen", "hIndex": 11, "citationCount": 457, "paperCount": 28}, {"authorId": "26607641", "name": "Holger Strubberg", "hIndex": 1, "citationCount": 135, "paperCount": 2}, {"authorId": "1920390", "name": "B. Eskofier", "hIndex": 36, "citationCount": 5193, "paperCount": 197}], "tldr": {"model": "tldr@v2.0.0", "text": "The results show that detailed player monitoring in beach volleyball using wearable sensors is feasible and indicates that Deep Learning has the potential to extend the boundaries of sensor-based activity recognition."}, "topics": ["Non-Invasive Vital Sign Monitoring", "Anomaly Detection Techniques and Applications", "Sports injuries and prevention"], "keywords": ["Margin (machine learning)"], "mesh": [], "referenced_works_count": 61}, "referenced_works": ["https://openalex.org/W114517082", "https://openalex.org/W119403003", "https://openalex.org/W1506806321", "https://openalex.org/W1522301498", "https://openalex.org/W1523794535", "https://openalex.org/W1578840425", "https://openalex.org/W1594031697", "https://openalex.org/W1663973292", "https://openalex.org/W1677182931", "https://openalex.org/W169052826", "https://openalex.org/W183625566", "https://openalex.org/W1893956891", "https://openalex.org/W1904365287", "https://openalex.org/W1924689489", "https://openalex.org/W1958313680", "https://openalex.org/W1971189938", "https://openalex.org/W1984541135", "https://openalex.org/W1991539813", "https://openalex.org/W2002261403", "https://openalex.org/W2006365246", "https://openalex.org/W2017337590", "https://openalex.org/W2020273436", "https://openalex.org/W2027150542", "https://openalex.org/W2031647209", "https://openalex.org/W2035424729", "https://openalex.org/W2045955564", "https://openalex.org/W2051889077", "https://openalex.org/W2058732827", "https://openalex.org/W2068375500", "https://openalex.org/W2069725995", "https://openalex.org/W2075450508", "https://openalex.org/W2077945629", "https://openalex.org/W2096680959", "https://openalex.org/W2101234009", "https://openalex.org/W2102734279", "https://openalex.org/W2105046342", "https://openalex.org/W2119821739", "https://openalex.org/W2122111042", "https://openalex.org/W2125173681", "https://openalex.org/W2135125546", "https://openalex.org/W2146083629", "https://openalex.org/W2148143831", "https://openalex.org/W2148857358", "https://openalex.org/W2149382544", "https://openalex.org/W2160815625", "https://openalex.org/W2162931300", "https://openalex.org/W2165005611", "https://openalex.org/W2231703879", "https://openalex.org/W2270470215", "https://openalex.org/W2463956487", "https://openalex.org/W2500148847", "https://openalex.org/W2516032334", "https://openalex.org/W2546302380", "https://openalex.org/W2911964244", "https://openalex.org/W2912934387", "https://openalex.org/W2919115771", "https://openalex.org/W2949117887", "https://openalex.org/W2963173190", "https://openalex.org/W3085162807", "https://openalex.org/W4212863985", "https://openalex.org/W98188630"]}, {"ref_id": "b90", "matched_paper_id": 206592218, "title": "Large-scale video classification with convolutional neural networks", "metadata": {"corpusId": "206592218", "paperId": "6d4c9c923e9f145d1c01a2de2afc38ec23c44253", "doi": "10.1109/CVPR.2014.223", "url": "https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253", "abstract": "Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of CNNs on large-scale video classification using a new dataset of 1 million YouTube videos belonging to 487 classes. We study multiple approaches for extending the connectivity of a CNN in time domain to take advantage of local spatio-temporal information and suggest a multiresolution, foveated architecture as a promising way of speeding up the training. Our best spatio-temporal networks display significant performance improvements compared to strong feature-based baselines (55.3% to 63.9%), but only a surprisingly modest improvement compared to single-frame models (59.3% to 60.9%). We further study the generalization performance of our best model by retraining the top layers on the UCF-101 Action Recognition dataset and observe significant performance improvements compared to the UCF-101 baseline model (63.3% up from 43.9%).", "year": 2014, "referenceCount": 30, "citationCount": 6338, "influentialCitationCount": 455, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-06-23", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2014 IEEE Conference on Computer Vision and Pattern Recognition", "volume": "", "issue": "", "pages": "1725-1732", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2354728", "name": "A. Karpathy", "hIndex": 16, "citationCount": 56400, "paperCount": 26}, {"authorId": "1805076", "name": "G. Toderici", "hIndex": 34, "citationCount": 17196, "paperCount": 93}, {"authorId": "152821938", "name": "Sanketh Shetty", "hIndex": 4, "citationCount": 6482, "paperCount": 8}, {"authorId": "152456068", "name": "Thomas Leung", "hIndex": 13, "citationCount": 11851, "paperCount": 16}, {"authorId": "1694199", "name": "R. Sukthankar", "hIndex": 62, "citationCount": 28182, "paperCount": 211}, {"authorId": "48004138", "name": "Li Fei-Fei", "hIndex": 136, "citationCount": 211953, "paperCount": 606}], "tldr": {"model": "tldr@v2.0.0", "text": "This work studies multiple approaches for extending the connectivity of a CNN in time domain to take advantage of local spatio-temporal information and suggests a multiresolution, foveated architecture as a promising way of speeding up the training."}, "topics": ["Human Pose and Action Recognition", "Anomaly Detection Techniques and Applications", "Video Surveillance and Tracking Methods"], "keywords": ["Feature (linguistics)", "Contextual image classification", "Retraining"], "mesh": [], "referenced_works_count": 30}, "referenced_works": ["https://openalex.org/W1498368596", "https://openalex.org/W1586730761", "https://openalex.org/W1967664674", "https://openalex.org/W1983364832", "https://openalex.org/W1993229407", "https://openalex.org/W1999192586", "https://openalex.org/W2020163092", "https://openalex.org/W2022508996", "https://openalex.org/W2062118960", "https://openalex.org/W2100916003", "https://openalex.org/W2102605133", "https://openalex.org/W2108082645", "https://openalex.org/W2108598243", "https://openalex.org/W2112796928", "https://openalex.org/W2116456623", "https://openalex.org/W2126574503", "https://openalex.org/W2131846894", "https://openalex.org/W2142194269", "https://openalex.org/W2161969291", "https://openalex.org/W2163605009", "https://openalex.org/W2167510172", "https://openalex.org/W2168231600", "https://openalex.org/W2206858481", "https://openalex.org/W24089286", "https://openalex.org/W2533739470", "https://openalex.org/W28988658", "https://openalex.org/W2962820688", "https://openalex.org/W2963038646", "https://openalex.org/W2963542991", "https://openalex.org/W4239072543"]}, {"ref_id": "b91", "matched_paper_id": 7870225, "title": "Human activity recognition with smartphone sensors using deep learning neural networks", "metadata": {"corpusId": "7870225", "paperId": "5363f1caefa6fd54ec6e3f6688fbd99e0a65798e", "doi": "", "url": "https://www.semanticscholar.org/paper/5363f1caefa6fd54ec6e3f6688fbd99e0a65798e", "abstract": null, "year": null, "referenceCount": 0, "citationCount": 674, "influentialCitationCount": 42, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": null, "journal": {"name": "", "volume": "", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [], "tldr": {"model": "tldr@v2.0.0", "text": "A deep convolutional neu- ral network (convnet) is proposed to performcient and effective HAR using smartphone sensors by exploiting the inherent characteristics of activities and 1D time-series signals, at the same time providing a way to automatically and data-adaptively extract robust features from raw data."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b92", "matched_paper_id": 27680895, "title": "Crowded Scene Understanding by Deeply Learned Volumetric Slices", "metadata": {"corpusId": "27680895", "paperId": "be374795e9268fbfdb2904964055b0b8b0fb7af8", "doi": "10.1109/TCSVT.2016.2593647", "url": "https://www.semanticscholar.org/paper/be374795e9268fbfdb2904964055b0b8b0fb7af8", "abstract": "Crowd video analysis is one of the hallmark tasks of crowded scene understanding. While we observe a tremendous progress in image-based tasks with the rise of convolutional neural networks (CNNs), performance on video analysis has not (yet) attained the same level of success. In this paper, we introduce intuitive but effective temporal-aware crowd motion channels by uniformly slicing the video volume from different dimensions. Multiple CNN structures with different data-fusion strategies and weight-sharing schemes are proposed to learn the connectivity both spatially and temporally from these motion channels. To well demonstrate our deep model, we construct a new large-scale Who do What at someWhere crowd data set with 10 000 videos from 8257 crowded scenes, and build an attribute set with 94 attributes. Extensive experiments on crowd video attribute prediction demonstrate the effectiveness of our novel method over the state-of-the-art.", "year": 2017, "referenceCount": 49, "citationCount": 35, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2017-03-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Circuits and Systems for Video Technology", "volume": "27", "issue": "", "pages": "613-623", "id": "https://openalex.org/S115173108", "h_index": 212, "i10_index": 4979, "2yr_mean_citedness": 7.258571428571429, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1388486428", "name": "Jing Shao", "hIndex": 33, "citationCount": 7276, "paperCount": 53}, {"authorId": "1717179", "name": "Chen Change Loy", "hIndex": 113, "citationCount": 70830, "paperCount": 341}, {"authorId": "2114072675", "name": "Kai Kang", "hIndex": 8, "citationCount": 1647, "paperCount": 13}, {"authorId": "31843833", "name": "Xiaogang Wang", "hIndex": 127, "citationCount": 92937, "paperCount": 641}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces intuitive but effective temporal-aware crowd motion channels by uniformly slicing the video volume from different dimensions by proposing multiple CNN structures with different data-fusion strategies and weight-sharing schemes."}, "topics": ["Anomaly Detection Techniques and Applications", "Video Surveillance and Tracking Methods", "Human Pose and Action Recognition"], "keywords": ["Data set"], "mesh": [], "referenced_works_count": 53}, "referenced_works": ["https://openalex.org/W1132495310", "https://openalex.org/W1546771929", "https://openalex.org/W1566135517", "https://openalex.org/W1598578845", "https://openalex.org/W1686810756", "https://openalex.org/W1903029394", "https://openalex.org/W1923404803", "https://openalex.org/W1962468782", "https://openalex.org/W1969914528", "https://openalex.org/W1976959044", "https://openalex.org/W1977069908", "https://openalex.org/W1983364832", "https://openalex.org/W2016053056", "https://openalex.org/W2018580609", "https://openalex.org/W2022508996", "https://openalex.org/W2027922120", "https://openalex.org/W2042015300", "https://openalex.org/W2058105398", "https://openalex.org/W2072232009", "https://openalex.org/W2083699127", "https://openalex.org/W2088929512", "https://openalex.org/W209511213", "https://openalex.org/W2097117768", "https://openalex.org/W2102605133", "https://openalex.org/W2108404684", "https://openalex.org/W2108992228", "https://openalex.org/W2109389234", "https://openalex.org/W2116435618", "https://openalex.org/W2121452312", "https://openalex.org/W2121839066", "https://openalex.org/W2123175289", "https://openalex.org/W2125095437", "https://openalex.org/W2125105611", "https://openalex.org/W2126030799", "https://openalex.org/W2126574503", "https://openalex.org/W2127242687", "https://openalex.org/W2135658380", "https://openalex.org/W2140220698", "https://openalex.org/W2144502914", "https://openalex.org/W2149021215", "https://openalex.org/W2156303437", "https://openalex.org/W2159989013", "https://openalex.org/W2160372426", "https://openalex.org/W2161969291", "https://openalex.org/W2162915993", "https://openalex.org/W2163605009", "https://openalex.org/W2165609887", "https://openalex.org/W2172207578", "https://openalex.org/W2325880033", "https://openalex.org/W2618530766", "https://openalex.org/W28988658", "https://openalex.org/W2950179405", "https://openalex.org/W2952453038"]}, {"ref_id": "b93", "matched_paper_id": 851173, "title": "Combining the right features for complex event recognition", "metadata": {"corpusId": "851173", "paperId": "1a81719f9248ab89887af68833fbad9d9a85a526", "doi": "10.1109/ICCV.2013.335", "url": "https://www.semanticscholar.org/paper/1a81719f9248ab89887af68833fbad9d9a85a526", "abstract": "In this paper, we tackle the problem of combining features extracted from video for complex event recognition. Feature combination is an especially relevant task in video data, as there are many features we can extract, ranging from image features computed from individual frames to video features that take temporal information into account. To combine features effectively, we propose a method that is able to be selective of different subsets of features, as some features or feature combinations may be uninformative for certain classes. We introduce a hierarchical method for combining features based on the AND/OR graph structure, where nodes in the graph represent combinations of different sets of features. Our method automatically learns the structure of the AND/OR graph using score-based structure learning, and we introduce an inference procedure that is able to efficiently compute structure scores. We present promising results and analysis on the difficult and large-scale 2011 TRECVID Multimedia Event Detection dataset.", "year": 2013, "referenceCount": 27, "citationCount": 88, "influentialCitationCount": 3, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-12-01", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2013 IEEE International Conference on Computer Vision", "volume": "", "issue": "", "pages": "2696-2703", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "3355264", "name": "K. Tang", "hIndex": 12, "citationCount": 1662, "paperCount": 17}, {"authorId": "38916673", "name": "Bangpeng Yao", "hIndex": 15, "citationCount": 4345, "paperCount": 26}, {"authorId": "48004138", "name": "Li Fei-Fei", "hIndex": 136, "citationCount": 211953, "paperCount": 606}, {"authorId": "1736370", "name": "D. Koller", "hIndex": 126, "citationCount": 75105, "paperCount": 316}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces a hierarchical method for combining features based on the AND/OR graph structure, where nodes in the graph represent combinations of different sets of features and introduces an inference procedure that is able to efficiently compute structure scores."}, "topics": ["Advanced Image and Video Retrieval Techniques", "Human Pose and Action Recognition", "Video Surveillance and Tracking Methods"], "keywords": ["Feature (linguistics)"], "mesh": [], "referenced_works_count": 26}, "referenced_works": ["https://openalex.org/W1566135517", "https://openalex.org/W1646506067", "https://openalex.org/W1758470730", "https://openalex.org/W1999192586", "https://openalex.org/W2017814585", "https://openalex.org/W2024868105", "https://openalex.org/W2050964073", "https://openalex.org/W2067646051", "https://openalex.org/W2098728436", "https://openalex.org/W2108890589", "https://openalex.org/W2109743529", "https://openalex.org/W2119246739", "https://openalex.org/W2122808326", "https://openalex.org/W2124372976", "https://openalex.org/W2132630629", "https://openalex.org/W2139117248", "https://openalex.org/W2141939040", "https://openalex.org/W2142258645", "https://openalex.org/W2142571543", "https://openalex.org/W2151103935", "https://openalex.org/W2161969291", "https://openalex.org/W2163352848", "https://openalex.org/W2171188027", "https://openalex.org/W2538008885", "https://openalex.org/W2905522029", "https://openalex.org/W2915649242"]}, {"ref_id": "b94", "matched_paper_id": 9094338, "title": "Multimodal Multi-Stream Deep Learning for Egocentric Activity Recognition", "metadata": {"corpusId": "9094338", "paperId": "6a9168bd32550e06f2cd23105f82f6735fb2edf4", "doi": "10.1109/CVPRW.2016.54", "url": "https://www.semanticscholar.org/paper/6a9168bd32550e06f2cd23105f82f6735fb2edf4", "abstract": "In this paper, we propose a multimodal multi-stream deep learning framework to tackle the egocentric activity recognition problem, using both the video and sensor data. First, we experiment and extend a multi-stream Convolutional Neural Network to learn the spatial and temporal features from egocentric videos. Second, we propose a multistream Long Short-Term Memory architecture to learn the features from multiple sensor streams (accelerometer, gyroscope, etc.). Third, we propose to use a two-level fusion technique and experiment different pooling techniques to compute the prediction results. Experimental results using a multimodal egocentric dataset show that our proposed method can achieve very encouraging performance, despite the constraint that the scale of the existing egocentric datasets is still quite limited.", "year": 2016, "referenceCount": 26, "citationCount": 77, "influentialCitationCount": 13, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}], "publicationDate": "2016-06-01", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "volume": "", "issue": "", "pages": "378-385", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2527741", "name": "Sibo Song", "hIndex": 10, "citationCount": 384, "paperCount": 11}, {"authorId": "1802086", "name": "V. Chandrasekhar", "hIndex": 39, "citationCount": 7498, "paperCount": 139}, {"authorId": "1709001", "name": "Bappaditya Mandal", "hIndex": 18, "citationCount": 1614, "paperCount": 71}, {"authorId": "2107939311", "name": "Liyuan Li", "hIndex": 26, "citationCount": 4176, "paperCount": 132}, {"authorId": "6516914", "name": "Joo-Hwee Lim", "hIndex": 34, "citationCount": 4508, "paperCount": 281}, {"authorId": "34094551", "name": "G. S. Babu", "hIndex": 10, "citationCount": 1249, "paperCount": 17}, {"authorId": "2307813", "name": "P. P. San", "hIndex": 13, "citationCount": 1665, "paperCount": 30}, {"authorId": "143770929", "name": "Ngai-Man Cheung", "hIndex": 39, "citationCount": 4990, "paperCount": 183}], "tldr": {"model": "tldr@v2.0.0", "text": "A multimodal multi-stream deep learning framework to tackle the egocentric activity recognition problem, using both the video and sensor data, and proposes a multistream Long Short-Term Memory architecture to learn the features from multiple sensor streams."}, "topics": ["Human Pose and Action Recognition", "Context-Aware Activity Recognition Systems", "Gait Recognition and Analysis"], "keywords": ["Pooling", "Activity Recognition", "Sensor Fusion"], "mesh": [], "referenced_works_count": 26}, "referenced_works": ["https://openalex.org/W1522734439", "https://openalex.org/W1548328233", "https://openalex.org/W1578985305", "https://openalex.org/W1922655562", "https://openalex.org/W1944615693", "https://openalex.org/W1947481528", "https://openalex.org/W1983364832", "https://openalex.org/W2016053056", "https://openalex.org/W2017634428", "https://openalex.org/W2025581566", "https://openalex.org/W2031688197", "https://openalex.org/W2035787713", "https://openalex.org/W2068611653", "https://openalex.org/W2093882332", "https://openalex.org/W2108307068", "https://openalex.org/W2108598243", "https://openalex.org/W2149276562", "https://openalex.org/W2156303437", "https://openalex.org/W2159613676", "https://openalex.org/W2165605600", "https://openalex.org/W2288074780", "https://openalex.org/W2308045930", "https://openalex.org/W2396108084", "https://openalex.org/W28988658", "https://openalex.org/W2962727177", "https://openalex.org/W913174861"]}, {"ref_id": "b95", "matched_paper_id": 63833913, "title": "Multiview fusion for activity recognition using deep neural networks", "metadata": {"corpusId": "63833913", "paperId": "92f2d26c9098ce65c041b2e3b4190a4abd1f0c53", "doi": "10.1117/1.JEI.25.4.043010", "url": "https://www.semanticscholar.org/paper/92f2d26c9098ce65c041b2e3b4190a4abd1f0c53", "abstract": "Convolutional neural networks (ConvNets) coupled with long short term memory (LSTM) networks have been recently shown to be effective for video classification as they combine the automatic feature extraction capabilities of a neural network with additional memory in the temporal domain. This paper shows how multiview fusion can be applied to such a ConvNet LSTM architecture. Two different fusion techniques are presented. The system is first evaluated in the context of a driver activity recognition system using data collected in a multicamera driving simulator. These results show significant improvement in accuracy with multiview fusion and also show that deep learning performs better than a traditional approach using spatiotemporal features even without requiring any background subtraction. The system is also validated on another publicly available multiview action recognition dataset that has 12 action classes and 8 camera views.", "year": 2016, "referenceCount": 32, "citationCount": 31, "influentialCitationCount": 2, "fieldsOfStudy": ["Engineering", "Computer Science"], "s2FieldsOfStudy": [{"category": "Engineering", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2016-07-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "Journal of Electronic Imaging", "volume": "25", "issue": "", "pages": "", "id": "https://openalex.org/S158511090", "h_index": 88, "i10_index": 1089, "2yr_mean_citedness": 1.1666666666666667, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2727334", "name": "R. Kavi", "hIndex": 8, "citationCount": 206, "paperCount": 9}, {"authorId": "1877222", "name": "V. Kulathumani", "hIndex": 17, "citationCount": 2302, "paperCount": 71}, {"authorId": "71257408", "name": "Fnu Rohit", "hIndex": 2, "citationCount": 76, "paperCount": 2}, {"authorId": "2147495", "name": "V. Kecojevic", "hIndex": 20, "citationCount": 1343, "paperCount": 72}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper shows how multiview fusion can be applied to such a ConvNet LSTM architecture and shows that deep learning performs better than a traditional approach using spatiotemporal features even without requiring any background subtraction."}, "topics": ["Video Surveillance and Tracking Methods", "Human Pose and Action Recognition", "Anomaly Detection Techniques and Applications"], "keywords": ["Feature (linguistics)"], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b96", "matched_paper_id": 15685913, "title": "Human activity recognition using deep belief networks", "metadata": {"corpusId": "15685913", "paperId": "9821066905c49f4d6c43d1ffe8b10b268cd12e37", "doi": "10.1109/SIU.2016.7496073", "url": "https://www.semanticscholar.org/paper/9821066905c49f4d6c43d1ffe8b10b268cd12e37", "abstract": "Human activity recognition using new generation depth sensors are particularly important for application that require human activity recognition. In this paper, a deep learning based algorithm is developed human activity recognition using RGB-D video sequences. Based on the assumption that every human activity is composed of many smaller actions, a temporal structure is being learnt in order to improve the classification of human activities. Since our approach is an attempt to develop a deep learning structure to the problem, it can be considered as a deep structural arhitecture. A deep neural network is obtained manipulating the activitation functions which yield hidden variables at every hidden layer. Our approach outperforms the methods that are constructed upon engineered features, since it uses the skeleton coordinates extracted from depth images. Tested on a new dataset, it is observed that our appproach outputs better recognition rates compared to those of other state-of-art methods.", "year": 2016, "referenceCount": 17, "citationCount": 16, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2016-05-16", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2016 24th Signal Processing and Communication Application Conference (SIU)", "volume": "", "issue": "", "pages": "1649-1652", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2261159", "name": "H. Yalcin", "hIndex": 15, "citationCount": 692, "paperCount": 56}], "tldr": {"model": "tldr@v2.0.0", "text": "A deep learning based algorithm is developed human activity recognition using RGB-D video sequences that outperforms the methods that are constructed upon engineered features, since it uses the skeleton coordinates extracted from depth images."}, "topics": ["Human Pose and Action Recognition", "Anomaly Detection Techniques and Applications", "Video Surveillance and Tracking Methods"], "keywords": ["Deep belief network", "Activity Recognition", "RGB color model", "Deep Neural Networks"], "mesh": [], "referenced_works_count": 13}, "referenced_works": ["https://openalex.org/W1905368000", "https://openalex.org/W1983363688", "https://openalex.org/W1983364832", "https://openalex.org/W1983705368", "https://openalex.org/W2017695267", "https://openalex.org/W2060280062", "https://openalex.org/W2085735683", "https://openalex.org/W2101032778", "https://openalex.org/W2143267104", "https://openalex.org/W2144380653", "https://openalex.org/W2145546283", "https://openalex.org/W2159613676", "https://openalex.org/W2259089761"]}, {"ref_id": "b97", "matched_paper_id": 8810735, "title": "Dance analysis using multiple kinect sensors", "metadata": {"corpusId": "8810735", "paperId": "6c44e67b93b139c396c1b24dba3199bc36d189bf", "doi": "10.5220/0004874007890795", "url": "https://www.semanticscholar.org/paper/6c44e67b93b139c396c1b24dba3199bc36d189bf", "abstract": "In this paper we present a method for body motion analysis in dance using multiple Kinect sensors. The proposed method applies fusion to combine the skeletal tracking data of multiple sensors in order to solve occlusion and self-occlusion tracking problems and increase the robustness of skeletal tracking. The fused skeletal data is split into five different body parts (torso, left hand, right hand, left leg and right leg), which are then transformed to allow view invariant posture recognition. For each part, a posture vocabulary is generated by performing k-means clustering on a large set of unlabeled postures. Finally, body part postures are combined into body posture sequences and Hidden Conditional Random Fields (HCRF) classifier is used to recognize motion patterns (e.g. dance figures). For the evaluation of the proposed method, Tsamiko dancers are captured using multiple Kinect sensors and experimental results are presented to demonstrate the high recognition accuracy of the proposed method.", "year": 2016, "referenceCount": 15, "citationCount": 83, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2016-11-26", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2014 International Conference on Computer Vision Theory and Applications (VISAPP)", "volume": "2", "issue": "", "pages": "789-795", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2198071", "name": "A. Kitsikidis", "hIndex": 9, "citationCount": 323, "paperCount": 18}, {"authorId": "2296506", "name": "K. Dimitropoulos", "hIndex": 31, "citationCount": 3233, "paperCount": 145}, {"authorId": "2673813", "name": "S. Douka", "hIndex": 13, "citationCount": 881, "paperCount": 36}, {"authorId": "48603481", "name": "N. Grammalidis", "hIndex": 26, "citationCount": 2502, "paperCount": 109}], "tldr": {"model": "tldr@v2.0.0", "text": "The proposed method applies fusion to combine the skeletal tracking data of multiple sensors in order to solve occlusion and self-occlusion tracking problems and increase the robustness of skeletal tracking."}, "topics": ["Human Pose and Action Recognition", "Human Motion and Animation", "Video Analysis and Summarization"], "keywords": ["Torso", "Robustness"], "mesh": [], "referenced_works_count": 6}, "referenced_works": ["https://openalex.org/W2049981393", "https://openalex.org/W2144380653", "https://openalex.org/W2145546283", "https://openalex.org/W2145835757", "https://openalex.org/W2172156083", "https://openalex.org/W3146908699"]}, {"ref_id": "b98", "matched_paper_id": 2277383, "title": "Pictorial structures for object recognition", "metadata": {"corpusId": "2277383", "paperId": "34d21e6bf1586715e233248dee787afc66a1fbe7", "doi": "10.1023/B:VISI.0000042934.15159.49", "url": "https://www.semanticscholar.org/paper/34d21e6bf1586715e233248dee787afc66a1fbe7", "abstract": null, "year": 2004, "referenceCount": 60, "citationCount": 2497, "influentialCitationCount": 285, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": ["JournalArticle"], "journal": {"name": "International Journal of Computer Vision", "volume": "61", "issue": "", "pages": "55-79", "id": "https://openalex.org/S25538012", "h_index": 283, "i10_index": 2338, "2yr_mean_citedness": 10.77304964539007, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1685089", "name": "Pedro F. Felzenszwalb", "hIndex": 29, "citationCount": 29407, "paperCount": 67}, {"authorId": "1713089", "name": "D. Huttenlocher", "hIndex": 57, "citationCount": 32794, "paperCount": 125}], "tldr": {"model": "tldr@v2.0.0", "text": "A computationally efficient framework for part-based modeling and recognition of objects, motivated by the pictorial structure models introduced by Fischler and Elschlager, that allows for qualitative descriptions of visual appearance and is suitable for generic recognition problems."}, "topics": ["Advanced Image and Video Retrieval Techniques", "Image Retrieval and Classification Techniques", "Medical Image Segmentation Techniques"], "keywords": ["Active appearance model", "3D single-object recognition"], "mesh": [], "referenced_works_count": 43}, "referenced_works": ["https://openalex.org/W1481387016", "https://openalex.org/W1560013842", "https://openalex.org/W1602797708", "https://openalex.org/W1958762911", "https://openalex.org/W1975691109", "https://openalex.org/W1988520084", "https://openalex.org/W1991605728", "https://openalex.org/W1994297893", "https://openalex.org/W2000048778", "https://openalex.org/W2020999234", "https://openalex.org/W2033554200", "https://openalex.org/W2045798786", "https://openalex.org/W2068204893", "https://openalex.org/W2069537876", "https://openalex.org/W2085261163", "https://openalex.org/W2092001588", "https://openalex.org/W2097041931", "https://openalex.org/W2097543505", "https://openalex.org/W2108611942", "https://openalex.org/W2112074894", "https://openalex.org/W2117138270", "https://openalex.org/W2118025528", "https://openalex.org/W2120954940", "https://openalex.org/W2123977795", "https://openalex.org/W2124722975", "https://openalex.org/W2128716185", "https://openalex.org/W2128981808", "https://openalex.org/W2131910503", "https://openalex.org/W2133716807", "https://openalex.org/W2136767371", "https://openalex.org/W2138451337", "https://openalex.org/W2143516773", "https://openalex.org/W2150095155", "https://openalex.org/W2153980837", "https://openalex.org/W2159080219", "https://openalex.org/W2159709546", "https://openalex.org/W2160754664", "https://openalex.org/W2163166770", "https://openalex.org/W2752885492", "https://openalex.org/W2974222084", "https://openalex.org/W3145128584", "https://openalex.org/W4285719527", "https://openalex.org/W5743890"]}, {"ref_id": "b99", "matched_paper_id": 7777777, "title": "Learning human pose estimation features with convolutional networks", "metadata": {"corpusId": "7777777", "paperId": "49609ea8946d5c4d8fad96553b10e2b07f4e2485", "doi": "", "url": "https://www.semanticscholar.org/paper/49609ea8946d5c4d8fad96553b10e2b07f4e2485", "abstract": "Abstract: This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "year": 2013, "referenceCount": 52, "citationCount": 213, "influentialCitationCount": 12, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2013-12-27", "publicationTypes": ["JournalArticle"], "journal": {"name": "CoRR", "volume": "abs/1312.7302", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "49147969", "name": "Arjun Jain", "hIndex": 21, "citationCount": 7365, "paperCount": 43}, {"authorId": "2704494", "name": "Jonathan Tompson", "hIndex": 37, "citationCount": 13209, "paperCount": 65}, {"authorId": "1906895", "name": "Mykhaylo Andriluka", "hIndex": 36, "citationCount": 13802, "paperCount": 57}, {"authorId": "144639556", "name": "Graham W. Taylor", "hIndex": 54, "citationCount": 22456, "paperCount": 240}, {"authorId": "2428034", "name": "C. Bregler", "hIndex": 40, "citationCount": 14202, "paperCount": 91}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b100", "matched_paper_id": 392527, "title": "Joint training of a convolutional network and a graphical model for human pose estimation", "metadata": {"corpusId": "392527", "paperId": "12ecc2d786080f638a01b9999518e9386baa157d", "doi": "", "url": "https://www.semanticscholar.org/paper/12ecc2d786080f638a01b9999518e9386baa157d", "abstract": "This paper proposes a new hybrid architecture that consists of a deep Convolu-tional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.", "year": 2014, "referenceCount": 43, "citationCount": 1520, "influentialCitationCount": 102, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-06-11", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "", "volume": "", "issue": "", "pages": "1799-1807", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2704494", "name": "Jonathan Tompson", "hIndex": 37, "citationCount": 13209, "paperCount": 65}, {"authorId": "49147969", "name": "Arjun Jain", "hIndex": 21, "citationCount": 7365, "paperCount": 43}, {"authorId": "1688882", "name": "Yann LeCun", "hIndex": 132, "citationCount": 244817, "paperCount": 405}, {"authorId": "2428034", "name": "C. Bregler", "hIndex": 40, "citationCount": 14202, "paperCount": 91}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a new hybrid architecture that consists of a deep Convolu-tional Network and a Markov Random Field and shows how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images."}, "topics": [], "keywords": [], "mesh": [], "referenced_works_count": 0}}, {"ref_id": "b101", "matched_paper_id": 6953475, "title": "One-shot learning of object categories", "metadata": {"corpusId": "6953475", "paperId": "812355cec91fa30bb50e9e992a3549af39e4f6eb", "doi": "10.1109/TPAMI.2006.79", "url": "https://www.semanticscholar.org/paper/812355cec91fa30bb50e9e992a3549af39e4f6eb", "abstract": "Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by Maximum Likelihood (ML) and Maximum A Posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.", "year": 2006, "referenceCount": 46, "citationCount": 3066, "influentialCitationCount": 174, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2006-04-01", "publicationTypes": ["JournalArticle", "Study"], "journal": {"name": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "volume": "28", "issue": "", "pages": "594-611", "id": "https://openalex.org/S199944782", "h_index": 537, "i10_index": 7353, "2yr_mean_citedness": 14.342065868263473, "is_core": true, "type": "journal"}, "authors": [{"authorId": "48004138", "name": "Li Fei-Fei", "hIndex": 136, "citationCount": 211953, "paperCount": 606}, {"authorId": "2276554", "name": "R. Fergus", "hIndex": 76, "citationCount": 101873, "paperCount": 125}, {"authorId": "1690922", "name": "P. Perona", "hIndex": 102, "citationCount": 113819, "paperCount": 427}], "tldr": {"model": "tldr@v2.0.0", "text": "It is found that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."}, "topics": ["Domain Adaptation and Few-Shot Learning", "Advanced Image and Video Retrieval Techniques", "Image Retrieval and Classification Techniques"], "keywords": [], "mesh": ["Algorithms/None", "Artificial Intelligence/None", "Cluster Analysis/None", "Image Enhancement/methods", "Image Interpretation, Computer-Assisted/methods", "Imaging, Three-Dimensional/methods", "Pattern Recognition, Automated/methods", "Bayes Theorem/None", "Computer Simulation/None", "Image Enhancement/None", "Image Interpretation, Computer-Assisted/None", "Imaging, Three-Dimensional/None", "Information Storage and Retrieval/methods", "Information Storage and Retrieval/None", "Models, Biological/None", "Models, Statistical/None", "Pattern Recognition, Automated/None", "Reproducibility of Results/None", "Sensitivity and Specificity/None"], "referenced_works_count": 48}, "referenced_works": ["https://openalex.org/W136324354", "https://openalex.org/W1578226009", "https://openalex.org/W1618600317", "https://openalex.org/W1676552347", "https://openalex.org/W1699734612", "https://openalex.org/W1758770588", "https://openalex.org/W1772705656", "https://openalex.org/W1949116567", "https://openalex.org/W1958762911", "https://openalex.org/W1992825118", "https://openalex.org/W1997600326", "https://openalex.org/W2030536784", "https://openalex.org/W2045656233", "https://openalex.org/W2049633694", "https://openalex.org/W2094414211", "https://openalex.org/W2105488551", "https://openalex.org/W2112796928", "https://openalex.org/W2117138270", "https://openalex.org/W2118304946", "https://openalex.org/W2124386111", "https://openalex.org/W2124722975", "https://openalex.org/W2125791971", "https://openalex.org/W2130416410", "https://openalex.org/W2134557905", "https://openalex.org/W2137154683", "https://openalex.org/W2154236465", "https://openalex.org/W2154422044", "https://openalex.org/W2155511848", "https://openalex.org/W2156406284", "https://openalex.org/W2159686933", "https://openalex.org/W2160754664", "https://openalex.org/W2162708558", "https://openalex.org/W2163030924", "https://openalex.org/W2164598857", "https://openalex.org/W2166049352", "https://openalex.org/W2168002178", "https://openalex.org/W2168753754", "https://openalex.org/W2171188998", "https://openalex.org/W2173414649", "https://openalex.org/W2204383650", "https://openalex.org/W2217896605", "https://openalex.org/W2544227212", "https://openalex.org/W2567948266", "https://openalex.org/W3146079624", "https://openalex.org/W3151111735", "https://openalex.org/W4234899042", "https://openalex.org/W4247690662", "https://openalex.org/W4248373945"]}, {"ref_id": "b102", "matched_paper_id": null, "title": ""}, {"ref_id": "b103", "matched_paper_id": null, "title": ""}, {"ref_id": "b104", "matched_paper_id": 15718221, "title": "A collection of hyperspectral images for imaging systems research", "metadata": {"corpusId": "15718221", "paperId": "74aace80ca9c823749bd2c56ed44fd36524bab75", "doi": "10.1117/12.2007097", "url": "https://www.semanticscholar.org/paper/74aace80ca9c823749bd2c56ed44fd36524bab75", "abstract": "A set of hyperspectral image data are made available, intended for use in modeling of imaging systems. The set contains images of faces, landscapes and buildings. The data cover wavelengths from 0.4 to 2.5 micrometers, spanning the visible, NIR and SWIR electromagnetic spectral ranges. The images have been recorded with two HySpex line-scan imaging spectrometers covering the spectral ranges 0.4 to 1 micrometers and 1 to 2.5 micrometers. The hyperspectral data set includes measured illuminants and software for converting the radiance data to estimated reflectance. The images are being made available for download at http://scien.stanford.edu", "year": 2013, "referenceCount": 11, "citationCount": 60, "influentialCitationCount": 3, "fieldsOfStudy": ["Geology", "Engineering", "Computer Science"], "s2FieldsOfStudy": [{"category": "Geology", "source": "external"}, {"category": "Engineering", "source": "external"}, {"category": "Computer Science", "source": "external"}, {"category": "Engineering", "source": "s2-fos-model"}, {"category": "Environmental Science", "source": "s2-fos-model"}], "publicationDate": "2013-02-04", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "8660", "issue": "", "pages": "", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "39921280", "name": "T. Skauli", "hIndex": 21, "citationCount": 2202, "paperCount": 97}, {"authorId": "2292019", "name": "J. Farrell", "hIndex": 28, "citationCount": 2734, "paperCount": 120}], "tldr": {"model": "tldr@v2.0.0", "text": "A set of hyperspectral image data are made available, intended for use in modeling of imaging systems, and contains images of faces, landscapes and buildings spanning the visible, NIR and SWIR electromagnetic spectral ranges."}, "topics": ["Color Science and Applications", "Optical Imaging and Spectroscopy Techniques", "Remote-Sensing Image Classification"], "keywords": ["Data set", "Imaging spectrometer", "Full spectral imaging", "Chemical Imaging"], "mesh": [], "referenced_works_count": 9}, "referenced_works": ["https://openalex.org/W1972705477", "https://openalex.org/W1986552350", "https://openalex.org/W2012946078", "https://openalex.org/W2040511445", "https://openalex.org/W2050510245", "https://openalex.org/W2098424973", "https://openalex.org/W2105234315", "https://openalex.org/W2145526806", "https://openalex.org/W2170946361"]}, {"ref_id": "b105", "matched_paper_id": null, "title": ""}, {"ref_id": "b106", "matched_paper_id": 9442999, "title": "Age and gender estimation of unfiltered faces", "metadata": {"corpusId": "9442999", "paperId": "5f8fe6bbc288288bd9f54d2ebdb6a51c46502376", "doi": "10.1109/TIFS.2014.2359646", "url": "https://www.semanticscholar.org/paper/5f8fe6bbc288288bd9f54d2ebdb6a51c46502376", "abstract": "This paper concerns the estimation of facial attributes-namely, age and gender-from images of faces acquired in challenging, in the wild conditions. This problem has received far less attention than the related problem of face recognition, and in particular, has not enjoyed the same dramatic improvement in capabilities demonstrated by contemporary face recognition systems. Here, we address this problem by making the following contributions. First, in answer to one of the key problems of age estimation research-absence of data-we offer a unique data set of face images, labeled for age and gender, acquired by smart-phones and other mobile devices, and uploaded without manual filtering to online image repositories. We show the images in our collection to be more challenging than those offered by other face-photo benchmarks. Second, we describe the dropout-support vector machine approach used by our system for face attribute estimation, in order to avoid over-fitting. This method, inspired by the dropout learning techniques now popular with deep belief networks, is applied here for training support vector machines, to the best of our knowledge, for the first time. Finally, we present a robust face alignment technique, which explicitly considers the uncertainties of facial feature detectors. We report extensive tests analyzing both the difficulty levels of contemporary benchmarks as well as the capabilities of our own system. These show our method to outperform state-of-the-art by a wide margin.", "year": 2014, "referenceCount": 82, "citationCount": 732, "influentialCitationCount": 133, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2014-12-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Information Forensics and Security", "volume": "9", "issue": "", "pages": "2170-2179", "id": "https://openalex.org/S61310614", "h_index": 192, "i10_index": 2859, "2yr_mean_citedness": 7.001166861143524, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2037829", "name": "E. Eidinger", "hIndex": 3, "citationCount": 808, "paperCount": 4}, {"authorId": "1792038", "name": "Roee Enbar", "hIndex": 2, "citationCount": 1066, "paperCount": 4}, {"authorId": "1756099", "name": "Tal Hassner", "hIndex": 46, "citationCount": 11221, "paperCount": 102}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper presents a robust face alignment technique, which explicitly considers the uncertainties of facial feature detectors, and describes the dropout-support vector machine approach used by the system for face attribute estimation, in order to avoid over-fitting."}, "topics": ["Face recognition and analysis", "Face and Expression Recognition", "Biometric Identification and Security"], "keywords": ["Dropout (neural networks)", "Margin (machine learning)", "Feature (linguistics)", "Upload", "Data set", "Feature vector"], "mesh": [], "referenced_works_count": 81}, "referenced_works": ["https://openalex.org/W1509928947", "https://openalex.org/W1514062569", "https://openalex.org/W1527459280", "https://openalex.org/W1550113892", "https://openalex.org/W1556392566", "https://openalex.org/W1569098853", "https://openalex.org/W1663973292", "https://openalex.org/W1782590233", "https://openalex.org/W1866173756", "https://openalex.org/W1904365287", "https://openalex.org/W1915759647", "https://openalex.org/W1971970117", "https://openalex.org/W1972581644", "https://openalex.org/W1976054037", "https://openalex.org/W1983255844", "https://openalex.org/W1997566808", "https://openalex.org/W2005454515", "https://openalex.org/W2009088607", "https://openalex.org/W2019464758", "https://openalex.org/W2020021186", "https://openalex.org/W2020944503", "https://openalex.org/W2030098377", "https://openalex.org/W2031342017", "https://openalex.org/W2036565334", "https://openalex.org/W2038952578", "https://openalex.org/W2047508432", "https://openalex.org/W2059683414", "https://openalex.org/W2067431615", "https://openalex.org/W2073085327", "https://openalex.org/W2087347434", "https://openalex.org/W2096525100", "https://openalex.org/W2098017479", "https://openalex.org/W2099363823", "https://openalex.org/W2101392314", "https://openalex.org/W2105026179", "https://openalex.org/W2106488920", "https://openalex.org/W2109824782", "https://openalex.org/W2114892142", "https://openalex.org/W2118664399", "https://openalex.org/W2118755929", "https://openalex.org/W2119486225", "https://openalex.org/W2119821739", "https://openalex.org/W2123497994", "https://openalex.org/W2123687672", "https://openalex.org/W2125615169", "https://openalex.org/W2129000824", "https://openalex.org/W2134113392", "https://openalex.org/W2135880122", "https://openalex.org/W2135964285", "https://openalex.org/W2136863438", "https://openalex.org/W2138200782", "https://openalex.org/W2141582847", "https://openalex.org/W2144896233", "https://openalex.org/W2147278565", "https://openalex.org/W2149194912", "https://openalex.org/W2153417333", "https://openalex.org/W2157558673", "https://openalex.org/W2158617780", "https://openalex.org/W2158844819", "https://openalex.org/W2161824756", "https://openalex.org/W2163352848", "https://openalex.org/W2163605009", "https://openalex.org/W2163626514", "https://openalex.org/W2163808566", "https://openalex.org/W2164715565", "https://openalex.org/W2165731615", "https://openalex.org/W2169628874", "https://openalex.org/W2170414574", "https://openalex.org/W2237515533", "https://openalex.org/W2397224220", "https://openalex.org/W2534023444", "https://openalex.org/W2536626143", "https://openalex.org/W2594639291", "https://openalex.org/W2652751060", "https://openalex.org/W3004623877", "https://openalex.org/W3097096317", "https://openalex.org/W3820303", "https://openalex.org/W4239510810", "https://openalex.org/W4240282276", "https://openalex.org/W4285719527", "https://openalex.org/W568921399"]}, {"ref_id": "b107", "matched_paper_id": null, "title": ""}, {"ref_id": "b108", "matched_paper_id": 8945673, "title": "ChestX-Ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases", "metadata": {"corpusId": "8945673", "paperId": "63f560006ba47e9b163f45ef46122a5f85b686e6", "doi": "10.1007/978-3-030-13969-8_18", "url": "https://www.semanticscholar.org/paper/63f560006ba47e9b163f45ef46122a5f85b686e6", "abstract": null, "year": 2019, "referenceCount": 19, "citationCount": 1341, "influentialCitationCount": 173, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": null, "publicationTypes": null, "journal": {"name": "", "volume": "", "issue": "", "pages": "369-392", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2026596", "name": "Xiaosong Wang", "hIndex": 23, "citationCount": 7174, "paperCount": 47}, {"authorId": "2699239", "name": "Yifan Peng", "hIndex": 29, "citationCount": 7130, "paperCount": 93}, {"authorId": "50706692", "name": "Le Lu", "hIndex": 53, "citationCount": 21747, "paperCount": 269}, {"authorId": "144202084", "name": "Zhiyong Lu", "hIndex": 75, "citationCount": 30011, "paperCount": 287}, {"authorId": "3774191", "name": "M. Bagheri", "hIndex": 19, "citationCount": 5171, "paperCount": 45}, {"authorId": "144838131", "name": "R. Summers", "hIndex": 76, "citationCount": 28851, "paperCount": 533}], "tldr": {"model": "tldr@v2.0.0", "text": "A new chest X-rays database, namely ChestX-ray8, is presented, which comprises 108,948 frontal-view X-ray images of 32,717 unique patients with the text-mined eight disease image labels from the associated radiological reports using natural language processing, which is validated using the proposed dataset."}, "topics": ["COVID-19 diagnosis using AI", "Lung Cancer Diagnosis and Treatment", "Radiomics and Machine Learning in Medical Imaging"], "keywords": ["Thorax (insect anatomy)"], "mesh": [], "referenced_works_count": 36}, "referenced_works": ["https://openalex.org/W122290181", "https://openalex.org/W1773149199", "https://openalex.org/W1861492603", "https://openalex.org/W1895577753", "https://openalex.org/W1905882502", "https://openalex.org/W1933349210", "https://openalex.org/W1994488211", "https://openalex.org/W2037227137", "https://openalex.org/W2097117768", "https://openalex.org/W2108598243", "https://openalex.org/W2117539524", "https://openalex.org/W2122402213", "https://openalex.org/W2125712079", "https://openalex.org/W2139865360", "https://openalex.org/W2152772232", "https://openalex.org/W2155893237", "https://openalex.org/W2156235098", "https://openalex.org/W2185175083", "https://openalex.org/W2222318341", "https://openalex.org/W2253429366", "https://openalex.org/W2322371438", "https://openalex.org/W2334763311", "https://openalex.org/W2343172899", "https://openalex.org/W2345010043", "https://openalex.org/W2438305798", "https://openalex.org/W2502805798", "https://openalex.org/W2525106365", "https://openalex.org/W2525606708", "https://openalex.org/W2561675875", "https://openalex.org/W2962714319", "https://openalex.org/W2962749469", "https://openalex.org/W2963398599", "https://openalex.org/W2963758027", "https://openalex.org/W2963890755", "https://openalex.org/W2963955958", "https://openalex.org/W3105950366"]}, {"ref_id": "b109", "matched_paper_id": 9938334, "title": "Leveraging mid-level semantic boundary cues for automated lymph node detection", "metadata": {"corpusId": "9938334", "paperId": "47692750125d4a2e45074b755b2d462c080095f0", "doi": "10.1007/978-3-319-24571-3_7", "url": "https://www.semanticscholar.org/paper/47692750125d4a2e45074b755b2d462c080095f0", "abstract": null, "year": 2015, "referenceCount": 16, "citationCount": 36, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Medicine", "source": "s2-fos-model"}], "publicationDate": "2015-10-05", "publicationTypes": ["JournalArticle"], "journal": {"name": "", "volume": "", "issue": "", "pages": "53-61", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2233674", "name": "Ari Seff", "hIndex": 16, "citationCount": 5963, "paperCount": 22}, {"authorId": "50706692", "name": "Le Lu", "hIndex": 53, "citationCount": 21747, "paperCount": 269}, {"authorId": "144719476", "name": "Adrian Barbu", "hIndex": 30, "citationCount": 3299, "paperCount": 140}, {"authorId": "144531567", "name": "H. Roth", "hIndex": 50, "citationCount": 18123, "paperCount": 177}, {"authorId": "1797022", "name": "Hoo-Chang Shin", "hIndex": 19, "citationCount": 12943, "paperCount": 35}, {"authorId": "144838131", "name": "R. Summers", "hIndex": 76, "citationCount": 28851, "paperCount": 533}], "tldr": {"model": "tldr@v2.0.0", "text": "A learned image transformation scheme for producing higher-level inputs to HOG, which moderately outperforms the state-of-the-art deep convolutional neural network (CNN) system in the mediastinum region, without relying on data augmentation and requiring significantly fewer training samples."}, "topics": ["AI in cancer detection", "Radiomics and Machine Learning in Medical Imaging", "Medical Image Segmentation Techniques"], "keywords": ["Feature (linguistics)"], "mesh": [], "referenced_works_count": 17}, "referenced_works": ["https://openalex.org/W1883146913", "https://openalex.org/W1903029394", "https://openalex.org/W1981444270", "https://openalex.org/W2008120479", "https://openalex.org/W2009463667", "https://openalex.org/W2085370032", "https://openalex.org/W2104853049", "https://openalex.org/W2118585731", "https://openalex.org/W2129587342", "https://openalex.org/W2151049637", "https://openalex.org/W2159386181", "https://openalex.org/W2161969291", "https://openalex.org/W2164547129", "https://openalex.org/W2168356304", "https://openalex.org/W2911964244", "https://openalex.org/W3105950366", "https://openalex.org/W317170363"]}, {"ref_id": "b110", "matched_paper_id": 7170984, "title": "A dataset for workflow recognition in industrial scenes", "metadata": {"corpusId": "7170984", "paperId": "a66d7c074851e368a4ed3f0b85e08757ca31e2df", "doi": "10.1109/ICIP.2011.6116362", "url": "https://www.semanticscholar.org/paper/a66d7c074851e368a4ed3f0b85e08757ca31e2df", "abstract": "In this paper we introduce the WR (Workflow Recognition) dataset. Recorded in the production line of a major automobile manufacturer, this dataset consists of sequences that depict workers executing industrial workflows. The heavy occlusions, outliers, the visually complicated background and the human-machinery interaction are among the factors that make this dataset a very challenging testbed for computer vision and image processing algorithms. We provide the original video sequences together with event labeling, as well as feature vectors extracted through our proposed scene representation methodology, and we refer to our results so far in workflow recognition using this dataset.", "year": 2011, "referenceCount": 9, "citationCount": 35, "influentialCitationCount": 0, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}], "publicationDate": "2011-12-29", "publicationTypes": ["JournalArticle", "Conference"], "journal": {"name": "2011 18th IEEE International Conference on Image Processing", "volume": "", "issue": "", "pages": "3249-3252", "id": "", "h_index": "", "i10_index": "", "2yr_mean_citedness": "", "is_core": "", "type": ""}, "authors": [{"authorId": "2594647", "name": "A. Voulodimos", "hIndex": 30, "citationCount": 5323, "paperCount": 160}, {"authorId": "1750988", "name": "D. Kosmopoulos", "hIndex": 26, "citationCount": 2012, "paperCount": 119}, {"authorId": "2610613", "name": "G. Vasiliou", "hIndex": 4, "citationCount": 114, "paperCount": 9}, {"authorId": "1720853", "name": "Emmanuel Sardis", "hIndex": 6, "citationCount": 171, "paperCount": 42}, {"authorId": "1746705", "name": "A. Doulamis", "hIndex": 44, "citationCount": 9793, "paperCount": 450}, {"authorId": "2227582", "name": "Vasilios Anagnostopoulos", "hIndex": 7, "citationCount": 224, "paperCount": 23}, {"authorId": "2755757", "name": "C. Lalos", "hIndex": 6, "citationCount": 127, "paperCount": 13}, {"authorId": "145122221", "name": "T. Varvarigou", "hIndex": 35, "citationCount": 5192, "paperCount": 355}], "tldr": {"model": "tldr@v2.0.0", "text": "This paper provides the original video sequences together with event labeling, as well as feature vectors extracted through the proposed scene representation methodology, and refers to the results so far in workflow recognition using this dataset."}, "topics": ["Anomaly Detection Techniques and Applications", "Human Pose and Action Recognition", "Gait Recognition and Analysis"], "keywords": ["Testbed", "Feature (linguistics)", "Representation"], "mesh": [], "referenced_works_count": 7}, "referenced_works": ["https://openalex.org/W1581274514", "https://openalex.org/W1974995050", "https://openalex.org/W2023093000", "https://openalex.org/W2078046413", "https://openalex.org/W2151458682", "https://openalex.org/W2156485661", "https://openalex.org/W2161969291"]}, {"ref_id": "b111", "matched_paper_id": 14805968, "title": "A threefold dataset for activity and workflow recognition in complex industrial environments", "metadata": {"corpusId": "14805968", "paperId": "b6d2e1dedd07dfb5d7a272f1ed0dbccad286f1e5", "doi": "10.1109/MMUL.2012.31", "url": "https://www.semanticscholar.org/paper/b6d2e1dedd07dfb5d7a272f1ed0dbccad286f1e5", "abstract": "Unlike any previous effort, the Workflow Recognition (WR) large-scale dataset is a collection of video sequences from the real industrial manufacturing environment of a major automobile manufacturer.", "year": 2012, "referenceCount": 12, "citationCount": 35, "influentialCitationCount": 1, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}], "publicationDate": "2012-07-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE MultiMedia", "volume": "19", "issue": "", "pages": "42-52", "id": "https://openalex.org/S72873717", "h_index": 91, "i10_index": 714, "2yr_mean_citedness": 1.4427083333333333, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2594647", "name": "A. Voulodimos", "hIndex": 30, "citationCount": 5323, "paperCount": 160}, {"authorId": "1750988", "name": "D. Kosmopoulos", "hIndex": 26, "citationCount": 2012, "paperCount": 119}, {"authorId": "2610613", "name": "G. Vasiliou", "hIndex": 4, "citationCount": 114, "paperCount": 9}, {"authorId": "1720853", "name": "Emmanuel Sardis", "hIndex": 6, "citationCount": 171, "paperCount": 42}, {"authorId": "2227582", "name": "Vasilios Anagnostopoulos", "hIndex": 7, "citationCount": 224, "paperCount": 23}, {"authorId": "2755757", "name": "C. Lalos", "hIndex": 6, "citationCount": 127, "paperCount": 13}, {"authorId": "1746705", "name": "A. Doulamis", "hIndex": 44, "citationCount": 9793, "paperCount": 450}, {"authorId": "145122221", "name": "T. Varvarigou", "hIndex": 35, "citationCount": 5192, "paperCount": 355}], "tldr": {"model": "tldr@v2.0.0", "text": "The Workflow Recognition (WR) large-scale dataset is a collection of video sequences from the real industrial manufacturing environment of a major automobile manufacturer."}, "topics": ["Anomaly Detection Techniques and Applications", "Time Series Analysis and Forecasting", "Human Pose and Action Recognition"], "keywords": ["Activity Recognition"], "mesh": [], "referenced_works_count": 11}, "referenced_works": ["https://openalex.org/W1581274514", "https://openalex.org/W1966620219", "https://openalex.org/W1978799052", "https://openalex.org/W1996608800", "https://openalex.org/W2017656341", "https://openalex.org/W2056828588", "https://openalex.org/W2088012302", "https://openalex.org/W2099600129", "https://openalex.org/W2121281594", "https://openalex.org/W2148340063", "https://openalex.org/W2163026698"]}, {"ref_id": "b112", "matched_paper_id": 6309858, "title": "A system for multicamera task recognition and summarization for structured environments", "metadata": {"corpusId": "6309858", "paperId": "f482fbdb387b2f7e1c34b8961ec1cb9166ddb057", "doi": "10.1109/TII.2012.2212712", "url": "https://www.semanticscholar.org/paper/f482fbdb387b2f7e1c34b8961ec1cb9166ddb057", "abstract": "In this paper, we propose a novel system for visual recognition and summarization of pick and place tasks that may be executed in settings such as an industrial assembly line. Our novel approach is based on the utilization of hidden Markov models for online task recognition as well as on the use of prior knowledge via a Hopfield-based optimization scheme. To facilitate offline analysis, we extract summaries of the captured content based on these features. We extract the motion energy using the norms of the Zernike moments, looking for local minima and maxima that indicate distinctive visual events and thus key-frames. The proposed scheme is not threshold-dependent, and, therefore, the number of extracted key-frames varies according to the complexity of motion energy variation. We validate our system by experimenting on two datasets.", "year": 2013, "referenceCount": 40, "citationCount": 30, "influentialCitationCount": 2, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}], "publicationDate": "2013-02-01", "publicationTypes": ["JournalArticle"], "journal": {"name": "IEEE Transactions on Industrial Informatics", "volume": "9", "issue": "", "pages": "161-171", "id": "https://openalex.org/S184777250", "h_index": 225, "i10_index": 5473, "2yr_mean_citedness": 8.043595263724434, "is_core": true, "type": "journal"}, "authors": [{"authorId": "1750988", "name": "D. Kosmopoulos", "hIndex": 26, "citationCount": 2012, "paperCount": 119}, {"authorId": "2594647", "name": "A. Voulodimos", "hIndex": 30, "citationCount": 5323, "paperCount": 160}, {"authorId": "1746705", "name": "A. Doulamis", "hIndex": 44, "citationCount": 9793, "paperCount": 450}], "tldr": {"model": "tldr@v2.0.0", "text": "A novel system for visual recognition and summarization of pick and place tasks that may be executed in settings such as an industrial assembly line based on the utilization of hidden Markov models for online task recognition as well as on the use of prior knowledge via a Hopfield-based optimization scheme."}, "topics": ["Video Analysis and Summarization", "Human Pose and Action Recognition", "Handwritten Text Recognition Techniques"], "keywords": ["Maxima and minima", "Variation (astronomy)"], "mesh": [], "referenced_works_count": 41}, "referenced_works": ["https://openalex.org/W1522456329", "https://openalex.org/W1548935184", "https://openalex.org/W1636244751", "https://openalex.org/W1953802779", "https://openalex.org/W1966085046", "https://openalex.org/W1967320926", "https://openalex.org/W1971712513", "https://openalex.org/W1978799052", "https://openalex.org/W2006322444", "https://openalex.org/W2020969241", "https://openalex.org/W2029232718", "https://openalex.org/W2029991575", "https://openalex.org/W2033431158", "https://openalex.org/W2037971948", "https://openalex.org/W2057499409", "https://openalex.org/W2071626817", "https://openalex.org/W2078046413", "https://openalex.org/W2088012302", "https://openalex.org/W2089412209", "https://openalex.org/W2099600129", "https://openalex.org/W2108883127", "https://openalex.org/W2113856781", "https://openalex.org/W2115060048", "https://openalex.org/W2116946038", "https://openalex.org/W2117245166", "https://openalex.org/W2118572719", "https://openalex.org/W2124776405", "https://openalex.org/W2125091774", "https://openalex.org/W2125337530", "https://openalex.org/W2125838338", "https://openalex.org/W2128160875", "https://openalex.org/W2138732321", "https://openalex.org/W2146136606", "https://openalex.org/W2150891397", "https://openalex.org/W2155469951", "https://openalex.org/W2161301299", "https://openalex.org/W2163026698", "https://openalex.org/W2163320927", "https://openalex.org/W2166182796", "https://openalex.org/W2168397545", "https://openalex.org/W4302154743"]}, {"ref_id": "b113", "matched_paper_id": null, "title": ""}], "metadata": {"paperId": "ca011427853d34ce4ec9ccafde8a70c9eacc3e21", "doi": "10.1155/2018/7068349", "url": "https://www.semanticscholar.org/paper/ca011427853d34ce4ec9ccafde8a70c9eacc3e21", "title": "Deep Learning for Computer Vision: A Brief Review", "abstract": "Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.", "year": 2018, "referenceCount": 115, "citationCount": 2709, "influentialCitationCount": 31, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}, {"category": "Medicine", "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationDate": "2018-02-01", "publicationTypes": ["Review", "JournalArticle"], "journal": {"name": "Computational Intelligence and Neuroscience", "volume": "2018", "issue": "", "pages": "", "id": "https://openalex.org/S72372694", "h_index": 102, "i10_index": 1614, "2yr_mean_citedness": 2.1768402154398565, "is_core": true, "type": "journal"}, "authors": [{"authorId": "2594647", "name": "A. Voulodimos", "hIndex": 30, "citationCount": 5323, "paperCount": 160}, {"authorId": "120205775", "name": "N. Doulamis", "hIndex": 45, "citationCount": 10014, "paperCount": 454}, {"authorId": "1746705", "name": "A. Doulamis", "hIndex": 44, "citationCount": 9793, "paperCount": 450}, {"authorId": "1806369", "name": "Eftychios E. Protopapadakis", "hIndex": 26, "citationCount": 4905, "paperCount": 123}], "tldr": {"model": "tldr@v2.0.0", "text": "A brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders are provided."}, "topics": ["Video Surveillance and Tracking Methods", "Advanced Neural Network Applications", "Human Pose and Action Recognition"], "keywords": ["Boltzmann machine", "Restricted Boltzmann machine", "Deep belief network"], "mesh": ["Algorithms/None", "Machine Learning/None", "Neural Networks, Computer/None", "Humans/None"], "referenced_works_count": 57}}